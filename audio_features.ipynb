{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPGnCHmqyXsRoRE8czb7ir3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Susmitapaul45/VoiceRecognition/blob/main/audio_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MHPW2mm9i27K",
        "outputId": "4de4c9c2-66f0-4be3-fa3e-bda3247e3c40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Differentially private dataset saved to: audio_features-CopyDP-8.csv\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv(\"/content/sample_data/audio_features - Copy.csv\")\n",
        "\n",
        "# Extract the \"file_name\" column for later\n",
        "Level_column = dataset[\"file_name\"]\n",
        "\n",
        "# Apply StandardScaler to every numeric column (excluding \"file_name\")\n",
        "numeric_columns = dataset.select_dtypes(include=[np.number]).columns\n",
        "\n",
        "scaler = StandardScaler()\n",
        "dataset[numeric_columns] = scaler.fit_transform(dataset[numeric_columns])\n",
        "\n",
        "# Define the privacy parameter epsilon with a fixed value\n",
        "epsilon = 2  # Fixed value for epsilon\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Function to add Laplace noise to a column\n",
        "def add_noise(column, epsilon):\n",
        "    sensitivity = 1  # Assuming a sensitivity of 1 for simplicity\n",
        "    scale = sensitivity / epsilon\n",
        "    noise = np.random.laplace(0, scale, len(column))\n",
        "    return column + noise\n",
        "\n",
        "# Apply differential privacy to each numeric column in the dataset (excluding \"file_name\")\n",
        "for column in numeric_columns:\n",
        "    dataset[column] = add_noise(dataset[column], epsilon)\n",
        "\n",
        "# Restore the \"file_name\" column\n",
        "dataset[\"file_name\"] = Level_column\n",
        "\n",
        "# Define the output file path\n",
        "output_file_path = \"audio_features-CopyDP-8.csv\"\n",
        "\n",
        "# Save the differentially private dataset to a new CSV file\n",
        "dataset.to_csv(output_file_path, index=False)\n",
        "\n",
        "print(\"Differentially private dataset saved to:\", output_file_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Read and prepare the data\n",
        "df = pd.read_csv('/content/sample_data/audio_features - Copy.csv')\n",
        "X = df.drop(['file_name'], axis=1)\n",
        "y = df['file_name']\n",
        "\n",
        "# Initialize metrics storage\n",
        "accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Initialize 5-fold cross validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross validation\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
        "    # Split the data\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Train the model\n",
        "    clf = RandomForestClassifier(random_state=42)\n",
        "    clf.fit(X_train_scaled, y_train)\n",
        "\n",
        "    # Make predictions\n",
        "    y_pred = clf.predict(X_test_scaled)\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    # Store metrics\n",
        "    accuracies.append(accuracy)\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"\\nFold {fold} Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Calculate and print average metrics\n",
        "print(\"\\nAverage Metrics across all folds:\")\n",
        "print(f\"Accuracy: {np.mean(accuracies):.4f} (+/- {np.std(accuracies):.4f})\")\n",
        "print(f\"Precision: {np.mean(precisions):.4f} (+/- {np.std(precisions):.4f})\")\n",
        "print(f\"Recall: {np.mean(recalls):.4f} (+/- {np.std(recalls):.4f})\")\n",
        "print(f\"F1-score: {np.mean(f1_scores):.4f} (+/- {np.std(f1_scores):.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezWfvPYEkcH4",
        "outputId": "13551b9f-d071-4031-f176-e827a1ce0b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1 Results:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8815\n",
            "\n",
            "Fold 2 Results:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8889\n",
            "\n",
            "Fold 3 Results:\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.7917\n",
            "Recall: 0.7500\n",
            "F1-score: 0.7417\n",
            "\n",
            "Fold 4 Results:\n",
            "Accuracy: 0.8750\n",
            "Precision: 0.9167\n",
            "Recall: 0.8750\n",
            "F1-score: 0.8667\n",
            "\n",
            "Fold 5 Results:\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.7500\n",
            "Recall: 0.7500\n",
            "F1-score: 0.7500\n",
            "\n",
            "Average Metrics across all folds:\n",
            "Accuracy: 0.8306 (+/- 0.0660)\n",
            "Precision: 0.8620 (+/- 0.0757)\n",
            "Recall: 0.8306 (+/- 0.0660)\n",
            "F1-score: 0.8257 (+/- 0.0657)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy import stats\n",
        "\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    \"\"\"Evaluate a model and return multiple metrics\"\"\"\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    return {\n",
        "        'accuracy': accuracy_score(y_test, y_pred),\n",
        "        'precision': precision_score(y_test, y_pred, average='weighted'),\n",
        "        'recall': recall_score(y_test, y_pred, average='weighted'),\n",
        "        'f1': f1_score(y_test, y_pred, average='weighted')\n",
        "    }\n",
        "\n",
        "# Read and prepare the data\n",
        "df = pd.read_csv('/content/sample_data/audio_features - Copy.csv')\n",
        "X = df.drop(['file_name'], axis=1)\n",
        "y = df['file_name']\n",
        "\n",
        "# Initialize models to test\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "    'SVM': SVC(random_state=42),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=42),\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Initialize storage for results\n",
        "results = {name: {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "          for name in models.keys()}\n",
        "\n",
        "# Perform cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate each model\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
        "    # Split and scale data\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Evaluate each model\n",
        "    for name, model in models.items():\n",
        "        metrics = evaluate_model(model, X_train_scaled, X_test_scaled, y_train, y_test)\n",
        "        for metric, value in metrics.items():\n",
        "            results[name][metric].append(value)\n",
        "\n",
        "# Calculate mean and std for each metric\n",
        "summary = pd.DataFrame(columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1', 'Std Dev'])\n",
        "\n",
        "for name in models.keys():\n",
        "    summary = pd.concat([summary, pd.DataFrame([{\n",
        "        'Model': name,\n",
        "        'Accuracy': f\"{np.mean(results[name]['accuracy']):.4f} ± {np.std(results[name]['accuracy']):.4f}\",\n",
        "        'Precision': f\"{np.mean(results[name]['precision']):.4f} ± {np.std(results[name]['precision']):.4f}\",\n",
        "        'Recall': f\"{np.mean(results[name]['recall']):.4f} ± {np.std(results[name]['recall']):.4f}\",\n",
        "        'F1': f\"{np.mean(results[name]['f1']):.4f} ± {np.std(results[name]['f1']):.4f}\",\n",
        "        'Std Dev': np.mean([np.std(results[name][metric]) for metric in ['accuracy', 'precision', 'recall', 'f1']])\n",
        "    }])], ignore_index=True)\n",
        "\n",
        "# Sort by F1 score (extracting mean F1 from string)\n",
        "summary['F1_sort'] = summary['F1'].apply(lambda x: float(x.split(' ')[0]))\n",
        "summary = summary.sort_values('F1_sort', ascending=False).drop('F1_sort', axis=1)\n",
        "\n",
        "# Statistical significance testing\n",
        "best_model = summary.iloc[0]['Model']\n",
        "best_f1_scores = results[best_model]['f1']\n",
        "\n",
        "# Perform t-tests\n",
        "p_values = {}\n",
        "for name in models.keys():\n",
        "    if name != best_model:\n",
        "        t_stat, p_val = stats.ttest_ind(best_f1_scores, results[name]['f1'])\n",
        "        p_values[name] = p_val\n",
        "\n",
        "print(\"Model Performance Summary:\")\n",
        "print(summary.to_string(index=False))\n",
        "print(\"\\nStatistical Significance Testing (p-values compared to best model):\")\n",
        "for model, p_val in p_values.items():\n",
        "    print(f\"{model}: {p_val:.4f}\")\n",
        "\n",
        "# Visualize results\n",
        "plt.figure(figsize=(12, 6))\n",
        "data = [results[model]['f1'] for model in models.keys()]\n",
        "plt.boxplot(data, labels=models.keys())\n",
        "plt.title('Model F1 Scores Comparison')\n",
        "plt.xticks(rotation=45)\n",
        "plt.ylabel('F1 Score')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "-qBlaxeVtU5Y",
        "outputId": "a7cf53ae-4db3-416f-ef4c-ff7a70979331"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-f082ddb10d1b>:68: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  summary = pd.concat([summary, pd.DataFrame([{\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Summary:\n",
            "              Model        Accuracy       Precision          Recall              F1  Std Dev\n",
            "Logistic Regression 0.8750 ± 0.1118 0.8917 ± 0.1041 0.8750 ± 0.1118 0.8717 ± 0.1137 0.110354\n",
            "      Random Forest 0.8306 ± 0.0660 0.8620 ± 0.0757 0.8306 ± 0.0660 0.8257 ± 0.0657 0.068331\n",
            "                SVM 0.8278 ± 0.1015 0.8602 ± 0.0910 0.8278 ± 0.1015 0.8213 ± 0.1046 0.099675\n",
            "      Decision Tree 0.8056 ± 0.1043 0.8435 ± 0.1014 0.8056 ± 0.1043 0.7984 ± 0.1053 0.103849\n",
            "  Gradient Boosting 0.7833 ± 0.0957 0.8315 ± 0.0815 0.7833 ± 0.0957 0.7819 ± 0.0876 0.090114\n",
            "                KNN 0.7778 ± 0.1478 0.8185 ± 0.1240 0.7778 ± 0.1478 0.7763 ± 0.1468 0.141588\n",
            "\n",
            "Statistical Significance Testing (p-values compared to best model):\n",
            "Random Forest: 0.5041\n",
            "Gradient Boosting: 0.2462\n",
            "SVM: 0.5327\n",
            "KNN: 0.3344\n",
            "Decision Tree: 0.3724\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACUI0lEQVR4nOzdeVxUZf//8fewg6KWIqJxi+YCiktikluWWW63pZW5ppJbJpliarimmVQqt5aWS66Z5YbllkuY+xpqZYH7ruCWooAgML8//DFfJ9FA4Yzg6/l4zKPmnOtc8znjAc685zrXMZnNZrMAAAAAAAAAA9nZugAAAAAAAAA8egilAAAAAAAAYDhCKQAAAAAAABiOUAoAAAAAAACGI5QCAAAAAACA4QilAAAAAAAAYDhCKQAAAAAAABiOUAoAAAAAAACGI5QCAAAAAACA4QilAABArjCZTPrwww+zvd3x48dlMpk0e/bsHK8JyKr7PX4BAEDWEUoBAJCPzZ49WyaTSSaTSVu2bLljvdlslre3t0wmk/773//aoML7t2HDBsu+/fPRtm1bS7tdu3bpnXfeUUBAgBwdHWUymbL1OikpKZo4caKeeuopFSpUSEWKFFHlypXVo0cPxcTE5PRuPTSOHDminj17qmzZsnJxcVGhQoVUt25dTZw4UUlJSbYuDwAA5AMOti4AAADkPhcXF82fP1/16tWzWr5x40adPn1azs7ONqrswfXp00dPP/201TIfHx/L/69atUpff/21qlatqrJly+rgwYPZ6v+1117TTz/9pHbt2ql79+66efOmYmJitGLFCtWpU0e+vr45sRsPlZUrV6p169ZydnZWp06d5O/vr5SUFG3ZskUDBgzQn3/+qWnTptm6zFyVlJQkBwdOlQEAyE38pQUA4BHQrFkzLVq0SJ9//rnVB+358+crICBAFy9etGF1D6Z+/fp6/fXX77q+V69eGjRokFxdXRUcHJytUGr37t1asWKFPv74Yw0ePNhq3aRJk3TlypX7LTvbbty4IScnJ9nZ5e5A92PHjqlt27YqXbq01q9fLy8vL8u63r176/Dhw1q5cmWu1mAr6enpSklJkYuLi1xcXGxdDgAA+R6X7wEA8Aho166dLl26pHXr1lmWpaSkaPHixWrfvn2m2yQkJKh///7y9vaWs7OzKlasqHHjxslsNlu1S05OVr9+/eTh4SF3d3e9/PLLOn36dKZ9njlzRm+99ZY8PT3l7OysypUra+bMmTm3o5nw9PSUq6vrfW175MgRSVLdunXvWGdvb6+iRYtaLTtz5oy6du2qkiVLytnZWWXKlFGvXr2UkpJiaXP06FG1bt1ajz/+uNzc3PTMM8/cEfJkXJr4/fffa+jQoSpVqpTc3NwUHx8vSdq5c6eaNGmiwoULy83NTQ0aNNDWrVut+rh27Zr69u0rHx8fOTs7q3jx4nrxxRe1Z8+ee+7zZ599puvXr2vGjBlWgVSGcuXK6b333rM8T01N1UcffaQnn3xSzs7O8vHx0eDBg5WcnGy1nY+Pj/773/9qw4YNqlmzplxdXVWlShVt2LBBkhQREaEqVarIxcVFAQEB2rt3r9X2Xbp0UcGCBXX06FE1btxYBQoUUMmSJTVq1Kg7jslx48apTp06Klq0qFxdXRUQEKDFixffsS8mk0nBwcH69ttvVblyZTk7O2v16tWWdbfPKZXV93PRokUKCAiQq6urihUrpo4dO+rMmTOZ7suZM2fUsmVLFSxYUB4eHnr//feVlpZ2l38ZAADyH0ZKAQDwCPDx8VHt2rX13XffqWnTppKkn376SVevXlXbtm31+eefW7U3m816+eWX9csvv6hr166qXr261qxZowEDBujMmTP63//+Z2nbrVs3zZs3T+3bt1edOnW0fv16NW/e/I4a4uLi9Mwzz1iCAA8PD/3000/q2rWr4uPj1bdv3/vat2vXrt0x0uvxxx/PkRFFpUuXliR9++23qlu37j0v5zp79qxq1aqlK1euqEePHvL19dWZM2e0ePFiJSYmysnJSXFxcapTp44SExPVp08fFS1aVHPmzNHLL7+sxYsXq1WrVlZ9fvTRR3JyctL777+v5ORkOTk5af369WratKkCAgI0YsQI2dnZadasWWrYsKE2b96sWrVqSZLefvttLV68WMHBwapUqZIuXbqkLVu2KDo6WjVq1Ljrfixfvlxly5ZVnTp1svQedevWTXPmzNHrr7+u/v37a+fOnQoLC1N0dLSWLl1q1fbw4cNq3769evbsqY4dO2rcuHFq0aKFpkyZosGDB+udd96RJIWFhemNN97QgQMHrP4d09LS1KRJEz3zzDP67LPPtHr1ao0YMUKpqakaNWqUpd3EiRP18ssvq0OHDkpJSdH333+v1q1ba8WKFXccm+vXr9fChQsVHBysYsWKWV36ebusvJ+zZ89WUFCQnn76aYWFhSkuLk4TJ07U1q1btXfvXhUpUsRqXxo3bqzAwECNGzdOP//8s8aPH68nn3xSvXr1ytJ7DwBAnmcGAAD51qxZs8ySzLt37zZPmjTJ7O7ubk5MTDSbzWZz69atzc8//7zZbDabS5cubW7evLllux9++MEsyTx69Gir/l5//XWzyWQyHz582Gw2m8379u0zSzK/8847Vu3at29vlmQeMWKEZVnXrl3NXl5e5osXL1q1bdu2rblw4cKWuo4dO2aWZJ41a9Y99+2XX34xS8r0cezYsUy36d27tzk7pz/p6enmBg0amCWZPT09ze3atTNPnjzZfOLEiTvadurUyWxnZ2fevXt3pv2YzWZz3759zZLMmzdvtqy7du2auUyZMmYfHx9zWlqa1b6VLVvW8r5k9FO+fHlz48aNLX2azWZzYmKiuUyZMuYXX3zRsqxw4cLm3r17Z3lfzWaz+erVq2ZJ5ldeeSVL7TP+/bt162a1/P333zdLMq9fv96yrHTp0mZJ5m3btlmWrVmzxizJ7OrqavWeTp061SzJ/Msvv1iWde7c2SzJ/O6771qWpaenm5s3b252cnIyX7hwwbL89vfMbDabU1JSzP7+/uaGDRtaLZdktrOzM//555937Ns/j99/ez9TUlLMxYsXN/v7+5uTkpIsy1esWGGWZB4+fPgd+zJq1CirPp566ilzQEDAXV8DAID8hsv3AAB4RLzxxhtKSkrSihUrdO3aNa1YseKul+6tWrVK9vb26tOnj9Xy/v37y2w266effrK0k3RHu3+OejKbzVqyZIlatGghs9msixcvWh6NGzfW1atX//WysrsZPny41q1bZ/UoUaLEffX1TyaTSWvWrNHo0aP12GOP6bvvvlPv3r1VunRptWnTxjKnVHp6un744Qe1aNFCNWvWzLQf6db7VatWLasJ5wsWLKgePXro+PHj+uuvv6y269y5s9Wlh/v27dOhQ4fUvn17Xbp0yfIeJiQk6IUXXtCmTZuUnp4uSSpSpIh27typs2fPZnl/My4PdHd3z1L7jH//kJAQq+X9+/eXpDsuS6xUqZJq165teR4YGChJatiwof7zn//csfzo0aN3vGZwcLDl/zNG3aWkpOjnn3+2LL/9Pfv777919epV1a9fP9NjrEGDBqpUqdK/7Om/v5+//vqrzp8/r3feecdqPqrmzZvL19c303m43n77bavn9evXz3SfAQDIr7h8DwCAR4SHh4caNWqk+fPnKzExUWlpaXedIPzEiRMqWbLkHeGEn5+fZX3Gf+3s7PTkk09atatYsaLV8wsXLujKlSuaNm3aXe/adv78+fvarypVqqhRo0b3tW1WODs7a8iQIRoyZIjOnTunjRs3auLEiVq4cKEcHR01b948XbhwQfHx8fL3979nXydOnLAELre7/X29vY8yZcpYtTt06JCkW2HV3Vy9elWPPfaYPvvsM3Xu3Fne3t4KCAhQs2bN1KlTJ5UtW/au2xYqVEjSrUsisyLj379cuXJWy0uUKKEiRYpYjpMMtwdPklS4cGFJkre3d6bL//77b6vldnZ2d9RfoUIFSdLx48cty1asWKHRo0dr3759VnNbZYSDt/vne3w3//Z+ZuzrP499SfL19dWWLVuslrm4uMjDw8Nq2WOPPXbHPgMAkJ8RSgEA8Ahp3769unfvrtjYWDVt2tRqjpvclDF6p2PHjncNVKpWrWpILQ/Cy8tLbdu21WuvvabKlStr4cKFmj17dq693j8naM94H8eOHavq1atnuk3BggUl3RoZV79+fS1dulRr167V2LFj9emnnyoiIsIyr9g/FSpUSCVLltT+/fuzVWdmYU9m7O3ts7Xc/I8JzLNi8+bNevnll/Xss8/qyy+/lJeXlxwdHTVr1izNnz//jvZZnQT/ft7Pe7nbPgMA8CghlAIA4BHSqlUr9ezZUzt27NCCBQvu2q506dL6+eefde3aNavRUjExMZb1Gf9NT0/XkSNHrEaIHDhwwKq/jDvzpaWl5eqoJqM4OjqqatWqOnTokC5evKjixYurUKFC/xrmlC5d+o73Rrrzfb2bjBFphQoVytL76OXlpXfeeUfvvPOOzp8/rxo1aujjjz++Z4jy3//+V9OmTdP27dutLrXLTMa//6FDhyyjvaRbk9pfuXLlX/cnu9LT03X06FHL6ChJOnjwoCRZJihfsmSJXFxctGbNGjk7O1vazZo164Ff/17vZ8a+HjhwQA0bNrTa7sCBAzn+XgAAkB8wpxQAAI+QggUL6quvvtKHH36oFi1a3LVds2bNlJaWpkmTJlkt/9///ieTyWQJNTL++8+7902YMMHqub29vV577TUtWbIk0+DmwoUL97M7ue7QoUM6efLkHcuvXLmi7du367HHHpOHh4fs7OzUsmVLLV++XL/++usd7TNG/DRr1ky7du3S9u3bLesSEhI0bdo0+fj4/OvcRgEBAXryySc1btw4Xb9+/Y71Ge9jWlqarl69arWuePHiKlmypNXlbJkZOHCgChQooG7duikuLu6O9UeOHNHEiRMt+yPd+e8dHh4uSZnehfFB3X5Mms1mTZo0SY6OjnrhhRck3TrWTCaT0tLSLO2OHz+uH3744b5fMyvvZ82aNVW8eHFNmTLF6j3+6aefFB0dnSvvBQAAeR0jpQAAeMTcaz6iDC1atNDzzz+vIUOG6Pjx46pWrZrWrl2rH3/8UX379rWM2KlevbratWunL7/8UlevXlWdOnUUGRmpw4cP39HnJ598ol9++UWBgYHq3r27KlWqpMuXL2vPnj36+eefdfny5RzfV+nWXD/ffPONJFkCo9GjR0u6NdLnzTffvOu2v/32m9q3b6+mTZuqfv36evzxx3XmzBnNmTNHZ8+e1YQJEyyXYY0ZM0Zr165VgwYN1KNHD/n5+encuXNatGiRtmzZoiJFiuiDDz7Qd999p6ZNm6pPnz56/PHHNWfOHB07dkxLliyRnd29vy+0s7PT119/raZNm6py5coKCgpSqVKldObMGf3yyy8qVKiQli9frmvXrumJJ57Q66+/rmrVqqlgwYL6+eeftXv3bo0fP/6er/Hkk09q/vz5atOmjfz8/NSpUyf5+/srJSVF27Zt06JFi9SlSxdJUrVq1dS5c2dNmzZNV65cUYMGDbRr1y7NmTNHLVu21PPPP5+lf6OscnFx0erVq9W5c2cFBgbqp59+0sqVKzV48GDL/EzNmzdXeHi4mjRpovbt2+v8+fOaPHmyypUrp99///2+Xjcr76ejo6M+/fRTBQUFqUGDBmrXrp3i4uI0ceJE+fj4qF+/fjn2PgAAkG/Y8tZ/AAAgd82aNcssybx79+57titdurS5efPmVsuuXbtm7tevn7lkyZJmR0dHc/ny5c1jx441p6enW7VLSkoy9+nTx1y0aFFzgQIFzC1atDCfOnXKLMk8YsQIq7ZxcXHm3r17m729vc2Ojo7mEiVKmF944QXztGnTLG2OHTtmlmSeNWvWPWv+5ZdfzJLMixYtylK7zB4NGjS457ZxcXHmTz75xNygQQOzl5eX2cHBwfzYY4+ZGzZsaF68ePEd7U+cOGHu1KmT2cPDw+zs7GwuW7asuXfv3ubk5GRLmyNHjphff/11c5EiRcwuLi7mWrVqmVesWJGtfdu7d6/51VdfNRctWtTs7OxsLl26tPmNN94wR0ZGms1mszk5Odk8YMAAc7Vq1czu7u7mAgUKmKtVq2b+8ssv77m/tzt48KC5e/fuZh8fH7OTk5PZ3d3dXLduXfMXX3xhvnHjhqXdzZs3zSNHjjSXKVPG7OjoaPb29jaHhoZatTGbMz/GzGazWZK5d+/eVssyjoGxY8dalnXu3NlcoEAB85EjR8wvvfSS2c3Nzezp6WkeMWKEOS0tzWr7GTNmmMuXL292dnY2+/r6mmfNmmUeMWKE+Z+nvpm99u3rMo7f7LyfCxYsMD/11FNmZ2dn8+OPP27u0KGD+fTp01ZtMvblnzKrEQCA/MxkNt/HDJIAAACAgbp06aLFixdnetkiAADIm5hTCgAAAAAAAIYjlAIAAAAAAIDhCKUAAAAAAABgOOaUAgAAAAAAgOEYKQUAAAAAAADDEUoBAAAAAADAcA62LuBhlJ6errNnz8rd3V0mk8nW5QAAAAAAAOQZZrNZ165dU8mSJWVnd/fxUIRSmTh79qy8vb1tXQYAAAAAAECederUKT3xxBN3XU8olQl3d3dJt968QoUK2bgaAAAAAACAvCM+Pl7e3t6WfOVuCKUykXHJXqFChQilAAAAAAAA7sO/TYnEROcAAAAAAAAwHKEUAAAAAAAADEcoBQAAAAAAAMMRSgEAAAAAAMBwhFIAAAAAAAAwHKEUAAAAAAAADEcoBQAAAAAAAMMRSgEAAAAAAMBwhFIAAAAAAAAwHKEUAAAAAAAADEcoBQAAAAAAAMMRSgEAAAAAAMBwhFIAAAAAAAAwnE1DqU2bNqlFixYqWbKkTCaTfvjhh3/dZsOGDapRo4acnZ1Vrlw5zZ49+442kydPlo+Pj1xcXBQYGKhdu3blfPEAAAAAAAC4bzYNpRISElStWjVNnjw5S+2PHTum5s2b6/nnn9e+ffvUt29fdevWTWvWrLG0WbBggUJCQjRixAjt2bNH1apVU+PGjXX+/Pnc2g0AAAAAAABkk8lsNpttXYQkmUwmLV26VC1btrxrm0GDBmnlypXav3+/ZVnbtm115coVrV69WpIUGBiop59+WpMmTZIkpaeny9vbW++++64++OCDLNUSHx+vwoUL6+rVqypUqND97xQAAAAAAMAjJqu5ioOBNT2w7du3q1GjRlbLGjdurL59+0qSUlJSFBUVpdDQUMt6Ozs7NWrUSNu3b79rv8nJyUpOTrY8j4+Pz9nCAQCwscTERMXExORa/0lJSTp+/Lh8fHzk6uqaK6/h6+srNze3XOkbeR/HOB4Whw4d0rVr13K834xjMC/LrZ8fd3d3lS9fPsf7BZD78lQoFRsbK09PT6tlnp6eio+PV1JSkv7++2+lpaVl2uZeJylhYWEaOXJkrtQMAMDDICYmRgEBAbYu44FERUWpRo0ati4DDymOcTwMDh06pAoVKti6jEfSwYMHCaaAPChPhVK5JTQ0VCEhIZbn8fHx8vb2tmFFAADkLF9fX0VFReVa/9HR0erYsaPmzZsnPz+/XHkNX1/fXOkX+QPHOB4GGSOkcuM4YaRU5jJ+NnNjdBqA3JenQqkSJUooLi7OallcXJwKFSokV1dX2dvby97ePtM2JUqUuGu/zs7OcnZ2zpWaAQB4GLi5uRkyAsPPz4+RHrAJjnE8THLrOKlbt26O9wkAtmTTu+9lV+3atRUZGWm1bN26dapdu7YkycnJSQEBAVZt0tPTFRkZaWkDAAAAAAAA27NpKHX9+nXt27dP+/btkyQdO3ZM+/bt08mTJyXduqyuU6dOlvZvv/22jh49qoEDByomJkZffvmlFi5cqH79+lnahISEaPr06ZozZ46io6PVq1cvJSQkKCgoyNB9AwAAAAAAwN3Z9PK9X3/9Vc8//7zleca8Tp07d9bs2bN17tw5S0AlSWXKlNHKlSvVr18/TZw4UU888YS+/vprNW7c2NKmTZs2unDhgoYPH67Y2FhVr15dq1evvmPycwAAAAAAANiOTUOp5557Tmaz+a7rZ8+enek2e/fuvWe/wcHBCg4OftDyAAAAAAAAkEvy1JxSAAAAAAAAyB8IpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhrN5KDV58mT5+PjIxcVFgYGB2rVr113b3rx5U6NGjdKTTz4pFxcXVatWTatXr7Zq8+GHH8pkMlk9fH19c3s3AAAAAAAAkA02DaUWLFigkJAQjRgxQnv27FG1atXUuHFjnT9/PtP2Q4cO1dSpU/XFF1/or7/+0ttvv61WrVpp7969Vu0qV66sc+fOWR5btmwxYncAAAAAAACQRTYNpcLDw9W9e3cFBQWpUqVKmjJlitzc3DRz5sxM23/zzTcaPHiwmjVrprJly6pXr15q1qyZxo8fb9XOwcFBJUqUsDyKFStmxO4AAAAAAAAgi2wWSqWkpCgqKkqNGjX6v2Ls7NSoUSNt3749022Sk5Pl4uJitczV1fWOkVCHDh1SyZIlVbZsWXXo0EEnT57M+R0AAAAAAADAfbNZKHXx4kWlpaXJ09PTarmnp6diY2Mz3aZx48YKDw/XoUOHlJ6ernXr1ikiIkLnzp2ztAkMDNTs2bO1evVqffXVVzp27Jjq16+va9eu3bWW5ORkxcfHWz0AAAAAAACQe2w+0Xl2TJw4UeXLl5evr6+cnJwUHBysoKAg2dn93240bdpUrVu3VtWqVdW4cWOtWrVKV65c0cKFC+/ab1hYmAoXLmx5eHt7G7E7AAAAAAAAjyybhVLFihWTvb294uLirJbHxcWpRIkSmW7j4eGhH374QQkJCTpx4oRiYmJUsGBBlS1b9q6vU6RIEVWoUEGHDx++a5vQ0FBdvXrV8jh16tT97RQAAAAAAACyxGahlJOTkwICAhQZGWlZlp6ersjISNWuXfue27q4uKhUqVJKTU3VkiVL9Morr9y17fXr13XkyBF5eXndtY2zs7MKFSpk9QAAAAAAAEDusenleyEhIZo+fbrmzJmj6Oho9erVSwkJCQoKCpIkderUSaGhoZb2O3fuVEREhI4eParNmzerSZMmSk9P18CBAy1t3n//fW3cuFHHjx/Xtm3b1KpVK9nb26tdu3aG7x8AAAAAAAAy52DLF2/Tpo0uXLig4cOHKzY2VtWrV9fq1astk5+fPHnSar6oGzduaOjQoTp69KgKFiyoZs2a6ZtvvlGRIkUsbU6fPq127drp0qVL8vDwUL169bRjxw55eHgYvXsAAAAAAAC4C5uGUpIUHBys4ODgTNdt2LDB6nmDBg30119/3bO/77//PqdKAwAAAAAAQC7JU3ffAwAAAAAAQP5AKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMJzNQ6nJkyfLx8dHLi4uCgwM1K5du+7a9ubNmxo1apSefPJJubi4qFq1alq9evUD9QkAAAAAAADj2TSUWrBggUJCQjRixAjt2bNH1apVU+PGjXX+/PlM2w8dOlRTp07VF198ob/++ktvv/22WrVqpb179953nwAAAAAAADCeTUOp8PBwde/eXUFBQapUqZKmTJkiNzc3zZw5M9P233zzjQYPHqxmzZqpbNmy6tWrl5o1a6bx48ffd58AAAAAAAAwns1CqZSUFEVFRalRo0b/V4ydnRo1aqTt27dnuk1ycrJcXFyslrm6umrLli333ScAAAAAAACMZ7NQ6uLFi0pLS5Onp6fVck9PT8XGxma6TePGjRUeHq5Dhw4pPT1d69atU0REhM6dO3fffUq3wq74+HirBwAAAAAAAHKPzSc6z46JEyeqfPny8vX1lZOTk4KDgxUUFCQ7uwfbjbCwMBUuXNjy8Pb2zqGKAQAAAAAAkBmbhVLFihWTvb294uLirJbHxcWpRIkSmW7j4eGhH374QQkJCTpx4oRiYmJUsGBBlS1b9r77lKTQ0FBdvXrV8jh16tQD7h0AAAAAAADuxWahlJOTkwICAhQZGWlZlp6ersjISNWuXfue27q4uKhUqVJKTU3VkiVL9MorrzxQn87OzipUqJDVAwAAAAAAALnHwZYvHhISos6dO6tmzZqqVauWJkyYoISEBAUFBUmSOnXqpFKlSiksLEyStHPnTp05c0bVq1fXmTNn9OGHHyo9PV0DBw7Mcp8AAAAAAACwPZuGUm3atNGFCxc0fPhwxcbGqnr16lq9erVlovKTJ09azRd148YNDR06VEePHlXBggXVrFkzffPNNypSpEiW+wQAAAAAAIDt2TSUkqTg4GAFBwdnum7Dhg1Wzxs0aKC//vrrgfoEAAAAAACA7eWpu+8BAAAAAAAgfyCUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYzuYTnSNvSExMVExMTK71n5SUpOPHj8vHx0eurq658hq+vr5yc3PLlb4BAAAAAPePz5yPJkIpZElMTIwCAgJsXcYDiYqKUo0aNWxdBgAAAADgH/jM+WgilEKW+Pr6KioqKtf6j46OVseOHTVv3jz5+fnlymv4+vrmSr8AAAAAgAfDZ85HE6EUssTNzc2QxNfPz49kGQAAAAAeMXzmfDQx0TkAAAAAAAAMRygFAAAAAAAAwxFKAQAAAAAAwHCEUgAAAAAAADAcE53nM4cOHdK1a9dsXUa2RUdHW/03L3F3d1f58uVtXQYeUGJiomJiYnKt/6SkJB0/flw+Pj5ydXXNldfw9fWVm5tbrvQN4/B73Hj8HjcWx7jxOMYBAA8rQql85NChQ6pQoYKty3ggHTt2tHUJ9+XgwYOc7OVxMTExCggIsHUZDyQqKoo7ieRx/B63HX6PG4Nj3HY4xgEADyNCqXwk41vHefPmyc/Pz8bVZI8Ro0hyQ3R0tDp27Jgnv/GFNV9fX0VFReVa/xnHSm7+fPr6+uZKvzAOv8eNx+9xY3GMG49jHADwMCOUyof8/Pzy5GiJunXr2roEPMLc3NwM+bnJqz+fMFZePU74PY6s4hgHgLyLy7CNl58vwyaUAgAAAAAA/4rLsG0nv16GTSgFAAAAAAD+FZdhGy+/X4ZNKAUAAAAAALKMy7CRU+xsXQAAAAAAAAAePYRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDOdi6AOQcU+oNPVXCTq5XDkpnyRuN4HrloJ4qYSdT6g1bl/LIOHTokK5du2brMrItOjra6r95ibu7u8qXL2/rMgAAeOhxPm48zseNxTFuvPx+jBNK5SMu109qT8+C0qae0iZbV/No8JO0p2dBRV8/KamOrcvJ9w4dOqQKFSrYuowH0rFjR1uXcF8OHjxIMAUAwL/gfNx4nI8bi2PcePn9GCeUykduFPyPaky9rm+//VZ+vr62LueREB0Tow4dOmhGs//YupRHQsYIqXnz5snPz8/G1WRPUlKSjh8/Lh8fH7m6utq6nCyLjo5Wx44d8+ToNAAAjMb5uPE4HzcWx7jx8vsxTiiVj5gdXLQ3Nl1JRSpIJavbupxHQlJsuvbGpsvs4GLrUh4pfn5+qlGjhq3LyLa6devaugQAAJCLOB83HufjxuIYN15+P8a5CBQAAAAAAACGI5QCAAAAAACA4QilAAAAAAAAYDhCKQAAAAAAABiOUAoAAAAAAACGI5QCAAAAAACA4QilAAAAAAAAYDhCKQAAAAAAABiOUAoAAAAAAACGI5QCAAAAAACA4WweSk2ePFk+Pj5ycXFRYGCgdu3adc/2EyZMUMWKFeXq6ipvb2/169dPN27csKz/8MMPZTKZrB6+vr65vRsAAAAAAADIBgdbvviCBQsUEhKiKVOmKDAwUBMmTFDjxo114MABFS9e/I728+fP1wcffKCZM2eqTp06OnjwoLp06SKTyaTw8HBLu8qVK+vnn3+2PHdwsOluAgAAAAAA4B9sOlIqPDxc3bt3V1BQkCpVqqQpU6bIzc1NM2fOzLT9tm3bVLduXbVv314+Pj566aWX1K5duztGVzk4OKhEiRKWR7FixYzYHQAAAAAAAGSRzUKplJQURUVFqVGjRv9XjJ2dGjVqpO3bt2e6TZ06dRQVFWUJoY4ePapVq1apWbNmVu0OHTqkkiVLqmzZsurQoYNOnjx5z1qSk5MVHx9v9QAAAAAAAEDusdl1bRcvXlRaWpo8PT2tlnt6eiomJibTbdq3b6+LFy+qXr16MpvNSk1N1dtvv63Bgwdb2gQGBmr27NmqWLGizp07p5EjR6p+/frav3+/3N3dM+03LCxMI0eOzLmdAwAAAAAAwD3ZfKLz7NiwYYPGjBmjL7/8Unv27FFERIRWrlypjz76yNKmadOmat26tapWrarGjRtr1apVunLlihYuXHjXfkNDQ3X16lXL49SpU0bsDgAAAAAAwCPLZiOlihUrJnt7e8XFxVktj4uLU4kSJTLdZtiwYXrzzTfVrVs3SVKVKlWUkJCgHj16aMiQIbKzuzNjK1KkiCpUqKDDhw/ftRZnZ2c5Ozs/wN4AAAAAAAAgO2w2UsrJyUkBAQGKjIy0LEtPT1dkZKRq166d6TaJiYl3BE/29vaSJLPZnOk2169f15EjR+Tl5ZVDlQMAAAAAAOBB2WyklCSFhISoc+fOqlmzpmrVqqUJEyYoISFBQUFBkqROnTqpVKlSCgsLkyS1aNFC4eHheuqppxQYGKjDhw9r2LBhatGihSWcev/999WiRQuVLl1aZ8+e1YgRI2Rvb6927drZbD8BAAAAAABgzaahVJs2bXThwgUNHz5csbGxql69ulavXm2Z/PzkyZNWI6OGDh0qk8mkoUOH6syZM/Lw8FCLFi308ccfW9qcPn1a7dq106VLl+Th4aF69eppx44d8vDwMHz/AAAAAAAAkDmbhlKSFBwcrODg4EzXbdiwweq5g4ODRowYoREjRty1v++//z4nywMAAAAAAEAuyFN33wMAAAAAAED+QCgFAAAAAAAAwxFKAQAAAAAAwHCEUgAAAAAAADAcoRQAAAAAAAAMRygFAAAAAAAAwxFKAQAAAAAAwHD3FUqlpqbq559/1tSpU3Xt2jVJ0tmzZ3X9+vUcLQ4AAAAAAAD5k0N2Nzhx4oSaNGmikydPKjk5WS+++KLc3d316aefKjk5WVOmTMmNOgEAAAAAAJCPZHuk1HvvvaeaNWvq77//lqurq2V5q1atFBkZmaPFAQAAAAAAIH/K9kipzZs3a9u2bXJycrJa7uPjozNnzuRYYQAAAAAAAMi/sj1SKj09XWlpaXcsP336tNzd3XOkKAAAAAAAAORv2Q6lXnrpJU2YMMHy3GQy6fr16xoxYoSaNWuWk7UBAAAAAAAgn8r25Xvjxo1TkyZNVKlSJd24cUPt27fXoUOHVKxYMX333Xe5USMAAAAAAADymWyHUt7e3vrtt9+0YMEC/fbbb7p+/bq6du2qDh06WE18DgAAAAAAANxNtkKpmzdvytfXVytWrFCHDh3UoUOH3KoLAAAAAAAA+Vi25pRydHTUjRs3cqsWAAAAAAAAPCKyPdF579699emnnyo1NTU36gEAAAAAAMAjINtzSu3evVuRkZFau3atqlSpogIFClitj4iIyLHiAAAAAAAAkD9lO5QqUqSIXnvttdyoBQAAAAAAAI+IbIdSs2bNyo06AAAAAAAA8AjJdiiV4cKFCzpw4IAkqWLFivLw8MixogAAAAAAAJC/ZXui84SEBL311lvy8vLSs88+q2effVYlS5ZU165dlZiYmBs1AgAAAAAAIJ/JdigVEhKijRs3avny5bpy5YquXLmiH3/8URs3blT//v1zo0YAAAAAAADkM9m+fG/JkiVavHixnnvuOcuyZs2aydXVVW+88Ya++uqrnKwPAAAAAAAA+VC2R0olJibK09PzjuXFixfn8j0AAAAAAABkSbZDqdq1a2vEiBG6ceOGZVlSUpJGjhyp2rVr52hxAAAAAAAAyJ+yffnexIkT1bhxYz3xxBOqVq2aJOm3336Ti4uL1qxZk+MFAgAAAAAAIP/Jdijl7++vQ4cO6dtvv1VMTIwkqV27durQoYNcXV1zvEAAAAAAAADkP9kOpSTJzc1N3bt3z+laAAAAAAAA8IjI9pxSYWFhmjlz5h3LZ86cqU8//TRHigIAAAAAAED+lu1QaurUqfL19b1jeeXKlTVlypQcKQoAAAAAAAD5W7ZDqdjYWHl5ed2x3MPDQ+fOncuRogAAAAAAAJC/ZTuU8vb21tatW+9YvnXrVpUsWTJHigIAAAAAAED+lu2Jzrt3766+ffvq5s2batiwoSQpMjJSAwcOVP/+/XO8QAAAAAAAAOQ/2Q6lBgwYoEuXLumdd95RSkqKJMnFxUWDBg1SaGhojhcIAAAAAACA/CfboZTJZNKnn36qYcOGKTo6Wq6uripfvrycnZ1zoz4AAAAAAADkQ9meUypDwYIF9fTTT8vd3V1HjhxRenp6TtYFAAAAAACAfCzLodTMmTMVHh5utaxHjx4qW7asqlSpIn9/f506dSrHCwQAAAAAAED+k+VQatq0aXrssccsz1evXq1Zs2Zp7ty52r17t4oUKaKRI0fmSpEAAAAAAADIX7IcSh06dEg1a9a0PP/xxx/1yiuvqEOHDqpRo4bGjBmjyMjIbBcwefJk+fj4yMXFRYGBgdq1a9c920+YMEEVK1aUq6urvL291a9fP924ceOB+gQAAAAAAICxshxKJSUlqVChQpbn27Zt07PPPmt5XrZsWcXGxmbrxRcsWKCQkBCNGDFCe/bsUbVq1dS4cWOdP38+0/bz58/XBx98oBEjRig6OlozZszQggULNHjw4PvuEwAAAAAAAMbLcihVunRpRUVFSZIuXryoP//8U3Xr1rWsj42NVeHChbP14uHh4erevbuCgoJUqVIlTZkyRW5ubpo5c2am7bdt26a6deuqffv28vHx0UsvvaR27dpZjYTKbp8AAAAAAAAwXpZDqc6dO6t379766KOP1Lp1a/n6+iogIMCyftu2bfL398/yC6ekpCgqKkqNGjX6v2Ls7NSoUSNt3749023q1KmjqKgoSwh19OhRrVq1Ss2aNbvvPgEAAAAAAGA8h6w2HDhwoBITExUREaESJUpo0aJFVuu3bt2qdu3aZfmFL168qLS0NHl6elot9/T0VExMTKbbtG/fXhcvXlS9evVkNpuVmpqqt99+23L53v30KUnJyclKTk62PI+Pj8/yfgAAAAAAACD7sjxSys7OTqNGjdLevXv1008/yc/Pz2r9okWL1LVr1xwv8HYbNmzQmDFj9OWXX2rPnj2KiIjQypUr9dFHHz1Qv2FhYSpcuLDl4e3tnUMVAwAAAAAAIDNZHimV04oVKyZ7e3vFxcVZLY+Li1OJEiUy3WbYsGF688031a1bN0lSlSpVlJCQoB49emjIkCH31ackhYaGKiQkxPI8Pj6eYAoAAAAAACAXZXmkVE5zcnJSQECAIiMjLcvS09MVGRmp2rVrZ7pNYmKi7OysS7a3t5ckmc3m++pTkpydnVWoUCGrBwAAAAAAAHKPzUZKSVJISIg6d+6smjVrqlatWpowYYISEhIUFBQkSerUqZNKlSqlsLAwSVKLFi0UHh6up556SoGBgTp8+LCGDRumFi1aWMKpf+sTAAAAAAAAtmfTUKpNmza6cOGChg8frtjYWFWvXl2rV6+2TFR+8uRJq5FRQ4cOlclk0tChQ3XmzBl5eHioRYsW+vjjj7PcJwAAAAAAAGzPpqGUJAUHBys4ODjTdRs2bLB67uDgoBEjRmjEiBH33ScAAAAAAABsL8fmlDp16pTeeuutnOoOAAAAAAAA+ViOhVKXL1/WnDlzcqo7AAAAAAAA5GNZvnxv2bJl91x/9OjRBy4GAAAAAAAAj4Ysh1ItW7aUyWSS2Wy+axuTyZQjRQEAAAAAACB/y/Lle15eXoqIiFB6enqmjz179uRmnQAAAAAAAMhHshxKBQQEKCoq6q7r/20UFQAAAAAAAJAhy5fvDRgwQAkJCXddX65cOf3yyy85UhQAAAAAAADytyyHUvXr17/n+gIFCqhBgwYPXBAAAAAAAADyvyxfvnf06FEuzwMAAAAAAECOyHIoVb58eV24cMHyvE2bNoqLi8uVogAAAAAAAJC/ZTmU+ucoqVWrVt1zjikAAAAAAADgbrIcSgEAAAAAAAA5JcuhlMlkkslkumMZAAAAAAAAkF1Zvvue2WxWly5d5OzsLEm6ceOG3n77bRUoUMCqXURERM5WCAAAAAAAgHwny6FU586drZ537Ngxx4sBAAAAAADAoyHLodSsWbNysw4AAAAAAAA8QrIcSgGArZlSb+ipEnZyvXJQOst9GozgeuWgniphJ1PqDVuXAgAAACCfIZQCkGe4XD+pPT0LSpt6SptsXc2jwU/Snp4FFX39pKQ6ti4HAAAAQD5CKAUgz7hR8D+qMfW6vv32W/n5+tq6nEdCdEyMOnTooBnN/mPrUgAAAADkM4RSAPIMs4OL9samK6lIBalkdVuX80hIik3X3th0mR1cbF0KAAAAgHyGSVkAAAAAAABgOEIpAAAAAAAAGI5QCgAAAAAAAIYjlAIAAAAAAIDhCKUAAAAAAABgOEIpAAAAAAAAGI5QCgAAAAAAAIYjlAIAAAAAAIDhCKUAAAAAAABgOEIpAAAAAAAAGI5QCgAAAAAAAIYjlAIAAAAAAIDhCKUAAAAAAABgOEIpAAAAAAAAGI5QCgAAAAAAAIYjlAIAAAAAAIDhCKUAAAAAAABgOEIpAAAAAAAAGI5QCgAAAAAAAIYjlAIAAAAAAIDhCKUAAAAAAABguIcilJo8ebJ8fHzk4uKiwMBA7dq1665tn3vuOZlMpjsezZs3t7Tp0qXLHeubNGlixK4AAAAAAAAgCxxsXcCCBQsUEhKiKVOmKDAwUBMmTFDjxo114MABFS9e/I72ERERSklJsTy/dOmSqlWrptatW1u1a9KkiWbNmmV57uzsnHs7AQAAAAAAgGyx+Uip8PBwde/eXUFBQapUqZKmTJkiNzc3zZw5M9P2jz/+uEqUKGF5rFu3Tm5ubneEUs7OzlbtHnvsMSN2BwAAAAAAAFlg05FSKSkpioqKUmhoqGWZnZ2dGjVqpO3bt2epjxkzZqht27YqUKCA1fINGzaoePHieuyxx9SwYUONHj1aRYsWzbSP5ORkJScnW57Hx8ffx97YXmJioiRpz549Nq4k+5KSknT8+HH5+PjI1dXV1uVkWXR0tK1LAJCPmFJv6KkSdnK9clA6a/PvjR4JrlcO6qkSdjKl3rB1KY8EjnHjcYwbi/Nx43E+DuRtNg2lLl68qLS0NHl6elot9/T0VExMzL9uv2vXLu3fv18zZsywWt6kSRO9+uqrKlOmjI4cOaLBgweradOm2r59u+zt7e/oJywsTCNHjnywnXkIZLxn3bt3t3Eljx53d3dblwAgH3C5flJ7ehaUNvWUNtm6mkeDn6Q9PQsq+vpJSXVsXU6+xzFuPI5xY3E+bjucjwN5k83nlHoQM2bMUJUqVVSrVi2r5W3btrX8f5UqVVS1alU9+eST2rBhg1544YU7+gkNDVVISIjleXx8vLy9vXOv8FzSsmVLSZKvr6/c3NxsW0w2RUdHq2PHjpo3b578/PxsXU62uLu7q3z58rYuA0A+cKPgf1Rj6nV9++238vP1tXU5j4TomBh16NBBM5r9x9alPBI4xo3HMW4szsdtg/NxIO+yaShVrFgx2dvbKy4uzmp5XFycSpQocc9tExIS9P3332vUqFH/+jply5ZVsWLFdPjw4UxDKWdn53wxEXqxYsXUrVs3W5fxQPz8/FSjRg1blwEANmF2cNHe2HQlFakglaxu63IeCUmx6dobmy6zg4utS3kkcIwbj2PcWJyPA0D22PRificnJwUEBCgyMtKyLD09XZGRkapdu/Y9t120aJGSk5PVsWPHf32d06dP69KlS/Ly8nrgmgEAAAAAAPDgbD7DZEhIiKZPn645c+YoOjpavXr1UkJCgoKCgiRJnTp1spoIPcOMGTPUsmXLOyYvv379ugYMGKAdO3bo+PHjioyM1CuvvKJy5cqpcePGhuwTAAAAAAAA7s3mc0q1adNGFy5c0PDhwxUbG6vq1atr9erVlsnPT548KTs76+zswIED2rJli9auXXtHf/b29vr99981Z84cXblyRSVLltRLL72kjz76KF9cogcAAAAAAJAf2DyUkqTg4GAFBwdnum7Dhg13LKtYsaLMZnOm7V1dXbVmzZqcLA8AAAAAAAA5zOaX7wEAAAAAAODR81CMlMLDLzExUTExMbnWf3R0tNV/c0NevDUvrCUmJkqS9uzZY+NKsi8pKUnHjx+Xj4+PXF1dbV1OluXmzyTuxDFuPI5xAHkF5+N4GHCuYrz8fq5CKIUsiYmJUUBAQK6/Tlbupni/oqKiuL1tHpdxIta9e3cbV/LocXd3t3UJjwSOcdvhGAfwsON8HA8DzlVsJ7+eqxBKIUt8fX0VFRWVa/0bkVr7+vrmSr8wTsuWLSXlzW/ZoqOj1bFjR82bN09+fn62Lidb3N3dVb58eVuX8UjgGLcNjnEAeQHn43gYcK5iG/n5XIVQClni5uaW699q1K1bN1f7R95XrFgxdevWzdZlPBA/Pz++IcRdcYwDAO6G83E8DDhXQU5jonMAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjrvvAQDwCEhMTFRMTEyu9R8dHW3139yQF28/DQAAgLsjlAIA4BEQExOjgICAXH+djh075lrfUVFR3MIZAAAgHyGUAgDgEeDr66uoqKhc6z8pKUnHjx+Xj4+PXF1dc+U1fH19c6VfAAAA2AahFAAAjwA3N7dcH2VUt27dXO0fAAAA+QsTnQMAAAAAAMBwhFIAAAAAAAAwHKEUAAAAAAAADEcoBQAAAAAAAMMRSgEAAAAAAMBwhFIAAAAAAAAwHKEUAAAAAAAADEcoBQAAAAAAAMMRSgEAAAAAAMBwhFIAAAAAAAAwHKEUAAAAAAAADEcoBQAAAAAAAMMRSgEAAAAAAMBwhFIAAAAAAAAwHKEUAAAAAAAADEcoBQAAAAAAAMMRSgEAAAAAAMBwhFIAAAAAAAAwHKEUAAAAAAAADEcoBQAAAAAAAMMRSgEAAAAAAMBwhFIAAAAAAAAwHKEUAAAAAAAADEcoBQAAAAAAAMMRSgEAAAAAAMBwhFIAAAAAAAAw3EMRSk2ePFk+Pj5ycXFRYGCgdu3adde2zz33nEwm0x2P5s2bW9qYzWYNHz5cXl5ecnV1VaNGjXTo0CEjdgUAAAAAAABZYPNQasGCBQoJCdGIESO0Z88eVatWTY0bN9b58+czbR8REaFz585ZHvv375e9vb1at25tafPZZ5/p888/15QpU7Rz504VKFBAjRs31o0bN4zaLQAAAAAAANyDzUOp8PBwde/eXUFBQapUqZKmTJkiNzc3zZw5M9P2jz/+uEqUKGF5rFu3Tm5ubpZQymw2a8KECRo6dKheeeUVVa1aVXPnztXZs2f1ww8/GLhnAAAAAAAAuBubhlIpKSmKiopSo0aNLMvs7OzUqFEjbd++PUt9zJgxQ23btlWBAgUkSceOHVNsbKxVn4ULF1ZgYGCW+wQAAAAAAEDucrDli1+8eFFpaWny9PS0Wu7p6amYmJh/3X7Xrl3av3+/ZsyYYVkWGxtr6eOffWas+6fk5GQlJydbnsfHx2d5HwAAAAAAAJB9Nr9870HMmDFDVapUUa1atR6on7CwMBUuXNjy8Pb2zqEKAQAAAAAAkBmbhlLFihWTvb294uLirJbHxcWpRIkS99w2ISFB33//vbp27Wq1PGO77PQZGhqqq1evWh6nTp3K7q4AAAAAAAAgG2waSjk5OSkgIECRkZGWZenp6YqMjFTt2rXvue2iRYuUnJysjh07Wi0vU6aMSpQoYdVnfHy8du7cedc+nZ2dVahQIasHAAAAAAAAco9N55SSpJCQEHXu3Fk1a9ZUrVq1NGHCBCUkJCgoKEiS1KlTJ5UqVUphYWFW282YMUMtW7ZU0aJFrZabTCb17dtXo0ePVvny5VWmTBkNGzZMJUuWVMuWLY3aLQAAAAAAANyDzUOpNm3a6MKFCxo+fLhiY2NVvXp1rV692jJR+cmTJ2VnZz2g68CBA9qyZYvWrl2baZ8DBw5UQkKCevTooStXrqhevXpavXq1XFxccn1/AAAAAAAA8O9sHkpJUnBwsIKDgzNdt2HDhjuWVaxYUWaz+a79mUwmjRo1SqNGjcqpEgEAAAAAAJCD8vTd9wAAAAAAAJA3EUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADDEUoBAAAAAADAcIRSAAAAAAAAMByhFAAAAAAAAAxHKAUAAAAAAADD2TyUmjx5snx8fOTi4qLAwEDt2rXrnu2vXLmi3r17y8vLS87OzqpQoYJWrVplWf/hhx/KZDJZPXx9fXN7NwAAAAAAAJANDrZ88QULFigkJERTpkxRYGCgJkyYoMaNG+vAgQMqXrz4He1TUlL04osvqnjx4lq8eLFKlSqlEydOqEiRIlbtKleurJ9//tny3MHBprsJAAAAAACAf7BpWhMeHq7u3bsrKChIkjRlyhStXLlSM2fO1AcffHBH+5kzZ+ry5cvatm2bHB0dJUk+Pj53tHNwcFCJEiVytXYAAAAAAADcP5tdvpeSkqKoqCg1atTo/4qxs1OjRo20ffv2TLdZtmyZateurd69e8vT01P+/v4aM2aM0tLSrNodOnRIJUuWVNmyZdWhQwedPHnynrUkJycrPj7e6gEAAAAAAIDcY7NQ6uLFi0pLS5Onp6fVck9PT8XGxma6zdGjR7V48WKlpaVp1apVGjZsmMaPH6/Ro0db2gQGBmr27NlavXq1vvrqKx07dkz169fXtWvX7lpLWFiYChcubHl4e3vnzE4CAAAAAAAgU3lqsqX09HQVL15c06ZNk729vQICAnTmzBmNHTtWI0aMkCQ1bdrU0r5q1aoKDAxU6dKltXDhQnXt2jXTfkNDQxUSEmJ5Hh8fTzAFAAAAAACQi2wWShUrVkz29vaKi4uzWh4XF3fX+aC8vLzk6Ogoe3t7yzI/Pz/FxsYqJSVFTk5Od2xTpEgRVahQQYcPH75rLc7OznJ2dr7PPQEAAAAAAEB22ezyPScnJwUEBCgyMtKyLD09XZGRkapdu3am29StW1eHDx9Wenq6ZdnBgwfl5eWVaSAlSdevX9eRI0fk5eWVszsAAAAAAACA+2azUEqSQkJCNH36dM2ZM0fR0dHq1auXEhISLHfj69Spk0JDQy3te/XqpcuXL+u9997TwYMHtXLlSo0ZM0a9e/e2tHn//fe1ceNGHT9+XNu2bVOrVq1kb2+vdu3aGb5/AAAAAAAAyJxN55Rq06aNLly4oOHDhys2NlbVq1fX6tWrLZOfnzx5UnZ2/5ebeXt7a82aNerXr5+qVq2qUqVK6b333tOgQYMsbU6fPq127drp0qVL8vDwUL169bRjxw55eHgYvn8AAAAAAADInM0nOg8ODlZwcHCm6zZs2HDHstq1a2vHjh137e/777/PqdIAAAAAAACQS2x6+R4AAAAAAAAeTTYfKQUAD4PExETFxMTkWv/R0dFW/80Nvr6+cnNzy7X+AQAAACAnEUoBgKSYmBgFBATk+ut07Ngx1/qOiopSjRo1cq1/AAAAAMhJhFIAoFujjKKionKt/6SkJB0/flw+Pj5ydXXNldfw9fXNlX4BAAAAIDcQSgGAJDc3t1wfZVS3bt1c7R8AAAAA8hImOgcAAAAAAIDhCKUAAAAAAABgOEIpAAAAAAAAGI5QCgAAAAAAAIZjonMAAAAYIjExUZK0Z88eG1eSfUbcRTU3REdH27oEAADuilAKAAAAhoiJiZEkde/e3caVPHrc3d1tXQIAAHcglAIAAIAhWrZsKUny9fWVm5ubbYvJpujoaHXs2FHz5s2Tn5+frcvJFnd3d5UvX97WZQAAcAdCKQAAABiiWLFi6tatm63LeCB+fn6qUaOGrcsAACBfYKJzAAAAAAAAGI5QCgAAAAAAAIYjlAIAAAAAAIDhCKUAAAAAAABgOEIpAAAAAAAAGI5QCgAAAAAAAIYjlAIAAAAAAIDhCKUAAAAAAABgOEIpAAAAAAAAGI5QCgAAAAAAAIYjlAIAAAAAAIDhCKUAAAAAAABgOEIpAAAAAAAAGI5QCgAAAAAAAIZzsHUBAAAAwINKTExUTExMrvUfHR1t9d/c4OvrKzc3t1zrHwAeZvwefzSZzGaz2dZFPGzi4+NVuHBhXb16VYUKFbJ1OQAAAPgXe/bsUUBAgK3LeCBRUVGqUaOGrcsAAJvg93j+ktVchZFSAAAAyPN8fX0VFRWVa/0nJSXp+PHj8vHxkaura668hq+vb670CwB5Ab/HH02MlMoEI6UAAAAAAADuT1ZzFSY6BwAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOFsHkpNnjxZPj4+cnFxUWBgoHbt2nXP9leuXFHv3r3l5eUlZ2dnVahQQatWrXqgPgEAAAAAAGAsm4ZSCxYsUEhIiEaMGKE9e/aoWrVqaty4sc6fP59p+5SUFL344os6fvy4Fi9erAMHDmj69OkqVarUffcJAAAAAAAA45nMZrPZVi8eGBiop59+WpMmTZIkpaeny9vbW++++64++OCDO9pPmTJFY8eOVUxMjBwdHXOkz8zEx8ercOHCunr1qgoVKnSfewcAAAAAAPDoyWquYrORUikpKYqKilKjRo3+rxg7OzVq1Ejbt2/PdJtly5apdu3a6t27tzw9PeXv768xY8YoLS3tvvsEAAAAAACA8Rxs9cIXL15UWlqaPD09rZZ7enoqJiYm022OHj2q9evXq0OHDlq1apUOHz6sd955Rzdv3tSIESPuq09JSk5OVnJysuV5fHz8A+wZAAAAAAAA/o3NJzrPjvT0dBUvXlzTpk1TQECA2rRpoyFDhmjKlCkP1G9YWJgKFy5seXh7e+dQxQAAAAAAAMiMzUZKFStWTPb29oqLi7NaHhcXpxIlSmS6jZeXlxwdHWVvb29Z5ufnp9jYWKWkpNxXn5IUGhqqkJAQy/OrV6/qP//5DyOmAAAAAAAAsikjT/m3acxtFko5OTkpICBAkZGRatmypaRbI6EiIyMVHByc6TZ169bV/PnzlZ6eLju7W4O8Dh48KC8vLzk5OUlStvuUJGdnZzk7O1ueZ7x5jJgCAAAAAAC4P9euXVPhwoXvut5moZQkhYSEqHPnzqpZs6Zq1aqlCRMmKCEhQUFBQZKkTp06qVSpUgoLC5Mk9erVS5MmTdJ7772nd999V4cOHdKYMWPUp0+fLPeZFSVLltSpU6fk7u4uk8mUszuNTMXHx8vb21unTp3ijofIlzjGkd9xjCO/4xhHfscxjvyOY9xYZrNZ165dU8mSJe/ZzqahVJs2bXThwgUNHz5csbGxql69ulavXm2ZqPzkyZOWEVHSrZFLa9asUb9+/VS1alWVKlVK7733ngYNGpTlPrPCzs5OTzzxRM7tKLKsUKFC/IJAvsYxjvyOYxz5Hcc48juOceR3HOPGudcIqQwm879d4AcYID4+XoULF9bVq1f5BYF8iWMc+R3HOPI7jnHkdxzjyO84xh9OeeruewAAAAAAAMgfCKXwUHB2dtaIESOsJpwH8hOOceR3HOPI7zjGkd9xjCO/4xh/OHH5HgAAAAAAAAzHSCkAAAAAAAAYjlAKAAAAAAAAhiOUAgAAAAAAgOEIpQAAAAAAAGA4QikAAJCr0tPTbV0CAAAAHkKEUngkZfYB6dq1azaoBLAtwgLkphMnTuj48eOys7PjWEO+xs2sAWPxMwfkH4RSeCTZ2dnpxIkTmjBhgiRp0aJF6tSpk65evWrbwgCD2dnd+jOwY8cOnT171sbVID85efKkypQpowYNGujgwYMEU8h3zp07p0OHDkmSTCaTjasB8rd//v3gZw4Ps4zQNC0tTTdu3LBxNQ8/Qik8klJTU/XVV19p1qxZ6ty5s9q0aaNXXnlFhQsXtnVpgCFuP7lbv369mjVrprlz5+rChQs2rAr5yaFDh/T444+rUKFCatmypfbv308whXzjxo0beu655xQSEqIDBw7YuhwgXzObzZYv0aZPn66+fftq3LhxiomJsXFlwJ3MZrNMJpNWrVqlzp07q2bNmho6dKiWL19u69IeWoRSeCQ5ODhoxIgRKl26tL755hu98cYb6tKli6RbiTaQn91+cvfFF1/o119/VXJysj777DPNmDGDYAo5wt/fX0888YQqV66sOnXq6I033tBff/1FMIV8wcXFRdOmTVNUVJRGjRrFh2Mgl6Snp1tGRYWGhmrw4MH6448/NG/ePLVr1047duywcYWANZPJpGXLlql169by8fFRSEiINm3apIEDB2rfvn22Lu+hRCiFR07GcEonJycVKVJEL774ok6fPq2wsDBJkr29PcEU8rWMk7tRo0Zp2LBhqlChgr7//nu98cYb+uyzzzRz5kxdvHjRxlUir0pPT5fZbJanp6cGDx6sI0eOqH79+ipfvrxat25NMIU8Lz09Xenp6WrQoIEWL16stWvX6qOPPiKYAnJBxpdohw4dUnx8vNasWaPIyEhNnjxZFSpUUMeOHQmm8FC5ePGixo0bpzFjxmj06NFq3769oqOj1axZM1WvXt3W5T2UCKXwSMkYThkVFaUzZ85ozpw5WrBggZ566in9+OOPVsGUJD6YI9+6evWqfvzxRw0bNkwtW7ZUixYtNGXKFHXv3l2jRo3S119/rfPnz9u6TOQhJ0+etAROGcGnv7+/ihcvrlKlSmn06NHy9va2Cqb4AgB5yalTp/TXX38pNTXV8kG5Tp06WrJkidauXauRI0cSTAG5YNGiRXrxxRe1e/duPfHEE5KkunXrasCAAapRo4befPNNgik8NFxcXJSYmKjmzZvr2LFjKleunFq1aqXx48dLkn7++WcdO3bMxlU+XAil8MjICKSWLl2qZs2a6YsvvtClS5dUpEgRDRkyRE8//bSWLVumMWPGSJKGDx+uXr16KTk52caVAzkr4/K9tLQ0ywerjEkYP/30UzVo0ECTJk3SN998oytXrtiwUuQVJ06cULly5VS9enWFhYVpzpw5kqRKlSrJ399fgwcPVpUqVTRq1Cj5+PioXbt2+uOPPyxfAAAPu9OnT6tMmTLy9/dXhw4d1Lt3b+3YsUMXLlzQs88+axm9MXr0aP3555+2LhfIV+zs7FSxYkXFxMRYnZfUrFlTAwcOVM2aNfXiiy/yswebybgSx2w26+rVq0pKStLWrVv10ksvqWnTpvrqq68kSUePHtXMmTMtN8nALYRSeGSYTCb99NNP6tChg8LCwjRo0CAVK1ZMklSiRAkNGzZM9erV08yZM1WpUiVNnjxZ77//vpydnW1cOfBgMrtjjbu7uypWrKjp06dLuvWtzs2bNyVJpUuXloeHh8aNG6fNmzdL4tbLuLfDhw+rfPnyMplMOn/+vKZNm6aGDRtq6dKlat++vcqUKaPIyEjVqlVLgwcPVuHChdWjRw+lpKRwbOGhlnF8XrlyRbVq1ZIklS9fXr/99ps6deqkKlWqqG/fvrp06ZJmzZqlVatWaerUqfrtt99sWTaQZ2V2afdrr72m/v37y9/fXx07drQakVizZk29++676tevn3x9fY0sFbD8jcgYxJCenq5SpUqpVatWCgoKUqVKlTR9+nTLl3AzZszQ/v375efnZ7OaH0YmM2eDeESkpKSoR48eKl68uD777DMlJCTo5MmTmjdvnsqUKaPmzZvL3d1d27dv14EDB9SkSROVK1fO1mUDDyQ9Pd0yGmrnzp1ydnZWkSJF5OPjo1OnTumFF16Qp6enfv75Zzk4OMje3l5vvPGGBg4cqHHjxmn//v3av3+/jfcCD6uDBw9qyZIlCg0N1apVqzRy5Ei5uLgoIiJC48eP1/79+7Vr1y7Fx8crKChIkydPlnTrWCxZsqS8vb1tvAfAvd24ccMS2kdHR6tnz55KT0/XL7/8osuXL2vRokXasWOHVq1apeeee05r1qxRamqqgoODNW7cODk5Odl6F4A84/Zzlo0bNyo5OVmpqalq1qyZpFuXPY0dO1bXrl3TrFmzVLFixTv6SEtLYxQuDJFxFc7atWs1Y8YMXbt2Ta6urpo8ebIcHBw0cOBAffvttxo3bpxu3rypI0eO6JtvvtHmzZtVrVo1W5f/UCGUwiPj5s2bevHFF1W8eHF98cUXGjZsmA4dOqSzZ8/q6tWratu2rSZMmGDrMoEck/HHUpIGDBigBQsW6MqVK6pbt67at2+vN998U9u2bVO3bt109epV+fv769y5c0pMTNThw4c1ceJEffPNN9q1a5flJBHIkJ6ers8++0xffPGFdu/eraJFi2rt2rXq37+/qlatqsWLF0uSvvzyS3377bfq0aOHOnfubOOqgayLjY1VjRo19N1336lBgwZKTU1VdHS02rRpI1dXV23YsEHu7u5KTU3V5cuXtXnzZm3atEmbN2/WvHnzVKlSJVvvApAnDRgwQPPnz5eLi4vOnTunZ599VmFhYXrqqae0du1ahYeHKyEhQVOmTFHlypVtXS4eYT/++KPat2+vfv36qVy5cpo0aZJiY2O1c+dOmc1mff3111q4cKHc3d3l4+OjYcOGyd/f39ZlP3QIpZBv3f6BPMPKlSvVsWNHpaam6qWXXtLrr7+udu3a6ZNPPtEPP/ygDRs2yMXFxUYVAzkj4/bJGcf/li1b1L17d82YMUMXL15URESEfv/9d/Xu3Vtdu3ZVUlKSPvvsM12/fl0uLi4aPny4HB0d9dZbb+nixYtatGiRnJyc7vh5Anbt2qVGjRpp0qRJ6tSpk27cuKGff/5Z/fr1U5kyZbR27VpJ0qVLl1S0aFEbVwtkz9mzZ9WrVy+tX79ea9asUZ06dZSWlqa//vpLHTp0kCRt3bpV7u7uVtslJCSoQIECtigZyPOmT5+uIUOG6KefflLx4sWVkJCgVq1aycPDQ7NmzdKTTz6plStX6sMPP1RAQICmTJli65LxiLpy5YpefvlltWjRQgMGDNCZM2dUr149NWrUyDI9hiSdP39exYsXt4y8xZ0IpZAvZQRSW7du1ebNm3XhwgU1atRITZs21dmzZ3X06FHVq1fP0u69997TuXPnNHfuXH5ZIF9ZsmSJVq1apSeeeEIjR46UJB04cEATJ07U9u3b1bNnT7399ttW28TFxWnMmDGaN2+eNm3axLeQuKfg4GBt2LBB69atk5eXl1JSUrRu3Tr1799fpUqVUmRkpCQpNTVVDg4ONq4WyJ7Tp08rNDRUixYt0vr16y3BVHR0tDp06CCTyaTNmzfL3d1dN2/elKOjY6ZfigG407Jly/TCCy9Yhbjvvfee4uLi9P3331suxTt//rxq1qyp559/3nIjjR07dqhWrVqM5IZhMmITk8mktLQ03bhxQ/7+/tq6dascHBxUo0YNNW/eXFOnTpUkzZ8/X6+//rrlMm7+NtwdP8XIl0wmkyIiIvTKK69o27ZtunLlipo3b67Q0FAVLVpU9erVkyT98ccfGjx4sObMmaOhQ4cSSCFP69Kli4YOHSrp1mipU6dOadq0aVq6dKnOnj1raVexYkW99957ql27tmbMmKGxY8da1p05c0YLFy7Utm3bFBkZSSCFTN0+EW2zZs1048YNy8TOTk5OeumllzR+/HidP39egYGBkkQghTwhMTFRSUlJludPPPGERo8erddee00NGzbU1q1bZW9vLz8/P3377beyt7eXv7+/rl+/LkdHR0niQweQBWFhYZo+fbrc3Nwsy9LT03X27FnFx8dLkuzt7XXjxg3LfLCRkZE6deqUJOmZZ56RnZ1dphOjAzkls5sFLVu2TKNGjZKjo6MqVKigefPm6emnn1aLFi00adIkSbcu/164cKFWrVpltS0yRyiFfOnAgQMKCQnRmDFjtGzZMn3++eeWD0QZd9P77bffNH78eC1fvlwbN25U1apVbVky8EBu3LihZs2aacSIEZJu3T7Z29tbH374oZ577jmtXbvWMsePdCuY6tu3r8qXL6+//vrL8u1PqVKl9Prrr2vNmjWqXr26LXYFD6nY2Fjt27dPkqy+mW7WrJm8vb316aefWpY5OjrqpZde0siRI2U2m3Xy5EmjywWy7dChQ3r++efVunVrLVu2TFu3bpV0646kkydP1quvvqqGDRtqy5YtlmBqxowZ8vb21vnz521cPZC3hIaGaunSpTKZTNq7d6+uXLkiOzs7vfnmm9qwYYPmzp0rSZYvjM1mszw8PFSoUCGrfhgphdySMfH+H3/8oVWrVslkMmnfvn3q2bOnypQpo7S0NJUrV06jR4+Wv7+/vvrqK8uXExMnTtTRo0dVs2ZNG+9F3sDle8iXdu3apQEDBmjjxo06cuSIGjRoYDWc8tSpU/L29tavv/4qLy8vlSpVysYVA/fvn8OBp06dqlWrVumHH36QyWTSjh07NG7cOF26dEl9+vRRq1atLG1PnTqlUqVKWb5t5OQOmYmPj1eNGjVkZ2enwMBAhYaGytvb2zKXzpo1a/TOO+9o8uTJatKkieVYunnzplJSUphfBw+9y5cva+TIkfriiy8sgdPff/+tihUr6umnn9Zbb72la9euac6cOZo6daq2bt2qgIAApaWlKS0tjbvsAdlw+x3yli9fri5duujjjz9Whw4dZG9vryFDhujHH39UaGioOnTooKtXr6p79+6WUSqMOEFuyziP+e2331SzZk199dVXevbZZ7Vs2TKdPXtW4eHhkm5NefHGG28oOTlZDRs2VPny5bVt2zYtWrRIGzdu5C57WUQohXzh9ltyFilSRGlpaerQoYO+++47tWvXTi+++KK+/PJL2dvba+PGjRo7dqymTp1KGIV84Z9h0qRJkzR16lQFBARo1qxZMplM2rJliyZMmKCLFy+qb9++atmy5T37ADIcP35cv/32m86dOyd7e3uNGzdOaWlpKl++vIYMGaLq1avLwcFBzzzzjJ599ll9/vnnkpg7AXlHTEyMBg8erH79+mnevHmKjY1VpUqV1KFDB82YMUNbt27VmTNn9Nhjj8nf319r1qzR1atXtW/fPkZZA9mU2flGp06dtHv3boWEhKhLly6Ki4vTl19+qfDwcHl4eMjV1VXu7u7asWOHHB0dOWdBrrp9hFRgYKD69eun0aNHy9fXV4cOHVLLli0VERFhaX/mzBl98skn2rFjh9LT01WmTBl9+OGH3GUvGwilkG9s2bJFTZo00VdffaWmTZsqKChI69ev1yuvvKL58+dbPiCFhoZq586dWrhwoYoVK2brsoEHsm3bNnl7e8vb21shISGqWLGiOnfurNmzZ2vatGmqXLmy5s6da5n4f+LEifrzzz8t3/gA9/LHH3/o1VdfVeXKldWnTx81bNhQaWlpmjJlitauXatVq1apUaNG6ty5s1JSUtSnTx++GUSeM2vWLE2dOlU7duxQTEyMxo4dqz///FN9+/ZV27ZtJUmRkZE6ceKEZs2apTNnzuj48eOKjo5WxYoVbVw9kHfcHiYtWrRIhQoVUuPGjSVJ3bp104YNG/TBBx/ozTfflLOzs2JiYrRv3z5LO3t7e26agVyVcYzGxMRY7qT3/fffS5L279+vLl266OrVq5o8ebJeeukly3ZpaWkym826efOm7O3tGT2bTYRSyBdOnDihqVOnqmDBgho8eLAkadq0aZo4caKefvppDRgwQElJSVq4cKGmT5+uTZs2qUqVKjauGrh/6enp+vvvv+Xh4aHWrVvL3d1dixcv1qZNm1S1alUlJiZqzpw5mj59ulUwtX79eq1fv14jR460DJ0HMhMTE6M6deqoZ8+eevfdd1WyZMk72ixZskRr167VvHnzVLx4cZ04cULjxo1T3759+RYbeUZYWJiWLFminTt3yt7eXkeOHNGYMWP0559/qmPHjgoODra0TUpKUkpKihITE+Xl5WXDqoG85fbRs4MGDdKSJUv09ttv680335Snp6ckKSgoSJs3b9agQYP0+uuv67HHHrPq4/bL/oCclhFI7du3T3Xq1JG9vb1KliypadOmKTAwUC4uLoqOjtbrr7+uMmXKKDQ0VHXr1rXaFveHUAp5XkxMjN566y2dPXtWgwYNUq9evSzrxo8frxUrVlhCKHt7e82YMYMJnJFvnDx5Ur6+vjKbzVq6dKmaNGliOfHLCKa+/vprValSxXIpXwZO7nA3N27cUKdOnVS8eHHLnWQk6ebNm4qNjVVCQoJ8fX0l3bpbWVxcnMaNG6d9+/Zp1qxZqlChgq1KB7Lkxo0blgmUP/roI23atEnr1q2zfLDICKaio6PVsWNHvfPOO5LEKA3gAX3yySeW8/OMu7Pernv37tq8ebPefvtt9ejRw+rufEBu+/3331WjRg2NHDlSQ4YMUb169XTmzBnNnj1btWvXlpOTk/bv36833nhDTz75pEJDQ1WnTh1bl53nEechz/P19VWtWrUUHx9vmechQ//+/bVs2TJt27ZNy5Yt09q1awmkkOdl3J42NTVV8fHxljtKfvPNNzp27JgleHJzc1OnTp3UvXt3rVmzRqNHj5Yky532CKRwNw4ODoqNjbUET9KtycwHDhwof39/NWvWTA0bNpTZbJabm5vKlCmjCRMmaN26dQRSeOidOXNGnTp10rp16yTdCuiLFi0q6dbvx/T0dD355JMaNGiQ/Pz89O2332r8+PGSRCAF3Cez2azLly9r/fr1Gjt2rAIDA3X8+HGtWrVKb7zxhvr376/U1FRNnz5dfn5+2rFjh1xdXW1dNh4hiYmJGjFihAYPHqwhQ4ZIujU9TKlSpdSlSxdt375dKSkp8vf318KFC3Xy5El98MEH2rlzp40rz/sYKYU8526T5w4aNEgrVqxQmzZt1KdPHxUpUsT44oBcdvvw4D179qhGjRqSpAMHDqhGjRpq3ry5PvvsM/n4+Fhtt2LFCjVt2pQgClkSHx+vwMBA1a9fX/3791dERITmzJkjf39/PfvssypYsKDCwsL08ssva/z48QxbR55y9OhRdezYUUWKFNHo0aO1ePFinT592nIL+tslJCSoQ4cOSk9P15w5c+64nAjA3WX2t6Fhw4Zyd3dXz5499dVXX+nvv/9WyZIltXr1arVp00bTp0+32pabZsBIJ0+e1H/+8x9Jt0aHOzo6SlKmI6b27dunt99+W4sWLZK3t7cty87zCKWQp2T8Ydq5c6e2bt0qJycnlSlTRs2bN5d0a2TUhg0b1LJlS7377rsqUqQIf8yQb9x+cjd06FCtX79evXv3VsuWLVWgQAHt3btX9erV08svv6yPPvpI5cqV0yuvvKJXX31VnTt3lsQle8i69evXq3HjxipVqpQuX76ssWPH6oUXXlC5cuV08+ZN/fe//5WXl5dmz55t61KBbDt8+LCCg4NVoEABnThxQmazWf7+/rKzs5OdnZ2Sk5NlMpnk6uqqc+fO6auvvtITTzxh67KBPOP2c5bly5erUKFCatCggb755htNmzZNe/bsUd++fdWkSRPVr19fo0aN0p9//qm5c+daRoDzhQeMcrfPi7dfsp0RTM2dO1e1atWSs7OzUlJSmNQ8BxBKIc/I+GWxZMkSBQUFqXr16rpy5Yqio6P17rvvKjw8XJLUr18/bd++Xc8995xCQ0NVuHBhG1cO5KwhQ4Zo2rRp+u6771SzZk2r8PXXX39Vo0aN5Ovra5mQ9/fff7d80wNkx6lTp3T+/HmVLl3a6m6l6enpatu2rSpWrKhRo0ZJEuE/8pwDBw6oX79+2rx5s5ydndW6dWsdPXpUJpNJBQsW1M2bN5WSkqLx48erUqVKti4XyDP+Oan50qVL1bdvX3Xp0sVyB724uDiVLVvWss3zzz+vqlWrauLEibYqG8jU7cHU888/rz179uinn35SnTp1GPyQQwil8NDK7NuRw4cP69lnn9WwYcPUq1cv/f3331q7dq3eeust9erVS+PGjZMk9ezZUwcPHtSiRYusPkgBed2+ffvUrl07ff3116pbt66uXLmic+fOad26dapTp45q1qyp/fv3a9GiRXJwcFBoaKgcHByYnBc5JiUlRR999JFmzpypDRs2qHz58rYuCbhvhw8fVt++fS3hE3fmBXJOWFiY/ve//2np0qWqXbv2Hef1165d0969ezVmzBidO3dOUVFRnKvgoXT7eXTTpk31xRdfqFy5cjauKv8glMJDKSOQ+uOPP3T27Fk1btxYkrRz50516tRJkZGRVsPo58+fr27dumnFihVq2LChJOn8+fMqXry4TeoHcsvhw4f10ksvaeLEiSpdurSmTJmiyMhImc1mHT58WDt27FCtWrWsQl0CKeSUefPmaffu3VqwYIF++uknPfXUU7YuCXhgBw8eVJ8+fSTdGolav359yzq+BQfuz8WLF/Xqq6+qW7du6tSpk06ePKkDBw7ou+++U8mSJTV69GhFRkZqzpw5+vvvvxURESFHR0fOWWBT9/qdz7GZe7hIFw+djA/Tv//+u6pVq6Zdu3ZZ1rm5uenIkSM6ePCgpP+7i9hzzz0nLy8vnTt3ztKWQAp5XcZd9m7n5OSkp556SoMGDVJgYKBMJpPGjBmjX3/9VU899ZQ2btwoSVbfRvIHFDnhwIEDmjFjhk6dOqVffvmFQAr5RoUKFfTFF1/I0dFRAwcOtLqTEoEUcH8KFy4sR0dHrV+/XsuXL9d7772nDz/8UOfPn9fEiRPVv39/vfDCCxowYIB+/PFHAikYKuMz5KFDhxQTE6OjR49KuvU7P7Pzb4nz6dzEO4uHSkYgtW/fPtWpU0eDBw/WsGHDLOt9fX3VtGlTTZ48WUWKFLHceaxYsWJ6/PHHdfPmTVuVDuSo20c67du3T5cvX5afn5/+85//aMqUKdqzZ4/c3NxUt25dy6S89vb28vDwsHHlyK8qVqyoBQsWyNnZmbn6kO+UL19eY8eO1bBhw+Tl5WXrcoA8JbMpNxwdHfXyyy9r0aJFat26tfr166d+/frp2Wef1fvvv68LFy5IkuWS2fT0dD70wzAmk0mLFy9Wv379lJqaKh8fH7Vr1059+vSRnZ0dk+wbjMv38NA5cOCAqlWrpuHDh2vw4MGW5StWrNBzzz2nyMhIhYeHq3DhwurRo4fKlCmjuXPnatasWdq1a5d8fHxsVzyQA24fOvzBBx/ou+++U2JiohwdHdWgQQOFhoaqatWqkqSkpCSdPXtWffr0UVxcnHbs2MFJHQDcJ+6kBGTP7R/eZ8+erX379iktLU3169fXG2+8oevXrys2NtZq/p3nnntOAQEBGj9+vK3KxiMq4xw7NjZWzz33nAYOHKjixYtr06ZNWrhwobp166ahQ4dK4u6PRuKTCx4qN27c0IcffqiCBQuqdu3aluUff/yxpkyZonXr1umVV15Renq6vvvuO7Vs2VIVKlRQamqq1qxZQyCFfCEjkPryyy81Y8YMff/996pcubJWrlypiIgI9e3bV59//rn8/f01Z84cLV++XPHx8dq+fbscHByUlpYme3t7G+8FAOQ9BFJA9mR8aB84cKC++eYbtW3bVqmpqerZs6e2bt2qiRMnqly5ckpISNCff/6pYcOG6e+//9ann35q48rxKDKZTNq+fbsiIiLUsGFDderUSQ4ODgoICFDhwoU1ZcoUSdLQoUMZMWUgQik8VFxcXNSjRw/L3Z0KFiyoHTt2KDw8XN9++618fX0lSa1atdJ///tfHT9+XGlpaSpatCiXLSHfMJvNSk9P19atW9WhQwe98MILkqSuXbuqZMmSGjNmjBYsWCB/f38FBgbq8ccf12uvvWa5zTIjpQAAgFF+/vlnLV68WEuXLtUzzzyjhQsXau7cuZZR3ZIUGRmpefPmycHBQb/++itfosEmEhMTNX/+fH377beqUqWK5ZzZy8tLb731liRpxowZSkxM1JgxYwikDMLle3gobdq0SeHh4YqOjtaJEye0YcMGPfPMM5ZJ6UwmE3fEQb7XsWNHpaSkaMGCBVbHer9+/bRq1Sr9+eefVgEUJ3cAACC3/XP0yLx58/TVV19p69atioiIUJcuXTR27Fj17NlT169f1x9//KFnnnlGe/bs0VNPPSU7Ozu+RIOhbv/c+Mcff+jrr7/W1KlT9fnnn6tHjx6WdrGxsfriiy/0448/asOGDSpatCifNw1A9IeHSkbolDEJYvny5VWpUiUlJCRIsr4LDr8gkF/c7S4f5cuX1/bt27V3716r5QEBAfLw8FBiYqLVcgIpAACQ226fQ+r3339XoUKF5OPjowULFqhz586WQEqStmzZom+//VYXL15UQECA5ZIoAikYIeOzZVJSkuWGWFWqVFHfvn3VtWtXhYeHa8aMGZb2JUqUUJ8+fbRx40YVK1aMz5sGYaQUHjq3J9mbN2/W+PHjFR8frwEDBqhp06Z3tAHystu/bdy9e7fMZrPS0tIsc6o1aNBAZ8+e1ddff60KFSqoQIECatWqlQoXLqyIiAhblg4AAB4ht5+zjB07VqNHj9bu3bt1/fp1NWzYUPHx8friiy/Uu3dvSbeCgFdffVVeXl6aMWMG5+4wVMbnxZUrV2rixIm6du2aChQooJEjR6pu3bo6ceKExo4dq59//lmDBg1SUFCQrUt+ZBFR46Fz+6V59evXl9lsVnh4uP73v/8pJSVFr7zyCn/UkG9knNwNGjRICxcuVEpKim7cuKGXXnpJU6ZM0c8//6ymTZuqU6dOSk1Nlaenp9LS0rR69WpJBLQAAMAYGecsf/75p5KSkjRz5kxVqFBBkjRnzhy1atVKx48f1/Lly+Xm5qZPPvlE58+f1/Lly5l6A4bLCKRatWql/v3767HHHtP69ev12muv6eOPP1bXrl3Vp08fOTg4aNCgQXJ0dFTHjh1tXfYjiZFSeGj88w/V7c+3bNmi4cOHy93dXfPnz1eBAgVsVSaQ47744guNHDlSy5cvl6urqy5fvqx27dqpevXqWrNmjSRpxYoVunTpkhwcHNS2bVsmNQcAAIbbsmWLnn32WTk7O2vOnDl64403LOvmz5+vUaNG6e+//1aZMmXk6empxYsXy9HRkXkvkesuXLhgdeOrpKQktWzZUlWrVtXYsWMty9955x0tWbJEK1euVM2aNfX777/r22+/VY8ePfTkk0/aovRHHqEUbCIjcDp27JguX76sqlWrytHR8a7tJGn79u3y9vbWE088YXS5QK5666235ObmpkmTJlmWHT16VNWrV1e3bt0UHh5+xzac3AEAgNz2z0nNJel///uf+vfvrw8++EAjR460Ooe/cOGCEhIS5OzsrBIlSshkMvElGnLdiBEjlJiYqI8//lhOTk6SpOTkZNWvX19t2rRR//79lZycLGdnZ0lSw4YN5e7urh9//FGSdPPmzUw/i8IYTHQOmzCZTIqIiFDt2rXVokULVa1aVT/88INlQvPb22XkprVr1yaQQr6SmpqqtLQ0HT58WJcvX7YsT05OVtmyZTVs2DBt2rRJf//9t9LS0qy2JZACAAC5yWw2WwKpb775Rvv27ZN06y7AH3/8sT799FPNnDnTahsPDw/5+PjIy8tLJpOJSc1hiMqVK6tz585ycnKy3AjI2dlZjz/+uFasWGF5npycLEmqWbOmUlJSLNsTSNkWoRQMZzabdfbsWX388ccaOnSoVq9erUqVKmnQoEH6/vvvdf36dav2XHuO/GLDhg366quvNGrUKKWlpcnBwUH29vbq0qWLNm7cqGXLlkmS5VscFxcX2dvby9XVlRAKAAAYJj093XIOfuHCBXXu3Fkffvih9u/fL0kKDQ3VyJEj1bt3b02fPv2u/fxzlBWQG9544w35+/tr/fr1GjhwoP78809Jt47T06dPq0ePHpL+7xz7/PnzKlSokG7evCkuHLM9YmsYJuNSPLPZrMcee0z169dXUFCQChQooCVLlqhLly767LPPJElt2rRRwYIFbVwxkHO+/vprDR06VBUqVND+/fu1fPly7d69W9KtUYDPPfecxo0bp9TUVL366qu6ePGifvrpJ/n4+Fj+gAIAABghI0wKDQ1VUlKS/Pz89NNPP+natWv64osvVKlSJQ0dOlSSFBwcrOvXr6tfv362LBnQ6dOnNXfuXDk4OOi9995TvXr1NHDgQH366aeqW7eunn32WZ0+fVpLly7Vjh07GCH1kGBOKRhq5cqVmj17tk6ePCkXFxctW7ZMhQsXtqzv3LmzoqKi1KtXL3Xp0oUJzZEvTJ06Vb1799aiRYvUsGFDnTx5Uo0aNdKaNWtUvXp1SdLevXs1ceJELVq0SF5eXnJycpKTk5N2794tR0dH7lgDAAAMNXHiRI0aNUorV65UwYIFdeXKFb3++uvy9fXV5MmTVblyZUm37iC8bds2bdq0iXMVGCrj/PjUqVN64oknZDKZ9N1332nAgAFq2bKlPvjgA5UsWVK7du3S2LFjlZCQoCJFimjo0KHy9/e3dfn4/wilYJgdO3aoXr16euutt7R//35FR0frnXfe0fvvv6/HHnvM0u7VV1/V6dOntW7dOqvACsiLIiIi9Prrr2vlypVq2rSpJOnq1asKDAxU8+bNFR0drdatW+v111+Xo6Oj/vjjD+3cuVPFixfXa6+9xl32AACATQQFBSk9PV1z5syxLDt27JgCAwMVEBCgzz77TFWqVJH0fxOi8yUajJJxrC1fvlxjx47Vm2++qe7du0u6dSfIgQMHqmXLlgoJCVHZsmUt23Fe/fDhXwOGOHDggH755Rd99tlnCgkJkSSFhIRo3bp1cnV11bvvvmsJoCIiInT27FkCKeR5SUlJWrZsmcqWLauzZ89algcFBenq1atKS0vT9evX9fbbb+vMmTMaOHCgnn76aT399NOWthlzTwEAABghYz6pixcvWi1PTk5WmTJlNGzYML333ntydHTU5MmT5e3tLUkEUjBExnFmMpm0dOlStW/fXp988onq169vadO+fXulpaXpgw8+kIODg7p162YZGcV59cOHmeeQ644ePaqePXvq888/t5obJzw8XPXq1dMPP/ygyZMn6++//7asK1mypC1KBXKUq6urhg8frkaNGmnGjBn6+uuv1aZNGx09elRbt27VhAkTtGnTJjVt2lQzZ85UUlLSHX0wwTkAAMhN6enpVs/t7OxkMpnUtWtXrV+/XrNmzZL0f5NEFylSRF27dtWOHTs0fPhwq22A3LJ//36lpaVZjrPTp09r5MiRCg8P13vvvady5copKSlJK1eu1KVLl/Tmm29q7Nixmjp1qubNm6ebN2/aeA9wN4RSyHX/+c9/1LBhQ7m4uOjHH39UQkKCZV14eLief/55zZgxQzNmzODuB8hXzGazypYtq0GDBqly5cr66KOPtH79eq1Zs0Zly5a13LL2+eefl6enp1JTU21cMQAAeJRkXHYnScuXL9fnn3+ur776StHR0WrZsqV69Oihjz76SNOmTVNqaqrOnz+vBQsWKDAwUNOnT9eiRYv0+++/23gvkN9NmjRJ7777rtXnyOTkZF29elWVK1dWenq6PvvsMzVq1Ejt27dX1apVdfjwYbVv315z585V165dmdT8IcacUshxmQ3dTU1N1f/+9z999913qlOnjsaMGaNChQpZ1g8ZMkTdunVTmTJljC4XyFUZPw8nTpzQxx9/rD179qhr167q1auXpFs/G02aNJGXl5fmzp3Lt4wAAMBwAwcO1OLFi1W6dGkVKVJEy5Yt0/bt21WiRAlNnz5dY8eOVYkSJWQ2m1W4cGHt3btXGzduVI8ePbRp0yauckCuun79umJjY1WuXDmdP39ejz/+uG7evKm2bdsqJiZG165dU61atfTMM8+oe/fuql27tpo3b67//e9/ti4dWUAohRyV8QF827Zt2rBhg1JTU1WlShW1atVKaWlpGjdunJYuXaqAgACFhYVZBVNAXnf7t423y/i5OH78uD7++GPt379fnTp1Uq9evdSiRQsdPXpUv/32mxwcHJiPAQAAGGr+/Pnq37+/fvzxR9WqVUtz585Vly5dNG/ePMvcPAcOHNCOHTtUuHBhvfLKK3JwcND777+vbdu2acWKFXr88cdtvRvIp9LS0izTWezcuVPBwcEKDQ3Vq6++qj///FMbN25UWlqa2rVrp6JFi8pkMqlly5Z6/vnn9d5779m4emQFoRRy3JIlS9SlSxc9/fTTSkpK0s6dO9WzZ0+NHz9ezs7O+vTTT/XTTz+pbNmymjRpktzd3W1dMpCjrl27dsdxnRE2HTt2TGFhYfrrr790/PhxFShQQPv375ejoyN3AwEAAIbJ+DJt5MiRunTpkj7//HNFRESoc+fOCg8PV/fu3XXt2jVduXLFMpm5dOsGRhMnTtT8+fO1adMmVa1a1YZ7gUfJ1atX9cILL8jJyUlDhgxRkyZNrOZfvXr1qsaPH68pU6Zoy5YtqlChgg2rRVYxpxRy1LFjxxQSEqKxY8dq/fr12rp1q1atWqW5c+dqwIABsre314ABA/Tcc8/p3LlzVtcFA3nV+vXr9f3330uS3n33XX3yySdKS0uzamMymWQ2m1WmTBkNHjxYJUuWVKVKlQikAACAYdLT0y3nKBmju2/evKm0tDQtXbpUnTt31tixY9W9e3dJ0tKlSzVt2jTLPJgpKSnau3evrl27ps2bNxNIIVdljJ/59ddftXv3bhUuXFi//PKLnJ2dNWrUKK1YscJyPK9YsUJ9+vTRrFmztGbNGgKpPISRUrhv06dPl7+/v5555hnL5Ub79+9Xy5YttXz5cvn5+Vm+gVm5cqVefvllrVixQk2bNlVaWpquXLmiokWL2ngvgAdz+fJlde/eXbGxsfLw8NC6deu0Y8cOValSJdP2GSOm4uLi5OHhITs7OwIpAACQ65YvX66IiAidPXtWTZo0Ub9+/SRJc+bMUVhYmE6fPq1PPvlEwcHBkm6NOmnXrp2qVaumsLAwSz8pKSm6efOmChQoYJP9wKMh45w5IiJC7777rpo0aaKPPvpIJUuW1LVr1/Tyyy8rKSlJg/9fe3ceFnW9/n/8OcMAgiLmLno0TTTX3HA3LTtaKiYpruGuaKCm6UGlQnPX3HcFF8Ald1EyM1dyOWqhlno09w1wRSUUYZjvH1xM2HJ+v1PCBLwe/3j5GWaue65rgDevz/2+36NH07ZtW44fP05UVBSenp6UL1/e1uXL/0CdUvKnWCwWxo4dS+/evfnuu++sKbbBYODSpUtcv37d+nUWi4VmzZpRuXJlLl26BKQdc69ASnKCggULMnnyZO7fv09ERARBQUHWQOr3Mv/0ALdYsWIYjUZSU1MVSImIiEimWrJkCT169MBgMODg4MBHH33ExIkTAejRowd16tTBYDBQuHBhLly4wOnTp+ncuTNxcXGMGzcO+GVd4+DgoEBKMp3BYGDv3r34+PgwYcIEpk6dipubG6mpqbi4uBAREYGTkxNTpkyxziwePHiwAqlsSJ1S8j9LT62fPXtGvXr1SElJISQkhFq1amEymejWrRtXrlxh5syZ1K1bF0hrFW7QoAE9e/a0njomkt2lfy9cvHiRYcOG8fTpU549e0a/fv3o2rUr8PxwRhEREZGsFhwcjL+/P2vWrMHLy4u4uDhat25NfHz8cyfneXp6cvnyZc6fP0/t2rVxdHRk165d2Nvbaz0jNjFq1Cji4uJYtmyZ9TNoNpsxGo0YDAYeP35MkyZNKFy4MFu2bCFfvny2Lln+BIVS8qckJSXh6OhIQkICNWrUoHTp0kyaNIl69eqxd+9epk+fzu3btwkMDKRo0aJs3bqV4OBgjh49Srly5Wxdvshf8ken7J06dYqJEydy8+ZNPvjgA7p06WJ97MGDB7z00ktZWaaIiIjkcmfOnKFatWr06tWL4OBg6/UaNWoQFxdHVFQUycnJVKpUCYBr165x5swZSpUqReXKlTVmQGyqVatW2NnZsW3bNoDnTqm+evUqZcqU4fHjx9y/f58yZcrYslT5C7R9T/5nFosFR0dH1q1bx4gRI/jHP/7Bvn37GDhwINHR0bzxxhuMGDGCKlWq0KFDB3r37s22bdvYtWuXAinJ9iwWizWQWrFiBRMmTGDOnDk8ffqU6tWrM2zYMEqWLMmSJUsICwsDoGXLlixatMiWZYuIiEgulDdvXoYNG8bmzZsJDw8HoH379ty8eZOGDRsyYsQI3n77bdq3b8+8efNITEzk7bffpmrVqhozIDaVmppKnTp1ePToET/99BOQtqUvNTWVW7duMXLkSKKjo3FxcVEglc2pU0r+lKioKFq2bMncuXOpWrUqycnJ9O3bFzs7O8LDw6lZsyYAly5dwmQykTdvXs2QkmwvY4fUiBEjWL58OWXLluXBgwe4uroSFRWFs7MzR48eZf78+ezduxcnJycA6yl7IiIiIlnp1q1bzJkzhwULFlC6dGmcnZ1ZtWoV7u7u3L9/n6tXrzJ9+nQOHjzIq6++yo4dO2xdsuQy6R1QMTExPHv2DCcnJ4oWLcqJEydo0qQJPj4+DBo0iEqVKpGcnMzEiRMJDw9n9+7dlC5d2tbly1+kUEr+lBkzZrB+/XoOHDhg/UP70aNHeHh4kC9fPhYsWEDt2rV1Z0VypHv37jFkyBACAgIoX7480dHR+Pn5kZiYSHR0NM7Ozpw7d46LFy9y+fJlfH19MZlMan8XERERm7h16xaLFi1ixowZBAYGMmrUKACSk5Oxt7cnJSWFxMRE8uXL97sjCkQyS3ogtWXLFgIDAzEYDDx48AAfHx9GjRrF8ePH8fHx4ZVXXsFisVCwYEGioqLYs2ePtRFCsjf9xJH/SXqG+fDhQ+Lj462B1JMnT8ifPz9z5swhOjqa/v37c+rUKVuWKpIplixZQq1atbh9+zYlSpTAycmJBg0aEBISgrOzM7Vq1eLJkydUrFiRVq1a4efnh8lkwmw2K5ASERERm3Bzc6Nfv34MHjyYSZMmERISAmANpEwmE/nz58doNGI2m21creQmBoOB3bt34+Pjg6+vL8ePH2fgwIFMnTqVr776iubNm7Nt2za6du1KuXLlqF+/PkeOHFEglYOoU0r+lNOnT9OgQQNGjRplvdMCsHfvXmbNmkVMTAxr167VDCnJUVJTU9myZQuTJk3ixo0bXL16FQcHByAtsE0PZC9evEhsbCyOjo42rlhERERyi4xDoP/IrVu3mDdvHvPnz2fmzJn07t07i6oT+a30z6yfnx+pqaksXLiQGzdu8MYbb9C8eXPNZM0l1Ckl/1V6ZnnixAlWrVrFd999x71796hSpQoBAQEEBwczYcIEABISEvjmm28oW7Yshw4dUiAl2V5qaupz/zcajbRu3Zrx48djb29PixYtrI8ZDAZq1arF/PnzadeunbqiREREJMukpqZaA6knT54Av6zjM3Jzc8Pf3x9/f3/69u3L9u3bs7ROyd3S19a/XmPfuXOHxo0b8+TJE+rVq8ebb77JwoULAVi3bh179+7N8lol66hTSv6fNm3aRK9evShSpAgPHjyga9euDB06lKJFizJv3jwmTpxIoUKFyJcvHzdu3ND+XskRMg4137VrF7GxseTLl4+6detSsmRJvv76awYPHkypUqX45ptvfvc1zGYzdnZ2WVm2iIiI5DIZ1yxTp07l5MmTzJkz578eMnT9+nW+/PJL+vTpoxtpkunSP6PpnVEPHz7E1dXV+vjgwYPZtWsXP//8M+3atWP69OnY29uTnJxM9+7dqVChAp988ok+qzmUQin5Xek/MK5fv46fnx+enp5069aNFStWEB4eTrly5Rg7diyvvPIKFy9eJCIiAldXV15//XXKly9v6/JFXpiAgABWr16Nu7s7MTExFC5cmFGjRvHOO++wY8cOhg8fTqlSpfj6669tXaqIiIjkYgEBAYSFhREYGEjLli3/v9fkOohFMlN6IHXlyhXCw8PZuXMn169fp1GjRrRq1Ypu3bpx9epVunTpwvXr1zl37hzOzs6YzWY+/fRTwsLC2L17N+7u7rZ+K5JJFErJHzp27BihoaHcvHmTJUuWULhwYQBCQ0NZtGgRZcuWJSAggOrVq9u4UpEXJ+M8hhUrVhAYGMjGjRupX7++9cSadevW4enpSUpKCt988w1du3bFx8eH2bNn27h6ERERyS0ydkjt2bOHnj17Eh4ezuuvv27jykTSpH9Gf/jhB9q3b0+dOnVwcXGhdOnShISEkJSURJ8+ffjss8/YuHEjY8aMISEhAQ8PDxITEzl69Cg7d+7ULpwcTjOl5A/t2rWLL774giNHjhAfH2+93r17dwYMGMDNmzf5+OOPOXPmjO2KFHlBtm3bBvDcgNBTp07Rrl076tevz8aNGxk7diwzZ87E09OTn3/+mbt379KiRQsiIyOZMWOGrUoXERGRXGTkyJEA1kAK4OrVqxQuXJh69epZr/269+DXc3xEMlN6IHXy5EkaNmyIl5cXCxYsYPHixQQGBlpP1lu0aBGzZ8+mffv2bNy4kU6dOuHq6krDhg05dOiQAqlcQH2a8odGjx6Nq6srM2bMYMaMGQQEBFCmTBkgLZhKSkpi06ZNFChQwLaFivxFgYGB3Lp1izZt2lhDKYvFQmJiIq+99hqHDh2iZ8+eTJs2jQEDBmA2m1mzZg0Affv2pUGDBoBmSImIiEjm2r9/P6dOnfrNljuj0cj9+/eJiYnh5Zdftl5PX7P885//pFixYjaoWHIro9HIhQsXqF+/PsOHD2fcuHGYzWYgbctohQoVCAoK4s6dOyxdupRWrVpRoUIFJk+ebOPKJaupU0qAX+6kJCYmkpCQYL3u5+dH//79OXLkCLNnz+batWvWx/r168fatWtxc3PL8npFXqQPP/yQJUuWYDAYOHHiBJDWMVWlShX8/Pxo2rQpwcHBDBgwAICff/6ZtWvXcvXq1edeR4GUiIiIZKYGDRoQGRmJyWRi/fr11utlypQhKSmJtWvXcu/ePSBtLZOSksLSpUtZsWKFjSqW3Co1NZVly5bh4uJCkSJFgLS1stlsxmQyYbFYeOWVVxg9ejRnz57lxx9/fO75mjKUeyiUEusMncjISLp160bNmjUJCAjgyy+/BNKGJnp7e7Nv3z7mzZvHlStXrM/NeGqCSHbz+eef88MPP1CkSBHs7e3ZsGED77//PosXLwZg0KBB9O3bFwcHB8qVK8ft27e5dOkSHTt25OHDhwQFBdn4HYiIiEhuYTabcXBwwGAwcP78eXr27EmbNm0AaNasGf3792fixIlMnTqVbdu2sX//fjw9PXn8+DEfffSRjauX3MZoNOLv70/Xrl1ZvXq1tQPKzs7uua2ktWvXplChQsTExDz3/IwjNSRnUyglGAwGIiIi6NixI1WrVmX48OF8//33jBs3jtWrVwMwatQoOnfuzPr16wkODiYlJcXGVYv8Nfv27WPFihWMHz+en376CUi7++ju7s6aNWsICQkB0kLZ1q1b07hxY+rWrUuHDh1ISEjg0KFDmEwmaxuyiIiISGa5e/eutSN7z549VKhQgdDQUM6fP4+npycAY8eOJSgoiEOHDuHt7c3QoUOxWCz8+9//1ppFbMLNzY2RI0fi4eHBli1bmDJlCpAWWKUHU9HR0bi5uVG/fn1blio2pNP3hHPnztGhQwf8/f3x9fXlyZMnlClThoIFC1KgQAGGDh1Kp06dAJg5cybt2rWjbNmyNq5a5K8LDQ1l2bJlFClShDFjxlClShViY2Px9/cnJiaGfv360bNnTyBt8P+TJ09wdXWlSZMmGI1GHaEsIiIimS4yMpKQkBCmT5/O7NmzmTNnDvfv38fR0ZEdO3YwfPhwqlSpYj205fbt2zx8+BB7e3vKlClj3canNYvYSmxsLBMmTODYsWN4eXkREBBgfWzYsGGcPn2aNWvWULBgQRtWKbaiUCoXyXjUfUbXrl1jwYIF/Otf/yIxMZGmTZvy9ttv06dPHzp06ECBAgXw8/OjT58+Nqha5MV79uwZDg4OACxYsIBNmzZRsGBBJkyYgLu7OzExMQwaNIjY2Fh69uxJ3759f/MaGY9hFhEREckshw8fxtvbm/z58xMXF8f+/fupWrUqAE+fPuXLL79k+PDhVKtWja1bt/7m+VqzyN/B7wVT48ePZ8aMGRw4cMD6mZbcR6FULpH+y+jevXvExcVhNpupVq0akLY//f79+xQpUgRfX18SEhJYtGgRLi4udO3alaioKGrVqkVoaCj58+fX/l7J1jKGszNmzODUqVNERUVx5coV2rdvz9ixY6lUqRIxMTEMHjyYO3fu4OXlxZAhQ2xcuYiIiOQmFosFi8WC0WjE19eXkJAQ3nrrLWbOnEmlSpWsX5eUlERkZCQBAQGUKFGCAwcO2LBqkT+WHkydPHmSpKQkTp06xcGDB6lVq5atSxMbUmSeC6QHUj/++CPvvPMOrVu3xtPTk/79+wNpw+bST0Q4d+4cJUqUwMXFBQAXFxc++ugjlixZgqurqwIpyfbSP8Off/45Y8aMoWPHjmzevJmgoCAuX77Mp59+av0+mDt3LkajkXPnzukEEBEREckyqampGAwGa4dTixYtWLlyJRcvXmTMmDEcP37c+rWOjo60atWKzz77jEKFCj03RFrk76R48eIEBgZSvnx57t+/z+HDhxVIiTqlcrr0QOrkyZM0atSIAQMG0KZNGzZs2MDSpUuZNWsWAwcOxGw2k5SUxIABA3jw4AGenp5cvHiRsLAwjh07RsmSJW39VkReCIvFwrNnz/Dy8qJ69erWk0AAlixZwuTJk6lbty7jxo3D3d2de/fu8dJLL2E0Gv9wC6yIiIjIi5Jxu93cuXOJj49n6NCh5MuXj4MHD9K9e3fq1KlDQECA9Q/6rVu38u677/7ua4j83dy5c4fU1FSKFStm61Lkb0A/qXI4o9HIhQsXqF+/PkOHDuXzzz+nWbNm1mNhL168CKR1Szk7O/P++++TkpLC1KlTiYyMJDIyUoGU5CgGgwFHR0fy5s37m6Nn+/fvT7NmzYiMjGTgwIFcvnyZQoUKWU8IUSAlIiIimSl9ux7AiBEjmDx5MkWKFOH27dsANGrUiBUrVvD9998zfvx4VqxYgaenJ717936uQ0qBlPydFSlSRIGUWOkIhhwuNTWVZcuW4eLiQqFChazX165dS3JyMj/99BOzZs2iYMGCdOzYkRYtWvDGG29w//597OzsKFy4sA2rF/nrft3dlP5/d3d3vvjiC06dOkX16tWtj1eoUIHXXnuNevXqUaZMGet1Le5EREQkszx9+pQ8efJY1yzLly8nPDyciIgIPDw8gLQ1zOPHj2nSpAmrVq1i+PDhzJ8/n/z58xMbG6uubhHJlrR9Lxe4desWU6dO5ciRI/To0YPHjx8zefJk/Pz8qFGjBqtWreL69evExMRQsWJFPvzwQzw9PW1dtshflrF1/caNG5hMJvLkyUOBAgUA8PDwIDExkaVLl1KhQgVcXFzo3Lkzb775Jv7+/hgMBrW/i4iISKbq0qULnTt35t1337WGSh9++CEPHjxg5cqVnDlzhqioKJYsWcLDhw+ZPHkyHTp04Pbt2zx79gw3NzeMRiMpKSmYTOo5EJHsRaFULpF+0sGuXbu4ePEiO3fu5M033wSw/gKbN28e33//PcOHD6dy5co2rljkr8kYJo0dO5adO3dy4cIFWrRoQdu2benYsSNPnz6lefPmxMTEYDAYcHZ2JikpiTNnzmAymXS3UURERDLd6NGjGTNmDA4ODjx79gwHBwemT5/O1KlT8fHxYc+ePZQtW5aqVasSFxfHmjVruHTp0nO7IHQTTUSyK0XpuUTx4sX5+OOPMRqN7Nu3j+joaGsolb7/3N/fX3dYJMdIX5h9+umnLFiwgODgYJydnZk1axYBAQEkJibSs2dPDh48yPr1660DFwcMGIDJZMJsNmNnZ2fjdyEiIiI5VXqQNHHiRAAWLlyIxWKhd+/evPfee8THxxMREUGfPn1o0aIFr776KgcOHODs2bO/OWFPgZSIZFfqlMpl0jumjh07hpeXFwEBAQAKoyTHyNjdtG/fPvz8/AgODqZBgwbs2bOHNm3aULduXW7cuEFQUBA+Pj6/eQ0FUiIiIpLZ0tcs6f+2adOGs2fPEhQUROfOnXFwcCAhIYF8+fIBaet1T09PTCYTERER6uYWkRxBkXouU7x4cQIDA/Hw8GDbtm0EBQUBKJCSHCHjCXkxMTG89tpreHl54eHhwc6dO+ncuTNz585l8eLFmEwmRo8ezcKFC3/zOgqkREREJDNlvIl248YNALZv307Dhg2ZMGECq1atsgZSCQkJbNq0iRYtWhATE8OmTZuscy9FRLI7hVK5UHow5e7uzqFDh7h3756tSxJ5IdJb10eOHMnIkSNxcnIiMDAQo9HI4sWL6d+/P7169aJixYpUrlyZggULcvjwYdQwKiIiIlkl40201atX4+/vz8GDBwEICwujdu3aTJkyhfXr15OYmMi9e/f44YcfcHd35/jx49jb25OSkqIteyKSI6g9JpcqXrw4kydPBnhuSKJIdpTxbuPhw4fZtm0by5cvJ0+ePAAkJCRw+vRpatasidFo5NGjRzg4OBAYGIi3t/dzrfMiIiIimSXjQPKDBw/y1Vdf8e2335InTx7s7e2pW7cuq1evpmvXrkybNg07Ozu6dOnC8OHDcXZ2xmAwYDabtctBRHIM/TTLxYoVK2brEkReiPQwaebMmVy7do1mzZpRt25dIC2wMhqNNG3alMjISJKTkzl48CAJCQl06NDB2v6uu40iIiKS2dLXG8OGDSMiIoJ3332XVq1asXXrVgwGA4MGDaJRo0asXr2a7t27M3jwYAoXLkyrVq2AtHWNxgyISE6iv8JEJNv69ba7U6dOMXv2bL777jvi4+OBtMDK2dmZ7t27U716dXbs2EGBAgX49ttvMRqNCqREREQkSx08eJBVq1YRGhrK9OnTCQsLIyQkhLNnzzJr1iyOHj0KQGhoKEOHDqVly5bW56qrW0RyGnVKiUi2dODAAY4dO4bBYKBr164UL16c5cuXU7x4caZMmcK6devw8fHByckJgMaNG1OvXj3MZjOOjo4YDAadOikiIiJZzmQyYTQacXR0tF7z9vbGbDbTrVs37OzsrB1T6YcS6WRgEcmp1B4gItlOaGgo/fr148aNG+TLl4/ixYtbH5s0aRK+vr4MGTKEjRs38vTpU+tjdnZ25MmTxzpDSoGUiIiIZKb0ru5fd3enpKRw8+ZNAJKTkwHo1KkTr776Kj/++COhoaHWx0EnA4tIzqW/yEQkWwkLC2PAgAGEhYXRpk0b613GWbNmUbJkSby9vVm4cCEWiwVfX18MBgPvvfceTk5Oz23TU/u7iIiIZKaMIwJSUlKwt7cHoF69erRt25aePXuye/duatasCcC9e/eoU6cO1apVY/z48bRu3ZqSJUvarH4RkaygUEpEso2zZ88ybdo0Zs6cSfv27a3XO3bsyIYNG2jZsiUmkwkvLy8WLVqE0WjEx8eHwoULPzePQURERCQzZQyk5syZw/79+7FYLLz88svMmDGDhQsX8vDhQxo3bsyoUaPInz8/ERERJCcns3LlStasWcOOHTto27atjd+JiEjm0vY9Eck2rl+/zuPHj2natCmpqakA+Pn5ER0dzfbt20lJSSEkJIQNGzYAsGDBAqZNm0bz5s1tWbaIiIjkMumB1KhRoxg3bhwVKlSgYMGCbNiwAQ8PD+Lj49mwYQNDhgwhMjKSkJAQnJ2d2blzJwCOjo5UrFjRlm9BRCRLGCy/3uAsIvI3NWHCBGbOnMndu3et12JiYjCbzZQqVYqzZ8/Sr18/LBYL4eHhlC1b1vp1GmouIiIiWenMmTO0adOGhQsXWju2L126ZB0rcPjwYQDi4+PJkycPefLkAeCTTz5h2bJl7N+/n/Lly9usfhGRrKBOKRHJNsqXL8+TJ0/YtWuX9VqJEiUoVaoUqampVKpUibZt21KgQAGKFi363HMVSImIiEhWio+P5+HDh1SqVAlIG3Zerlw5Vq5cybVr11i9ejUALi4u5MmTh/Pnz+Pr68vSpUvZvn27AikRyRUUSolItuHh4YHJZGLx4sVcvXr1uceMRiOPHz8mKiqKihUrkjdvXhtVKSIiIgKVKlXCycmJTZs2Ab8cslKqVCmcnJx49OgR8MvJekWLFsXb25tDhw5Zh5+LiOR0ah0QkWyjXLlyLFq0iF69euHo6MiIESOoUaMGAFevXqVfv37cvn2bzZs3A2l3JHXKnoiIiGSFjMPNLRYLjo6OeHp6sm3bNkqUKEGnTp0AcHZ2pkCBAtbT+NLXKwUKFOCtt96yWf0iIragmVIikq2YzWaWL1/OBx98QLFixahatSopKSk8fvwYgKioKOzt7TGbzdY7jyIiIiKZYffu3Rw+fJiPP/4YeD6YgrSTgwMDA7l27Ro1a9akdu3arFu3jrt37xIdHa21iojkegqlRCRbOnHiBMHBwZw/f57SpUtTq1YtfH19sbOz01BzERERyXRJSUkMHjyYw4cP4+Pjw4gRI4Bfgqn0DqgLFy6wZcsWwsPDcXV1pUSJEoSFhekmmogICqVEJIfR4k5ERESyyq1bt5g6dSpHjhzBy8uLgIAAIC2YMhgM1jECKSkp1vVJxmu6iSYiuZ0GnYtItvV7mboCKREREckqbm5ujBw5Eg8PDzZv3syUKVMArJ1SAHFxcfTo0YO1a9daAymLxaJASkQEdUqJiIiIiIj8JbGxsUyYMIFjx47Rrl07Ro4cCUBMTAze3t7cvn2bM2fOKIgSEfkVhVIiIiIiIiJ/UcZgqn379vTu3Rtvb2/i4uI4ceKEZkiJiPwOhVIiIiIiIiIvQGxsLBMnTuTo0aP85z//wc3NjZMnT2Jvb68ZUiIiv0OhlIiIiIiIyAsSGxtLQEAAd+7cYevWrQqkRET+C4VSIiIiIiIiL9CDBw9wdXXFaDQqkBIR+S8USomIiIiIiGSC1NRUjEYdeC4i8kcUSomIiIiIiIiISJZTbC8iIiIiIiIiIllOoZSIiIiIiIiIiGQ5hVIiIiIiIiIiIpLlFEqJiIiIiIiIiEiWUyglIiIiIiIiIiJZTqGUiIiIiIiIiIhkOYVSIiIiIiIiIiKS5RRKiYiIiIiIiIhIllMoJSIiIiIiIiIiWU6hlIiIiIiIiIiIZLn/A/nTAZZi92PkAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Read and prepare the data\n",
        "df = pd.read_csv('/content/sample_data/audio_features - Copy.csv')\n",
        "X = df.drop(['file_name'], axis=1)\n",
        "y = df['file_name']\n",
        "\n",
        "# Initialize models\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(random_state=42),\n",
        "    'SVM': SVC(random_state=42, probability=True),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=42)\n",
        "}\n",
        "\n",
        "# Initialize metrics storage\n",
        "results = {\n",
        "    'Model': [],\n",
        "    'Fold': [],\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1-Score': []\n",
        "}\n",
        "\n",
        "# Initialize 5-fold cross validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross validation for each model\n",
        "for model_name, model in models.items():\n",
        "    print(f\"\\nEvaluating {model_name}\")\n",
        "\n",
        "    for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
        "        # Split the data\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        # Scale the features\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # Train and predict\n",
        "        model.fit(X_train_scaled, y_train)\n",
        "        y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "        # Calculate metrics\n",
        "        results['Model'].append(model_name)\n",
        "        results['Fold'].append(fold)\n",
        "        results['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
        "        results['Precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
        "        results['Recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
        "        results['F1-Score'].append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Convert results to DataFrame\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "# Calculate mean metrics for each model\n",
        "mean_results = results_df.groupby('Model').mean()\n",
        "#std_results = results_df.groupby('Model').std()\n",
        "\n",
        "print(\"\\nMean Results:\")\n",
        "print(mean_results.round(4))\n",
        "#print(\"\\nStandard Deviations:\")\n",
        "#rint(std_results.round(4))\n",
        "\n",
        "# Create voting classifier with best performing models\n",
        "# (We'll determine the best models based on mean accuracy)\n",
        "top_3_models = mean_results['Accuracy'].nlargest(3).index\n",
        "\n",
        "voting_models = []\n",
        "for model_name in top_3_models:\n",
        "    if model_name == 'SVM':\n",
        "        voting_models.append((model_name, SVC(probability=True, random_state=42)))\n",
        "    elif model_name == 'Random Forest':\n",
        "        voting_models.append((model_name, RandomForestClassifier(random_state=42)))\n",
        "    elif model_name == 'Gradient Boosting':\n",
        "        voting_models.append((model_name, GradientBoostingClassifier(random_state=42)))\n",
        "    elif model_name == 'Decision Tree':\n",
        "        voting_models.append((model_name, DecisionTreeClassifier(random_state=42)))\n",
        "    elif model_name == 'KNN':\n",
        "        voting_models.append((model_name, KNeighborsClassifier()))\n",
        "\n",
        "# Create and evaluate voting classifier\n",
        "voting_clf = VotingClassifier(estimators=voting_models, voting='soft')\n",
        "\n",
        "# Initialize metrics storage for voting classifier\n",
        "voting_results = {\n",
        "    'Accuracy': [],\n",
        "    'Precision': [],\n",
        "    'Recall': [],\n",
        "    'F1-Score': []\n",
        "}\n",
        "\n",
        "# Evaluate voting classifier\n",
        "for train_index, test_index in skf.split(X, y):\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    voting_clf.fit(X_train_scaled, y_train)\n",
        "    y_pred = voting_clf.predict(X_test_scaled)\n",
        "\n",
        "    voting_results['Accuracy'].append(accuracy_score(y_test, y_pred))\n",
        "    voting_results['Precision'].append(precision_score(y_test, y_pred, average='weighted'))\n",
        "    voting_results['Recall'].append(recall_score(y_test, y_pred, average='weighted'))\n",
        "    voting_results['F1-Score'].append(f1_score(y_test, y_pred, average='weighted'))\n",
        "\n",
        "# Print voting classifier results\n",
        "print(\"\\nVoting Classifier Results (using top 3 models):\")\n",
        "for metric, values in voting_results.items():\n",
        "    print(f\"{metric}: {np.mean(values):.4f} (+/- {np.std(values):.4f})\")\n",
        "\n",
        "\n",
        "\n",
        "# Return best individual model and whether voting classifier improved results\n",
        "best_model = mean_results['Accuracy'].idxmax()\n",
        "best_model_accuracy = mean_results['Accuracy'].max()\n",
        "voting_accuracy = np.mean(voting_results['Accuracy'])\n",
        "\n",
        "print(\"\\nBest Model Selection:\")\n",
        "print(f\"Best Individual Model: {best_model}\")\n",
        "print(f\"Best Individual Model Accuracy: {best_model_accuracy:.4f}\")\n",
        "print(f\"Voting Classifier Accuracy: {voting_accuracy:.4f}\")\n",
        "#print(f\"Improvement using Voting: {(voting_accuracy - best_model_accuracy):.4f}\")\n",
        "\n",
        "# Save final model if voting classifier is better\n",
        "if voting_accuracy > best_model_accuracy:\n",
        "    final_model = voting_clf\n",
        "    print(\"Final Recommendation: Use Voting Classifier\")\n",
        "else:\n",
        "    final_model = models[best_model]\n",
        "    print(f\"Final Recommendation: Use {best_model}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d6rXBaQguxHV",
        "outputId": "88588c8d-edad-48ad-89e6-1d9b7a773e70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating Decision Tree\n",
            "\n",
            "Evaluating Random Forest\n",
            "\n",
            "Evaluating SVM\n",
            "\n",
            "Evaluating KNN\n",
            "\n",
            "Evaluating Gradient Boosting\n",
            "\n",
            "Mean Results:\n",
            "                   Fold  Accuracy  Precision  Recall  F1-Score\n",
            "Model                                                         \n",
            "Decision Tree       3.0    0.8056     0.8435  0.8056    0.7984\n",
            "Gradient Boosting   3.0    0.7833     0.8315  0.7833    0.7819\n",
            "KNN                 3.0    0.7778     0.8185  0.7778    0.7763\n",
            "Random Forest       3.0    0.8306     0.8620  0.8306    0.8257\n",
            "SVM                 3.0    0.8278     0.8602  0.8278    0.8213\n",
            "\n",
            "Voting Classifier Results (using top 3 models):\n",
            "Accuracy: 0.8056 (+/- 0.1043)\n",
            "Precision: 0.8454 (+/- 0.1028)\n",
            "Recall: 0.8056 (+/- 0.1043)\n",
            "F1-Score: 0.7991 (+/- 0.1058)\n",
            "\n",
            "Best Model Selection:\n",
            "Best Individual Model: Random Forest\n",
            "Best Individual Model Accuracy: 0.8306\n",
            "Voting Classifier Accuracy: 0.8056\n",
            "Final Recommendation: Use Random Forest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Read and prepare the data\n",
        "df = pd.read_csv('/content/sample_data/audio_features - Copy.csv')\n",
        "X = df.drop(['file_name'], axis=1)\n",
        "y = df['file_name']\n",
        "\n",
        "# Initialize models with optimized hyperparameters\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(max_depth=8, min_samples_split=5, random_state=42),\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, random_state=42),\n",
        "    'SVM': SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5, weights='distance'),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42)\n",
        "}\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Initialize results storage\n",
        "results = {model_name: {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "          for model_name in models.keys()}\n",
        "\n",
        "# Perform 5-fold cross validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Evaluate each model\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
        "    print(f\"\\nFold {fold}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Split and scale data\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Evaluate each model\n",
        "    for model_name, model in models.items():\n",
        "        accuracy, precision, recall, f1 = evaluate_model(\n",
        "            model, X_train_scaled, X_test_scaled, y_train, y_test\n",
        "        )\n",
        "\n",
        "        results[model_name]['accuracy'].append(accuracy)\n",
        "        results[model_name]['precision'].append(precision)\n",
        "        results[model_name]['recall'].append(recall)\n",
        "        results[model_name]['f1'].append(f1)\n",
        "\n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1-score: {f1:.4f}\")\n",
        "\n",
        "# Print average results\n",
        "print(\"\\nAverage Results Across All Folds:\")\n",
        "print(\"-\" * 50)\n",
        "for model_name in models.keys():\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"Accuracy: {np.mean(results[model_name]['accuracy']):.4f} (+/- {np.std(results[model_name]['accuracy']):.4f})\")\n",
        "    print(f\"Precision: {np.mean(results[model_name]['precision']):.4f} (+/- {np.std(results[model_name]['precision']):.4f})\")\n",
        "    print(f\"Recall: {np.mean(results[model_name]['recall']):.4f} (+/- {np.std(results[model_name]['recall']):.4f})\")\n",
        "    print(f\"F1-score: {np.mean(results[model_name]['f1']):.4f} (+/- {np.std(results[model_name]['f1']):.4f})\")\n",
        "\n",
        "# Create and evaluate Voting Classifier\n",
        "print(\"\\nTraining Voting Classifier...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Initialize voting classifier\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5, random_state=42)),\n",
        "    ('svm', SVC(kernel='rbf', C=10, gamma='scale', probability=True, random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=200, learning_rate=0.1, max_depth=5, random_state=42))\n",
        "], voting='soft')\n",
        "\n",
        "# Evaluate voting classifier\n",
        "voting_results = {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(X, y), 1):\n",
        "    # Split and scale data\n",
        "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    # Evaluate voting classifier\n",
        "    accuracy, precision, recall, f1 = evaluate_model(\n",
        "        voting_clf, X_train_scaled, X_test_scaled, y_train, y_test\n",
        "    )\n",
        "\n",
        "    voting_results['accuracy'].append(accuracy)\n",
        "    voting_results['precision'].append(precision)\n",
        "    voting_results['recall'].append(recall)\n",
        "    voting_results['f1'].append(f1)\n",
        "\n",
        "# Print voting classifier results\n",
        "print(\"\\nVoting Classifier Results:\")\n",
        "print(f\"Accuracy: {np.mean(voting_results['accuracy']):.4f} (+/- {np.std(voting_results['accuracy']):.4f})\")\n",
        "print(f\"Precision: {np.mean(voting_results['precision']):.4f} (+/- {np.std(voting_results['precision']):.4f})\")\n",
        "print(f\"Recall: {np.mean(voting_results['recall']):.4f} (+/- {np.std(voting_results['recall']):.4f})\")\n",
        "print(f\"F1-score: {np.mean(voting_results['f1']):.4f} (+/- {np.std(voting_results['f1']):.4f})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8mlA7Crwnln",
        "outputId": "2f24540c-05c3-44a3-ffc5-28e5bc967538"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fold 1\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.7778\n",
            "Precision: 0.6667\n",
            "Recall: 0.7778\n",
            "F1-score: 0.7037\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8815\n",
            "\n",
            "SVM:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8815\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9167\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8783\n",
            "\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8815\n",
            "\n",
            "Fold 2\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8889\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8889\n",
            "\n",
            "SVM:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8815\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.7778\n",
            "Precision: 0.7778\n",
            "Recall: 0.7778\n",
            "F1-score: 0.7778\n",
            "\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8889\n",
            "\n",
            "Fold 3\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.6250\n",
            "Precision: 0.6667\n",
            "Recall: 0.6250\n",
            "F1-score: 0.6167\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.7500\n",
            "Recall: 0.7500\n",
            "F1-score: 0.7500\n",
            "\n",
            "SVM:\n",
            "Accuracy: 0.8750\n",
            "Precision: 0.9167\n",
            "Recall: 0.8750\n",
            "F1-score: 0.8667\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.7500\n",
            "Recall: 0.7500\n",
            "F1-score: 0.7500\n",
            "\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.6250\n",
            "Precision: 0.7500\n",
            "Recall: 0.6250\n",
            "F1-score: 0.6333\n",
            "\n",
            "Fold 4\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.8750\n",
            "Precision: 0.9167\n",
            "Recall: 0.8750\n",
            "F1-score: 0.8667\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.8750\n",
            "Precision: 0.9167\n",
            "Recall: 0.8750\n",
            "F1-score: 0.8667\n",
            "\n",
            "SVM:\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.7917\n",
            "Recall: 0.7500\n",
            "F1-score: 0.7417\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.7917\n",
            "Recall: 0.7500\n",
            "F1-score: 0.7417\n",
            "\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.8750\n",
            "Precision: 0.9167\n",
            "Recall: 0.8750\n",
            "F1-score: 0.8667\n",
            "\n",
            "Fold 5\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.7917\n",
            "Recall: 0.7500\n",
            "F1-score: 0.7417\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.7500\n",
            "Recall: 0.7500\n",
            "F1-score: 0.7500\n",
            "\n",
            "SVM:\n",
            "Accuracy: 0.6250\n",
            "Precision: 0.6667\n",
            "Recall: 0.6250\n",
            "F1-score: 0.6167\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.8333\n",
            "Recall: 0.7500\n",
            "F1-score: 0.7333\n",
            "\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.7500\n",
            "Precision: 0.7917\n",
            "Recall: 0.7500\n",
            "F1-score: 0.7417\n",
            "\n",
            "Average Results Across All Folds:\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.7833 (+/- 0.0957)\n",
            "Precision: 0.7935 (+/- 0.1139)\n",
            "Recall: 0.7833 (+/- 0.0957)\n",
            "F1-score: 0.7635 (+/- 0.1020)\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.8306 (+/- 0.0660)\n",
            "Precision: 0.8537 (+/- 0.0847)\n",
            "Recall: 0.8306 (+/- 0.0660)\n",
            "F1-score: 0.8274 (+/- 0.0636)\n",
            "\n",
            "SVM:\n",
            "Accuracy: 0.8056 (+/- 0.1043)\n",
            "Precision: 0.8454 (+/- 0.1028)\n",
            "Recall: 0.8056 (+/- 0.1043)\n",
            "F1-score: 0.7976 (+/- 0.1046)\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.7833 (+/- 0.0539)\n",
            "Precision: 0.8139 (+/- 0.0580)\n",
            "Recall: 0.7833 (+/- 0.0539)\n",
            "F1-score: 0.7762 (+/- 0.0532)\n",
            "\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.8056 (+/- 0.1043)\n",
            "Precision: 0.8620 (+/- 0.0757)\n",
            "Recall: 0.8056 (+/- 0.1043)\n",
            "F1-score: 0.8024 (+/- 0.1001)\n",
            "\n",
            "Training Voting Classifier...\n",
            "--------------------------------------------------\n",
            "\n",
            "Voting Classifier Results:\n",
            "Accuracy: 0.8306 (+/- 0.0660)\n",
            "Precision: 0.8620 (+/- 0.0757)\n",
            "Recall: 0.8306 (+/- 0.0660)\n",
            "F1-score: 0.8257 (+/- 0.0657)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Read and prepare the data\n",
        "df = pd.read_csv('/content/sample_data/audio_features - Copy.csv')\n",
        "X = df.drop(['file_name'], axis=1)\n",
        "y = df['file_name']\n",
        "\n",
        "# Initial train-test split (80-20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize models with optimized hyperparameters\n",
        "models = {\n",
        "    'Decision Tree': DecisionTreeClassifier(\n",
        "        max_depth=8,\n",
        "        min_samples_split=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    'Random Forest': RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    'SVM': SVC(\n",
        "        kernel='rbf',\n",
        "        C=10,\n",
        "        gamma='scale',\n",
        "        class_weight='balanced',\n",
        "        probability=True,\n",
        "        random_state=42\n",
        "    ),\n",
        "    'KNN': KNeighborsClassifier(\n",
        "        n_neighbors=5,\n",
        "        weights='distance',\n",
        "        metric='euclidean'\n",
        "    ),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test, model_name=\"\"):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Initialize results storage for cross-validation\n",
        "cv_results = {model_name: {'accuracy': [], 'precision': [], 'recall': [], 'f1': []}\n",
        "             for model_name in models.keys()}\n",
        "\n",
        "# Perform 5-fold cross validation on training data\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"Performing 5-fold Cross-validation on Training Data...\")\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X_train_scaled, y_train), 1):\n",
        "    print(f\"\\nFold {fold}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    # Split training data into training and validation\n",
        "    X_train_fold = X_train_scaled[train_idx]\n",
        "    X_val_fold = X_train_scaled[val_idx]\n",
        "    y_train_fold = y_train.iloc[train_idx]\n",
        "    y_val_fold = y_train.iloc[val_idx]\n",
        "\n",
        "    # Evaluate each model\n",
        "    for model_name, model in models.items():\n",
        "        model_clone = model.__class__(**model.get_params())\n",
        "        accuracy, precision, recall, f1 = evaluate_model(\n",
        "            model_clone, X_train_fold, X_val_fold, y_train_fold, y_val_fold, model_name\n",
        "        )\n",
        "\n",
        "        cv_results[model_name]['accuracy'].append(accuracy)\n",
        "        cv_results[model_name]['precision'].append(precision)\n",
        "        cv_results[model_name]['recall'].append(recall)\n",
        "        cv_results[model_name]['f1'].append(f1)\n",
        "\n",
        "# Print average cross-validation results\n",
        "print(\"\\nAverage Cross-validation Results:\")\n",
        "print(\"-\" * 50)\n",
        "best_accuracy = 0\n",
        "best_model_name = \"\"\n",
        "\n",
        "for model_name in models.keys():\n",
        "    avg_accuracy = np.mean(cv_results[model_name]['accuracy'])\n",
        "    avg_precision = np.mean(cv_results[model_name]['precision'])\n",
        "    avg_recall = np.mean(cv_results[model_name]['recall'])\n",
        "    avg_f1 = np.mean(cv_results[model_name]['f1'])\n",
        "\n",
        "    if avg_accuracy > best_accuracy:\n",
        "        best_accuracy = avg_accuracy\n",
        "        best_model_name = model_name\n",
        "\n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"Accuracy: {avg_accuracy:.4f} (+/- {np.std(cv_results[model_name]['accuracy']):.4f})\")\n",
        "    print(f\"Precision: {avg_precision:.4f} (+/- {np.std(cv_results[model_name]['precision']):.4f})\")\n",
        "    print(f\"Recall: {avg_recall:.4f} (+/- {np.std(cv_results[model_name]['recall']):.4f})\")\n",
        "    print(f\"F1-score: {avg_f1:.4f} (+/- {np.std(cv_results[model_name]['f1']):.4f})\")\n",
        "\n",
        "print(f\"\\nBest performing model in cross-validation: {best_model_name}\")\n",
        "\n",
        "# Create and evaluate Voting Classifier on test set\n",
        "print(\"\\nTraining Voting Classifier...\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('rf', RandomForestClassifier(n_estimators=200, max_depth=10, min_samples_split=5,\n",
        "                                 class_weight='balanced', random_state=42)),\n",
        "    ('svm', SVC(kernel='rbf', C=10, gamma='scale', probability=True,\n",
        "                class_weight='balanced', random_state=42)),\n",
        "    ('gb', GradientBoostingClassifier(n_estimators=200, learning_rate=0.1,\n",
        "                                     max_depth=5, random_state=42))\n",
        "], voting='soft')\n",
        "\n",
        "# Final evaluation on test set\n",
        "print(\"\\nFinal Evaluation on Test Set:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Evaluate best individual model\n",
        "best_model = models[best_model_name]\n",
        "print(f\"\\nBest Individual Model ({best_model_name}):\")\n",
        "evaluate_model(best_model, X_train_scaled, X_test_scaled, y_train, y_test, best_model_name)\n",
        "\n",
        "# Evaluate voting classifier\n",
        "print(\"\\nVoting Classifier:\")\n",
        "evaluate_model(voting_clf, X_train_scaled, X_test_scaled, y_train, y_test, \"Voting Classifier\")\n",
        "\n",
        "# Feature importance for Random Forest (one of the best performing models)\n",
        "if isinstance(best_model, (RandomForestClassifier, GradientBoostingClassifier)):\n",
        "    print(\"\\nFeature Importance:\")\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': best_model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    print(feature_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fKalalgJyJD_",
        "outputId": "2fd86931-b0ba-47bb-8540-4b59290da8b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 5-fold Cross-validation on Training Data...\n",
            "\n",
            "Fold 1\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy: 0.7143\n",
            "Precision: 0.7143\n",
            "Recall: 0.7143\n",
            "F1-score: 0.6667\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.71         7\n",
            "   macro avg       0.62      0.62      0.58         7\n",
            "weighted avg       0.71      0.71      0.67         7\n",
            "\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.5714\n",
            "Precision: 0.7143\n",
            "Recall: 0.5714\n",
            "F1-score: 0.5714\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.57         7\n",
            "   macro avg       0.62      0.50      0.50         7\n",
            "weighted avg       0.71      0.57      0.57         7\n",
            "\n",
            "\n",
            "SVM Results:\n",
            "Accuracy: 0.7143\n",
            "Precision: 0.7143\n",
            "Recall: 0.7143\n",
            "F1-score: 0.6667\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.71         7\n",
            "   macro avg       0.62      0.62      0.58         7\n",
            "weighted avg       0.71      0.71      0.67         7\n",
            "\n",
            "\n",
            "KNN Results:\n",
            "Accuracy: 0.5714\n",
            "Precision: 0.7143\n",
            "Recall: 0.5714\n",
            "F1-score: 0.5714\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.57         7\n",
            "   macro avg       0.62      0.50      0.50         7\n",
            "weighted avg       0.71      0.57      0.57         7\n",
            "\n",
            "\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 0.5714\n",
            "Precision: 0.7143\n",
            "Recall: 0.5714\n",
            "F1-score: 0.5714\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.00      0.00      0.00         1\n",
            "           3       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.57         7\n",
            "   macro avg       0.62      0.50      0.50         7\n",
            "weighted avg       0.71      0.57      0.57         7\n",
            "\n",
            "\n",
            "Fold 2\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy: 0.8571\n",
            "Precision: 0.9048\n",
            "Recall: 0.8571\n",
            "F1-score: 0.8476\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.86         7\n",
            "   macro avg       0.92      0.88      0.87         7\n",
            "weighted avg       0.90      0.86      0.85         7\n",
            "\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         7\n",
            "   macro avg       1.00      1.00      1.00         7\n",
            "weighted avg       1.00      1.00      1.00         7\n",
            "\n",
            "\n",
            "SVM Results:\n",
            "Accuracy: 0.7143\n",
            "Precision: 0.8333\n",
            "Recall: 0.7143\n",
            "F1-score: 0.7048\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       1.00      0.50      0.67         2\n",
            "           3       0.67      1.00      0.80         2\n",
            "\n",
            "    accuracy                           0.71         7\n",
            "   macro avg       0.79      0.75      0.70         7\n",
            "weighted avg       0.83      0.71      0.70         7\n",
            "\n",
            "\n",
            "KNN Results:\n",
            "Accuracy: 0.8571\n",
            "Precision: 0.9286\n",
            "Recall: 0.8571\n",
            "F1-score: 0.8571\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           0.86         7\n",
            "   macro avg       0.88      0.88      0.83         7\n",
            "weighted avg       0.93      0.86      0.86         7\n",
            "\n",
            "\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 0.7143\n",
            "Precision: 0.5714\n",
            "Recall: 0.7143\n",
            "F1-score: 0.6190\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.50      1.00      0.67         2\n",
            "\n",
            "    accuracy                           0.71         7\n",
            "   macro avg       0.62      0.75      0.67         7\n",
            "weighted avg       0.57      0.71      0.62         7\n",
            "\n",
            "\n",
            "Fold 3\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy: 0.8571\n",
            "Precision: 0.9286\n",
            "Recall: 0.8571\n",
            "F1-score: 0.8571\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.86         7\n",
            "   macro avg       0.88      0.88      0.83         7\n",
            "weighted avg       0.93      0.86      0.86         7\n",
            "\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.8571\n",
            "Precision: 0.9286\n",
            "Recall: 0.8571\n",
            "F1-score: 0.8571\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.86         7\n",
            "   macro avg       0.88      0.88      0.83         7\n",
            "weighted avg       0.93      0.86      0.86         7\n",
            "\n",
            "\n",
            "SVM Results:\n",
            "Accuracy: 0.8571\n",
            "Precision: 0.9286\n",
            "Recall: 0.8571\n",
            "F1-score: 0.8571\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.86         7\n",
            "   macro avg       0.88      0.88      0.83         7\n",
            "weighted avg       0.93      0.86      0.86         7\n",
            "\n",
            "\n",
            "KNN Results:\n",
            "Accuracy: 0.8571\n",
            "Precision: 0.9286\n",
            "Recall: 0.8571\n",
            "F1-score: 0.8571\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      1.00      0.67         1\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.86         7\n",
            "   macro avg       0.88      0.88      0.83         7\n",
            "weighted avg       0.93      0.86      0.86         7\n",
            "\n",
            "\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 0.7143\n",
            "Precision: 0.9048\n",
            "Recall: 0.7143\n",
            "F1-score: 0.7381\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.33      1.00      0.50         1\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      0.50      0.67         2\n",
            "\n",
            "    accuracy                           0.71         7\n",
            "   macro avg       0.83      0.75      0.71         7\n",
            "weighted avg       0.90      0.71      0.74         7\n",
            "\n",
            "\n",
            "Fold 4\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy: 0.6667\n",
            "Precision: 0.5833\n",
            "Recall: 0.6667\n",
            "F1-score: 0.6111\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       0.50      1.00      0.67         1\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         6\n",
            "   macro avg       0.50      0.62      0.54         6\n",
            "weighted avg       0.58      0.67      0.61         6\n",
            "\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.8333\n",
            "Precision: 0.9167\n",
            "Recall: 0.8333\n",
            "F1-score: 0.8333\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.50      1.00      0.67         1\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.83         6\n",
            "   macro avg       0.88      0.88      0.83         6\n",
            "weighted avg       0.92      0.83      0.83         6\n",
            "\n",
            "\n",
            "SVM Results:\n",
            "Accuracy: 0.8333\n",
            "Precision: 0.9167\n",
            "Recall: 0.8333\n",
            "F1-score: 0.8333\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.50      1.00      0.67         1\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.83         6\n",
            "   macro avg       0.88      0.88      0.83         6\n",
            "weighted avg       0.92      0.83      0.83         6\n",
            "\n",
            "\n",
            "KNN Results:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         6\n",
            "   macro avg       1.00      1.00      1.00         6\n",
            "weighted avg       1.00      1.00      1.00         6\n",
            "\n",
            "\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 0.6667\n",
            "Precision: 0.5833\n",
            "Recall: 0.6667\n",
            "F1-score: 0.6111\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       0.50      1.00      0.67         1\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         6\n",
            "   macro avg       0.50      0.62      0.54         6\n",
            "weighted avg       0.58      0.67      0.61         6\n",
            "\n",
            "\n",
            "Fold 5\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree Results:\n",
            "Accuracy: 0.6667\n",
            "Precision: 0.5556\n",
            "Recall: 0.6667\n",
            "F1-score: 0.6000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         6\n",
            "   macro avg       0.54      0.62      0.57         6\n",
            "weighted avg       0.56      0.67      0.60         6\n",
            "\n",
            "\n",
            "Random Forest Results:\n",
            "Accuracy: 0.6667\n",
            "Precision: 0.6667\n",
            "Recall: 0.6667\n",
            "F1-score: 0.6667\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         6\n",
            "   macro avg       0.62      0.62      0.62         6\n",
            "weighted avg       0.67      0.67      0.67         6\n",
            "\n",
            "\n",
            "SVM Results:\n",
            "Accuracy: 0.8333\n",
            "Precision: 0.9167\n",
            "Recall: 0.8333\n",
            "F1-score: 0.8333\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.83         6\n",
            "   macro avg       0.88      0.88      0.83         6\n",
            "weighted avg       0.92      0.83      0.83         6\n",
            "\n",
            "\n",
            "KNN Results:\n",
            "Accuracy: 0.8333\n",
            "Precision: 0.8889\n",
            "Recall: 0.8333\n",
            "F1-score: 0.8222\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.83         6\n",
            "   macro avg       0.92      0.88      0.87         6\n",
            "weighted avg       0.89      0.83      0.82         6\n",
            "\n",
            "\n",
            "Gradient Boosting Results:\n",
            "Accuracy: 0.6667\n",
            "Precision: 0.5556\n",
            "Recall: 0.6667\n",
            "F1-score: 0.6000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.50      0.50      0.50         2\n",
            "           1       1.00      1.00      1.00         1\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       0.00      0.00      0.00         1\n",
            "\n",
            "    accuracy                           0.67         6\n",
            "   macro avg       0.54      0.62      0.57         6\n",
            "weighted avg       0.56      0.67      0.60         6\n",
            "\n",
            "\n",
            "Average Cross-validation Results:\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree:\n",
            "Accuracy: 0.7524 (+/- 0.0873)\n",
            "Precision: 0.7373 (+/- 0.1561)\n",
            "Recall: 0.7524 (+/- 0.0873)\n",
            "F1-score: 0.7165 (+/- 0.1133)\n",
            "\n",
            "Random Forest:\n",
            "Accuracy: 0.7857 (+/- 0.1506)\n",
            "Precision: 0.8452 (+/- 0.1304)\n",
            "Recall: 0.7857 (+/- 0.1506)\n",
            "F1-score: 0.7857 (+/- 0.1506)\n",
            "\n",
            "SVM:\n",
            "Accuracy: 0.7905 (+/- 0.0628)\n",
            "Precision: 0.8619 (+/- 0.0813)\n",
            "Recall: 0.7905 (+/- 0.0628)\n",
            "F1-score: 0.7790 (+/- 0.0776)\n",
            "\n",
            "KNN:\n",
            "Accuracy: 0.8238 (+/- 0.1393)\n",
            "Precision: 0.8921 (+/- 0.0958)\n",
            "Recall: 0.8238 (+/- 0.1393)\n",
            "F1-score: 0.8216 (+/- 0.1392)\n",
            "\n",
            "Gradient Boosting:\n",
            "Accuracy: 0.6667 (+/- 0.0522)\n",
            "Precision: 0.6659 (+/- 0.1321)\n",
            "Recall: 0.6667 (+/- 0.0522)\n",
            "F1-score: 0.6279 (+/- 0.0574)\n",
            "\n",
            "Best performing model in cross-validation: KNN\n",
            "\n",
            "Training Voting Classifier...\n",
            "--------------------------------------------------\n",
            "\n",
            "Final Evaluation on Test Set:\n",
            "--------------------------------------------------\n",
            "\n",
            "Best Individual Model (KNN):\n",
            "\n",
            "KNN Results:\n",
            "Accuracy: 0.7778\n",
            "Precision: 0.8519\n",
            "Recall: 0.7778\n",
            "F1-score: 0.7704\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.67      1.00      0.80         2\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.78         9\n",
            "   macro avg       0.83      0.79      0.77         9\n",
            "weighted avg       0.85      0.78      0.77         9\n",
            "\n",
            "\n",
            "Voting Classifier:\n",
            "\n",
            "Voting Classifier Results:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/sample_data/audio_features - Copy.csv\"\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Extract features and target variable\n",
        "X = dataset.drop(columns=[\"file_name\"])  # Replace 'file_name' with the actual target column name if different\n",
        "y = dataset[\"file_name\"]\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(probability=True),  # probability=True for voting\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Perform 5-fold cross-validation and choose the best model based on mean accuracy\n",
        "best_model = None\n",
        "best_score = 0\n",
        "cv_scores = {}\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "    cv_scores[model_name] = scores.mean()\n",
        "    print(f\"{model_name} - CV Mean Accuracy: {scores.mean():.4f}\")\n",
        "\n",
        "    # Update best model if this model's accuracy is better\n",
        "    if scores.mean() > best_score:\n",
        "        best_score = scores.mean()\n",
        "        best_model = model_name\n",
        "\n",
        "print(\"\\nBest Model from Cross-Validation:\", best_model, \"with accuracy:\", best_score)\n",
        "\n",
        "# Fit each model on training data and evaluate on test data\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{model_name} - Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Voting Ensemble with the top 3 performing models from cross-validation\n",
        "top_models = sorted(cv_scores, key=cv_scores.get, reverse=True)[:3]\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[(name, models[name]) for name in top_models],\n",
        "    voting='soft'\n",
        ")\n",
        "ensemble.fit(X_train, y_train)\n",
        "ensemble_pred = ensemble.predict(X_test)\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_pred)\n",
        "print(\"\\nVoting Ensemble Test Accuracy:\", ensemble_accuracy)\n",
        "\n",
        "# Determine the best-performing model\n",
        "final_model = ensemble if ensemble_accuracy >= best_score else models[best_model]\n",
        "print(\"\\nBest Model:\", \"Voting Ensemble\" if final_model == ensemble else best_model)\n",
        "print(\"Final Model Test Accuracy:\", max(ensemble_accuracy, best_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD0P9CXry2WW",
        "outputId": "50067ff4-47fb-4ac5-fc99-c321e7f73c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree - CV Mean Accuracy: 0.7952\n",
            "Random Forest - CV Mean Accuracy: 0.8238\n",
            "SVM - CV Mean Accuracy: 0.3048\n",
            "KNN - CV Mean Accuracy: 0.6619\n",
            "Gradient Boosting - CV Mean Accuracy: 0.7905\n",
            "\n",
            "Best Model from Cross-Validation: Random Forest with accuracy: 0.8238095238095238\n",
            "Decision Tree - Test Accuracy: 0.8889\n",
            "Random Forest - Test Accuracy: 1.0000\n",
            "SVM - Test Accuracy: 0.1111\n",
            "KNN - Test Accuracy: 0.8889\n",
            "Gradient Boosting - Test Accuracy: 1.0000\n",
            "\n",
            "Voting Ensemble Test Accuracy: 1.0\n",
            "\n",
            "Best Model: Voting Ensemble\n",
            "Final Model Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/sample_data/audio_features - Copy.csv\"\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Extract features and target variable\n",
        "X = dataset.drop(columns=[\"file_name\"])  # Replace 'file_name' with the actual target column name if different\n",
        "y = dataset[\"file_name\"]\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define parameter grids for each model\n",
        "param_grids = {\n",
        "    \"Decision Tree\": {\n",
        "        'clf__max_depth': [None, 10, 20, 30],\n",
        "        'clf__min_samples_split': [2, 5, 10]\n",
        "    },\n",
        "    \"Random Forest\": {\n",
        "        'clf__n_estimators': [50, 100, 150],\n",
        "        'clf__max_depth': [None, 10, 20, 30]\n",
        "    },\n",
        "    \"SVM\": {\n",
        "        'clf__C': [0.1, 1, 10],\n",
        "        'clf__gamma': ['scale', 'auto']\n",
        "    },\n",
        "    \"KNN\": {\n",
        "        'clf__n_neighbors': [3, 5, 7],\n",
        "        'clf__weights': ['uniform', 'distance']\n",
        "    },\n",
        "    \"Gradient Boosting\": {\n",
        "        'clf__n_estimators': [50, 100, 150],\n",
        "        'clf__learning_rate': [0.01, 0.1, 0.2]\n",
        "    }\n",
        "}\n",
        "\n",
        "# Define models\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(probability=True),  # probability=True for voting\n",
        "    \"KNN\": KNeighborsClassifier(),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier()\n",
        "}\n",
        "\n",
        "# Standardize data and apply hyperparameter tuning\n",
        "best_model = None\n",
        "best_score = 0\n",
        "cv_scores = {}\n",
        "for model_name, model in models.items():\n",
        "    pipe = Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', model)\n",
        "    ])\n",
        "    grid_search = GridSearchCV(pipe, param_grids[model_name], cv=5, scoring='accuracy')\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    cv_score = grid_search.best_score_\n",
        "    cv_scores[model_name] = cv_score\n",
        "    print(f\"{model_name} - Best CV Mean Accuracy: {cv_score:.4f}\")\n",
        "\n",
        "    # Update best model if this model's accuracy is better\n",
        "    if cv_score > best_score:\n",
        "        best_score = cv_score\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"\\nBest Model from Cross-Validation:\", best_model, \"with accuracy:\", best_score)\n",
        "\n",
        "# Evaluate each model on the test set\n",
        "for model_name, model in models.items():\n",
        "    best_estimator = GridSearchCV(Pipeline([('scaler', StandardScaler()), ('clf', model)]), param_grids[model_name], cv=5).fit(X_train, y_train).best_estimator_\n",
        "    y_pred = best_estimator.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"{model_name} - Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Voting Ensemble with the top 3 performing models from cross-validation\n",
        "top_models = sorted(cv_scores, key=cv_scores.get, reverse=True)[:3]\n",
        "ensemble_estimators = [(name, GridSearchCV(Pipeline([('scaler', StandardScaler()), ('clf', models[name])]), param_grids[name], cv=5).fit(X_train, y_train).best_estimator_) for name in top_models]\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=ensemble_estimators,\n",
        "    voting='soft'\n",
        ")\n",
        "ensemble.fit(X_train, y_train)\n",
        "ensemble_pred = ensemble.predict(X_test)\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_pred)\n",
        "print(\"\\nVoting Ensemble Test Accuracy:\", ensemble_accuracy)\n",
        "\n",
        "# Determine the best-performing model\n",
        "final_model = ensemble if ensemble_accuracy >= best_score else best_model\n",
        "print(\"\\nBest Model:\", \"Voting Ensemble\" if final_model == ensemble else best_model)\n",
        "print(\"Final Model Test Accuracy:\", max(ensemble_accuracy, best_score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O7Hv0oFUzt6n",
        "outputId": "ad8231e2-4c7a-4c8d-8687-1ff46b1b4400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree - Best CV Mean Accuracy: 0.8524\n",
            "Random Forest - Best CV Mean Accuracy: 0.8238\n",
            "SVM - Best CV Mean Accuracy: 0.7619\n",
            "KNN - Best CV Mean Accuracy: 0.7571\n",
            "Gradient Boosting - Best CV Mean Accuracy: 0.7905\n",
            "\n",
            "Best Model from Cross-Validation: Pipeline(steps=[('scaler', StandardScaler()),\n",
            "                ('clf',\n",
            "                 DecisionTreeClassifier(max_depth=10, min_samples_split=10))]) with accuracy: 0.8523809523809524\n",
            "Decision Tree - Test Accuracy: 0.8889\n",
            "Random Forest - Test Accuracy: 1.0000\n",
            "SVM - Test Accuracy: 0.8889\n",
            "KNN - Test Accuracy: 0.8889\n",
            "Gradient Boosting - Test Accuracy: 1.0000\n",
            "\n",
            "Voting Ensemble Test Accuracy: 1.0\n",
            "\n",
            "Best Model: Voting Ensemble\n",
            "Final Model Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load and prepare the dataset\n",
        "dataset = pd.read_csv('/content/sample_data/audio_features - Copy.csv')\n",
        "X = dataset.drop(columns=[\"file_name\"])\n",
        "y = dataset[\"file_name\"]\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define optimized models\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(\n",
        "        max_depth=8,\n",
        "        min_samples_split=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"SVM\": SVC(\n",
        "        kernel='rbf',\n",
        "        C=10,\n",
        "        gamma='scale',\n",
        "        probability=True,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"KNN\": KNeighborsClassifier(\n",
        "        n_neighbors=5,\n",
        "        weights='distance',\n",
        "        metric='euclidean'\n",
        "    ),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# Function to evaluate and print metrics\n",
        "def print_metrics(y_true, y_pred, model_name=\"\"):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"\\n{model_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Perform 5-fold cross-validation with multiple metrics\n",
        "print(\"Performing 5-fold Cross-validation:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "cv_results = {}\n",
        "scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_validate(model, X_train_scaled, y_train,\n",
        "                          cv=5, scoring=scoring, return_train_score=False)\n",
        "\n",
        "    cv_results[model_name] = {\n",
        "        'accuracy': scores['test_accuracy'].mean(),\n",
        "        'precision': scores['test_precision_weighted'].mean(),\n",
        "        'recall': scores['test_recall_weighted'].mean(),\n",
        "        'f1': scores['test_f1_weighted'].mean(),\n",
        "        'std_accuracy': scores['test_accuracy'].std()\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{model_name} - Cross-validation Results:\")\n",
        "    print(f\"Accuracy: {scores['test_accuracy'].mean():.4f} (+/- {scores['test_accuracy'].std():.4f})\")\n",
        "    print(f\"Precision: {scores['test_precision_weighted'].mean():.4f}\")\n",
        "    print(f\"Recall: {scores['test_recall_weighted'].mean():.4f}\")\n",
        "    print(f\"F1-score: {scores['test_f1_weighted'].mean():.4f}\")\n",
        "\n",
        "# Find best model from cross-validation\n",
        "best_model = max(cv_results.items(), key=lambda x: x[1]['accuracy'])\n",
        "print(f\"\\nBest Model from Cross-validation: {best_model[0]}\")\n",
        "print(f\"CV Accuracy: {best_model[1]['accuracy']:.4f}\")\n",
        "\n",
        "# Train and evaluate individual models on test set\n",
        "print(\"\\nEvaluating Models on Test Set:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "test_results = {}\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    test_results[model_name] = print_metrics(y_test, y_pred, model_name)\n",
        "\n",
        "# Select top 3 models for voting ensemble\n",
        "top_models = sorted(cv_results.items(), key=lambda x: x[1]['accuracy'], reverse=True)[:3]\n",
        "top_model_names = [model[0] for model in top_models]\n",
        "\n",
        "print(\"\\nTop 3 Models selected for Voting Ensemble:\")\n",
        "for model_name in top_model_names:\n",
        "    print(f\"{model_name}: CV Accuracy = {cv_results[model_name]['accuracy']:.4f}\")\n",
        "\n",
        "# Create and evaluate voting ensemble\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[(name, models[name]) for name in top_model_names],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "print(\"\\nTraining and Evaluating Voting Ensemble:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "voting_clf.fit(X_train_scaled, y_train)\n",
        "ensemble_pred = voting_clf.predict(X_test_scaled)\n",
        "ensemble_metrics = print_metrics(y_test, ensemble_pred, \"Voting Ensemble\")\n",
        "\n",
        "# Determine final best model\n",
        "final_ensemble_accuracy = ensemble_metrics[0]\n",
        "final_best_model_accuracy = max(test_results.items(), key=lambda x: x[1][0])[1][0]\n",
        "\n",
        "if final_ensemble_accuracy > final_best_model_accuracy:\n",
        "    print(\"\\nFinal Best Model: Voting Ensemble\")\n",
        "    print(f\"Final Accuracy: {final_ensemble_accuracy:.4f}\")\n",
        "else:\n",
        "    best_individual = max(test_results.items(), key=lambda x: x[1][0])[0]\n",
        "    print(f\"\\nFinal Best Model: {best_individual}\")\n",
        "    print(f\"Final Accuracy: {final_best_model_accuracy:.4f}\")\n",
        "\n",
        "# Feature importance for best model (if applicable)\n",
        "best_model_instance = models[best_model[0]]\n",
        "if hasattr(best_model_instance, 'feature_importances_'):\n",
        "    print(\"\\nFeature Importance for Best Model:\")\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': best_model_instance.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    print(feature_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MnyupEto1REz",
        "outputId": "126e152f-a297-4a5d-f70d-5a63ee16f0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 5-fold Cross-validation:\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree - Cross-validation Results:\n",
            "Accuracy: 0.6714 (+/- 0.1611)\n",
            "Precision: 0.6476\n",
            "Recall: 0.6714\n",
            "F1-score: 0.6375\n",
            "\n",
            "Random Forest - Cross-validation Results:\n",
            "Accuracy: 0.6714 (+/- 0.1333)\n",
            "Precision: 0.6516\n",
            "Recall: 0.6714\n",
            "F1-score: 0.6271\n",
            "\n",
            "SVM - Cross-validation Results:\n",
            "Accuracy: 0.7286 (+/- 0.1061)\n",
            "Precision: 0.7244\n",
            "Recall: 0.7286\n",
            "F1-score: 0.6841\n",
            "\n",
            "KNN - Cross-validation Results:\n",
            "Accuracy: 0.7905 (+/- 0.1424)\n",
            "Precision: 0.7832\n",
            "Recall: 0.7905\n",
            "F1-score: 0.7552\n",
            "\n",
            "Gradient Boosting - Cross-validation Results:\n",
            "Accuracy: 0.7048 (+/- 0.1480)\n",
            "Precision: 0.6794\n",
            "Recall: 0.7048\n",
            "F1-score: 0.6616\n",
            "\n",
            "Best Model from Cross-validation: KNN\n",
            "CV Accuracy: 0.7905\n",
            "\n",
            "Evaluating Models on Test Set:\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree Metrics:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "\n",
            "Random Forest Metrics:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8815\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.67      1.00      0.80         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.89         9\n",
            "   macro avg       0.92      0.88      0.87         9\n",
            "weighted avg       0.93      0.89      0.88         9\n",
            "\n",
            "\n",
            "SVM Metrics:\n",
            "Accuracy: 0.7778\n",
            "Precision: 0.8519\n",
            "Recall: 0.7778\n",
            "F1-score: 0.7704\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.67      1.00      0.80         2\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.78         9\n",
            "   macro avg       0.83      0.79      0.77         9\n",
            "weighted avg       0.85      0.78      0.77         9\n",
            "\n",
            "\n",
            "KNN Metrics:\n",
            "Accuracy: 0.7778\n",
            "Precision: 0.8519\n",
            "Recall: 0.7778\n",
            "F1-score: 0.7704\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.67      1.00      0.80         2\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.78         9\n",
            "   macro avg       0.83      0.79      0.77         9\n",
            "weighted avg       0.85      0.78      0.77         9\n",
            "\n",
            "\n",
            "Gradient Boosting Metrics:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "\n",
            "Top 3 Models selected for Voting Ensemble:\n",
            "KNN: CV Accuracy = 0.7905\n",
            "SVM: CV Accuracy = 0.7286\n",
            "Gradient Boosting: CV Accuracy = 0.7048\n",
            "\n",
            "Training and Evaluating Voting Ensemble:\n",
            "--------------------------------------------------\n",
            "\n",
            "Voting Ensemble Metrics:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "\n",
            "Final Best Model: Decision Tree\n",
            "Final Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/sample_data/audio_features - Copy.csv\"\n",
        "dataset = pd.read_csv(file_path)\n",
        "\n",
        "# Extract features and target variable\n",
        "X = dataset.drop(columns=[\"file_name\"])  # Update target column name if different\n",
        "y = dataset[\"file_name\"]\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define base models with parameter grids for hyperparameter tuning\n",
        "param_grids = {\n",
        "    \"Decision Tree\": (DecisionTreeClassifier(), {\"max_depth\": [5, 10, 15, None]}),\n",
        "    \"Random Forest\": (RandomForestClassifier(), {\"n_estimators\": [50, 100, 200], \"max_depth\": [5, 10, None]}),\n",
        "    \"SVM\": (SVC(probability=True), {\"C\": [0.1, 1, 10], \"kernel\": [\"linear\", \"rbf\"]}),\n",
        "    \"KNN\": (KNeighborsClassifier(), {\"n_neighbors\": [3, 5, 7], \"weights\": [\"uniform\", \"distance\"]}),\n",
        "    \"Gradient Boosting\": (GradientBoostingClassifier(), {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.01, 0.1, 0.2]})\n",
        "}\n",
        "\n",
        "# Perform 5-fold cross-validation with hyperparameter tuning\n",
        "best_models = {}\n",
        "cv_scores = {}\n",
        "\n",
        "for model_name, (model, params) in param_grids.items():\n",
        "    grid_search = GridSearchCV(model, params, cv=5, scoring=\"accuracy\")\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    best_models[model_name] = grid_search.best_estimator_\n",
        "    cv_scores[model_name] = grid_search.best_score_\n",
        "    print(f\"{model_name} - Best CV Mean Accuracy: {grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Voting Ensemble with the top 3 performing models\n",
        "top_models = sorted(cv_scores, key=cv_scores.get, reverse=True)[:3]\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[(name, best_models[name]) for name in top_models],\n",
        "    voting='soft'\n",
        ")\n",
        "ensemble.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate all models on the test set\n",
        "for model_name, model in best_models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_test, y_pred, average=\"weighted\")\n",
        "    f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
        "    print(f\"\\n{model_name} - Test Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"{model_name} - Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "# Evaluate the ensemble model on the test set\n",
        "ensemble_pred = ensemble.predict(X_test)\n",
        "ensemble_accuracy = accuracy_score(y_test, ensemble_pred)\n",
        "ensemble_precision = precision_score(y_test, ensemble_pred, average=\"weighted\")\n",
        "ensemble_recall = recall_score(y_test, ensemble_pred, average=\"weighted\")\n",
        "ensemble_f1 = f1_score(y_test, ensemble_pred, average=\"weighted\")\n",
        "\n",
        "print(\"\\nVoting Ensemble - Test Accuracy:\", ensemble_accuracy)\n",
        "print(\"Voting Ensemble - Precision:\", ensemble_precision)\n",
        "print(\"Voting Ensemble - Recall:\", ensemble_recall)\n",
        "print(\"Voting Ensemble - F1 Score:\", ensemble_f1)\n",
        "print(classification_report(y_test, ensemble_pred))\n",
        "\n",
        "# Determine the best-performing model\n",
        "final_model = ensemble if ensemble_accuracy >= max(cv_scores.values()) else best_models[max(cv_scores, key=cv_scores.get)]\n",
        "print(\"\\nBest Model:\", \"Voting Ensemble\" if final_model == ensemble else max(cv_scores, key=cv_scores.get))\n",
        "print(\"Final Model Test Accuracy:\", max(ensemble_accuracy, max(cv_scores.values())))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KLAWscq2fpd",
        "outputId": "e63c8fb2-7f20-4e73-830d-23b9ffe67c04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree - Best CV Mean Accuracy: 0.8238\n",
            "Random Forest - Best CV Mean Accuracy: 0.8238\n",
            "SVM - Best CV Mean Accuracy: 0.7905\n",
            "KNN - Best CV Mean Accuracy: 0.7571\n",
            "Gradient Boosting - Best CV Mean Accuracy: 0.7905\n",
            "\n",
            "Decision Tree - Test Accuracy: 0.8889\n",
            "Decision Tree - Precision: 0.9111, Recall: 0.8889, F1 Score: 0.8765\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.80      1.00      0.89         4\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.89         9\n",
            "   macro avg       0.95      0.88      0.89         9\n",
            "weighted avg       0.91      0.89      0.88         9\n",
            "\n",
            "\n",
            "Random Forest - Test Accuracy: 1.0000\n",
            "Random Forest - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "\n",
            "SVM - Test Accuracy: 0.8889\n",
            "SVM - Precision: 0.9111, Recall: 0.8889, F1 Score: 0.8765\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      0.50      0.67         2\n",
            "           2       0.80      1.00      0.89         4\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           0.89         9\n",
            "   macro avg       0.95      0.88      0.89         9\n",
            "weighted avg       0.91      0.89      0.88         9\n",
            "\n",
            "\n",
            "KNN - Test Accuracy: 0.8889\n",
            "KNN - Precision: 0.9444, Recall: 0.8889, F1 Score: 0.8889\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       0.50      1.00      0.67         1\n",
            "\n",
            "    accuracy                           0.89         9\n",
            "   macro avg       0.88      0.88      0.83         9\n",
            "weighted avg       0.94      0.89      0.89         9\n",
            "\n",
            "\n",
            "Gradient Boosting - Test Accuracy: 1.0000\n",
            "Gradient Boosting - Precision: 1.0000, Recall: 1.0000, F1 Score: 1.0000\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "\n",
            "Voting Ensemble - Test Accuracy: 1.0\n",
            "Voting Ensemble - Precision: 1.0\n",
            "Voting Ensemble - Recall: 1.0\n",
            "Voting Ensemble - F1 Score: 1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         4\n",
            "           3       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "\n",
            "Best Model: Voting Ensemble\n",
            "Final Model Test Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_validate\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load and prepare the dataset\n",
        "dataset = pd.read_csv('/content/sample_data/audio_features - Copy.csv')\n",
        "X = dataset.drop(columns=[\"file_name\"])\n",
        "y = dataset[\"file_name\"]\n",
        "\n",
        "# Split dataset into training (80%) and testing (20%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define optimized models\n",
        "models = {\n",
        "    \"Decision Tree\": DecisionTreeClassifier(\n",
        "        max_depth=8,\n",
        "        min_samples_split=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"Random Forest\": RandomForestClassifier(\n",
        "        n_estimators=200,\n",
        "        max_depth=10,\n",
        "        min_samples_split=5,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"SVM\": SVC(\n",
        "        kernel='rbf',\n",
        "        C=10,\n",
        "        gamma='scale',\n",
        "        probability=True,\n",
        "        class_weight='balanced',\n",
        "        random_state=42\n",
        "    ),\n",
        "    \"KNN\": KNeighborsClassifier(\n",
        "        n_neighbors=5,\n",
        "        weights='distance',\n",
        "        metric='euclidean'\n",
        "    ),\n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
        "        n_estimators=200,\n",
        "        learning_rate=0.1,\n",
        "        max_depth=5,\n",
        "        random_state=42\n",
        "    )\n",
        "}\n",
        "\n",
        "# Function to evaluate and print metrics\n",
        "def print_metrics(y_true, y_pred, model_name=\"\"):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(f\"\\n{model_name} Metrics:\")\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}\")\n",
        "    print(f\"Recall: {recall:.4f}\")\n",
        "    print(f\"F1-score: {f1:.4f}\")\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred))\n",
        "\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Perform 5-fold cross-validation with multiple metrics\n",
        "print(\"Performing 5-fold Cross-validation:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "cv_results = {}\n",
        "scoring = ['accuracy', 'precision_weighted', 'recall_weighted', 'f1_weighted']\n",
        "\n",
        "for model_name, model in models.items():\n",
        "    scores = cross_validate(model, X_train_scaled, y_train,\n",
        "                          cv=5, scoring=scoring, return_train_score=False)\n",
        "\n",
        "    cv_results[model_name] = {\n",
        "        'accuracy': scores['test_accuracy'].mean(),\n",
        "        'precision': scores['test_precision_weighted'].mean(),\n",
        "        'recall': scores['test_recall_weighted'].mean(),\n",
        "        'f1': scores['test_f1_weighted'].mean(),\n",
        "        'std_accuracy': scores['test_accuracy'].std()\n",
        "    }\n",
        "\n",
        "    print(f\"\\n{model_name} - Cross-validation Results:\")\n",
        "    print(f\"Accuracy: {scores['test_accuracy'].mean():.4f} (+/- {scores['test_accuracy'].std():.4f})\")\n",
        "    print(f\"Precision: {scores['test_precision_weighted'].mean():.4f}\")\n",
        "    print(f\"Recall: {scores['test_recall_weighted'].mean():.4f}\")\n",
        "    print(f\"F1-score: {scores['test_f1_weighted'].mean():.4f}\")\n",
        "\n",
        "# Find best model from cross-validation\n",
        "best_model = max(cv_results.items(), key=lambda x: x[1]['accuracy'])\n",
        "print(f\"\\nBest Model from Cross-validation: {best_model[0]}\")\n",
        "print(f\"CV Accuracy: {best_model[1]['accuracy']:.4f}\")\n",
        "\n",
        "# Train and evaluate individual models on test set\n",
        "print(\"\\nEvaluating Models on Test Set:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "test_results = {}\n",
        "for model_name, model in models.items():\n",
        "    model.fit(X_train_scaled, y_train)\n",
        "    y_pred = model.predict(X_test_scaled)\n",
        "    test_results[model_name] = print_metrics(y_test, y_pred, model_name)\n",
        "\n",
        "# Select top 3 models for voting ensemble\n",
        "top_models = sorted(cv_results.items(), key=lambda x: x[1]['accuracy'], reverse=True)[:3]\n",
        "top_model_names = [model[0] for model in top_models]\n",
        "\n",
        "print(\"\\nTop 3 Models selected for Voting Ensemble:\")\n",
        "for model_name in top_model_names:\n",
        "    print(f\"{model_name}: CV Accuracy = {cv_results[model_name]['accuracy']:.4f}\")\n",
        "\n",
        "# Create and evaluate voting ensemble\n",
        "voting_clf = VotingClassifier(\n",
        "    estimators=[(name, models[name]) for name in top_model_names],\n",
        "    voting='soft'\n",
        ")\n",
        "\n",
        "print(\"\\nTraining and Evaluating Voting Ensemble:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "voting_clf.fit(X_train_scaled, y_train)\n",
        "ensemble_pred = voting_clf.predict(X_test_scaled)\n",
        "ensemble_metrics = print_metrics(y_test, ensemble_pred, \"Voting Ensemble\")\n",
        "\n",
        "# Perform 5-fold cross-validation on the voting ensemble\n",
        "print(\"\\nPerforming 5-fold Cross-validation on Voting Ensemble:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "voting_cv_scores = cross_validate(voting_clf, X_train_scaled, y_train,\n",
        "                                 cv=5, scoring=scoring, return_train_score=False)\n",
        "\n",
        "voting_cv_results = {\n",
        "    'accuracy': voting_cv_scores['test_accuracy'].mean(),\n",
        "    'precision': voting_cv_scores['test_precision_weighted'].mean(),\n",
        "    'recall': voting_cv_scores['test_recall_weighted'].mean(),\n",
        "    'f1': voting_cv_scores['test_f1_weighted'].mean(),\n",
        "    'std_accuracy': voting_cv_scores['test_accuracy'].std()\n",
        "}\n",
        "\n",
        "print(\"\\nVoting Ensemble Cross-validation Results:\")\n",
        "print(f\"Accuracy: {voting_cv_results['accuracy']:.4f} (+/- {voting_cv_results['std_accuracy']:.4f})\")\n",
        "print(f\"Precision: {voting_cv_results['precision']:.4f}\")\n",
        "print(f\"Recall: {voting_cv_results['recall']:.4f}\")\n",
        "print(f\"F1-score: {voting_cv_results['f1']:.4f}\")\n",
        "\n",
        "# Determine final best model\n",
        "final_ensemble_accuracy = voting_cv_results['accuracy']\n",
        "final_best_model_accuracy = max(test_results.items(), key=lambda x: x[1][0])[1][0]\n",
        "\n",
        "if final_ensemble_accuracy > final_best_model_accuracy:\n",
        "    print(\"\\nFinal Best Model: Voting Ensemble\")\n",
        "    print(f\"Final Accuracy: {final_ensemble_accuracy:.4f}\")\n",
        "else:\n",
        "    best_individual = max(test_results.items(), key=lambda x: x[1][0])[0]\n",
        "    print(f\"\\nFinal Best Model: {best_individual}\")\n",
        "    print(f\"Final Accuracy: {final_best_model_accuracy:.4f}\")\n",
        "\n",
        "# Feature importance for best model (if applicable)\n",
        "best_model_instance = models[best_model[0]]\n",
        "if hasattr(best_model_instance, 'feature_importances_'):\n",
        "    print(\"\\nFeature Importance for Best Model:\")\n",
        "    feature_importance = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance': best_model_instance.feature_importances_\n",
        "    }).sort_values('importance', ascending=False)\n",
        "    print(feature_importance)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBxzrDiX2-8K",
        "outputId": "ab1ff609-ee28-494d-9dd8-1bcc48dd6e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performing 5-fold Cross-validation:\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree - Cross-validation Results:\n",
            "Accuracy: 0.6714 (+/- 0.1611)\n",
            "Precision: 0.6476\n",
            "Recall: 0.6714\n",
            "F1-score: 0.6375\n",
            "\n",
            "Random Forest - Cross-validation Results:\n",
            "Accuracy: 0.6714 (+/- 0.1333)\n",
            "Precision: 0.6516\n",
            "Recall: 0.6714\n",
            "F1-score: 0.6271\n",
            "\n",
            "SVM - Cross-validation Results:\n",
            "Accuracy: 0.7286 (+/- 0.1061)\n",
            "Precision: 0.7244\n",
            "Recall: 0.7286\n",
            "F1-score: 0.6841\n",
            "\n",
            "KNN - Cross-validation Results:\n",
            "Accuracy: 0.7905 (+/- 0.1424)\n",
            "Precision: 0.7832\n",
            "Recall: 0.7905\n",
            "F1-score: 0.7552\n",
            "\n",
            "Gradient Boosting - Cross-validation Results:\n",
            "Accuracy: 0.7048 (+/- 0.1480)\n",
            "Precision: 0.6794\n",
            "Recall: 0.7048\n",
            "F1-score: 0.6616\n",
            "\n",
            "Best Model from Cross-validation: KNN\n",
            "CV Accuracy: 0.7905\n",
            "\n",
            "Evaluating Models on Test Set:\n",
            "--------------------------------------------------\n",
            "\n",
            "Decision Tree Metrics:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "\n",
            "Random Forest Metrics:\n",
            "Accuracy: 0.8889\n",
            "Precision: 0.9259\n",
            "Recall: 0.8889\n",
            "F1-score: 0.8815\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.67      1.00      0.80         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           0.89         9\n",
            "   macro avg       0.92      0.88      0.87         9\n",
            "weighted avg       0.93      0.89      0.88         9\n",
            "\n",
            "\n",
            "SVM Metrics:\n",
            "Accuracy: 0.7778\n",
            "Precision: 0.8519\n",
            "Recall: 0.7778\n",
            "F1-score: 0.7704\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.67      1.00      0.80         2\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.78         9\n",
            "   macro avg       0.83      0.79      0.77         9\n",
            "weighted avg       0.85      0.78      0.77         9\n",
            "\n",
            "\n",
            "KNN Metrics:\n",
            "Accuracy: 0.7778\n",
            "Precision: 0.8519\n",
            "Recall: 0.7778\n",
            "F1-score: 0.7704\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.50      0.67         2\n",
            "           1       0.67      1.00      0.80         2\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.78         9\n",
            "   macro avg       0.83      0.79      0.77         9\n",
            "weighted avg       0.85      0.78      0.77         9\n",
            "\n",
            "\n",
            "Gradient Boosting Metrics:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "\n",
            "Top 3 Models selected for Voting Ensemble:\n",
            "KNN: CV Accuracy = 0.7905\n",
            "SVM: CV Accuracy = 0.7286\n",
            "Gradient Boosting: CV Accuracy = 0.7048\n",
            "\n",
            "Training and Evaluating Voting Ensemble:\n",
            "--------------------------------------------------\n",
            "\n",
            "Voting Ensemble Metrics:\n",
            "Accuracy: 1.0000\n",
            "Precision: 1.0000\n",
            "Recall: 1.0000\n",
            "F1-score: 1.0000\n",
            "\n",
            "Detailed Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "           1       1.00      1.00      1.00         2\n",
            "           2       1.00      1.00      1.00         2\n",
            "           3       1.00      1.00      1.00         3\n",
            "\n",
            "    accuracy                           1.00         9\n",
            "   macro avg       1.00      1.00      1.00         9\n",
            "weighted avg       1.00      1.00      1.00         9\n",
            "\n",
            "\n",
            "Performing 5-fold Cross-validation on Voting Ensemble:\n",
            "--------------------------------------------------\n",
            "\n",
            "Voting Ensemble Cross-validation Results:\n",
            "Accuracy: 0.7048 (+/- 0.1480)\n",
            "Precision: 0.6849\n",
            "Recall: 0.7048\n",
            "F1-score: 0.6638\n",
            "\n",
            "Final Best Model: Decision Tree\n",
            "Final Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub simpleaudio\n",
        "\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "import simpleaudio as sa\n",
        "\n",
        "# Step 1: Load the audio file\n",
        "audio = AudioSegment.from_file(\"/content/sample_data/3.mp3\")  # Replace with your audio file path\n",
        "samples = np.array(audio.get_array_of_samples())\n",
        "\n",
        "# Step 2: Add Laplacian noise\n",
        "epsilon = 0.0001\n",
        "scale = 1 / epsilon  # Scale parameter for Laplacian distribution\n",
        "laplacian_noise = np.random.laplace(0, scale, samples.shape)\n",
        "\n",
        "# Add noise and ensure the audio stays within the correct range\n",
        "if audio.sample_width == 1:  # 8-bit audio\n",
        "    samples = np.clip(samples + laplacian_noise, -128, 127).astype(np.int8)\n",
        "elif audio.sample_width == 2:  # 16-bit audio\n",
        "    samples = np.clip(samples + laplacian_noise, -32768, 32767).astype(np.int16)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported audio sample width\")\n",
        "\n",
        "# Step 3: Create a new AudioSegment with the noisy samples\n",
        "noisy_audio = AudioSegment(\n",
        "    samples.tobytes(),\n",
        "    frame_rate=audio.frame_rate,\n",
        "    sample_width=audio.sample_width,\n",
        "    channels=audio.channels\n",
        ")\n",
        "\n",
        "# Save the modified audio\n",
        "noisy_audio.export(\"noisy_audio.wav\", format=\"wav\")\n",
        "\n",
        "# Step 4: Play the modified audio\n",
        "wave_obj = sa.WaveObject.from_wave_file(\"noisy_audio.wav\")\n",
        "play_obj = wave_obj.play()\n",
        "play_obj.wait_done()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "68v3jvFS6N8f",
        "outputId": "b587a184-e60d-40e9-df85-4c7c70943e0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n",
            "Requirement already satisfied: simpleaudio in /usr/local/lib/python3.10/dist-packages (1.0.4)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SimpleaudioError",
          "evalue": "Error opening PCM device. -- CODE: -2 -- MSG: No such file or directory",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSimpleaudioError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-495fc4ba8bf3>\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Step 4: Play the modified audio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0mwave_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWaveObject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wave_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"noisy_audio.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m \u001b[0mplay_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwave_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0mplay_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/simpleaudio/shiny.py\u001b[0m in \u001b[0;36mplay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         return play_buffer(self.audio_data, self.num_channels,\n\u001b[0m\u001b[1;32m     20\u001b[0m                            self.bytes_per_sample, self.sample_rate)\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/simpleaudio/shiny.py\u001b[0m in \u001b[0;36mplay_buffer\u001b[0;34m(audio_data, num_channels, bytes_per_sample, sample_rate)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplay_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maudio_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_channels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_per_sample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m     play_id = _sa._play_buffer(audio_data, num_channels, bytes_per_sample,\n\u001b[0m\u001b[1;32m     61\u001b[0m                                sample_rate)\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mPlayObject\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplay_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSimpleaudioError\u001b[0m: Error opening PCM device. -- CODE: -2 -- MSG: No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def save_audio_to_folder(input_folder, output_folder):\n",
        "    \"\"\"\n",
        "    Saves the output of processing multiple audio files to a specified folder.\n",
        "\n",
        "    Parameters:\n",
        "    input_folder (str): Path to the input folder where the processed files will be saved\n",
        "    output_folder (str): Path to the output folder where the processed files will be saved\n",
        "    \"\"\"\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    for input_file in input_files:\n",
        "        # Get the filename without the extension\n",
        "        filename = os.path.splitext(os.path.basename(input_file))[0]\n",
        "\n",
        "        # Construct the output file path\n",
        "        output_file = os.path.join(output_folder, f\"{filename}.wav\")\n",
        "\n",
        "        # Process the audio and save the output\n",
        "        noisy_audio.export(output_file, format=\"wav\")\n",
        "\n",
        "        print(f\"Saved processed audio to: {output_file}\")\n",
        "\n",
        "#Here's how you can use this function:\n",
        "\n",
        "```python\n",
        "input_files = [\"audio_file1.wav\", \"audio_file2.wav\", \"audio_file3.wav\"]\n",
        "output_folder = \"processed_audio\"\n",
        "\n",
        "save_audio_to_folder(input_files, output_folder)"
      ],
      "metadata": {
        "id": "dKxtggzR6yeY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "2421f44e-9387-47bc-f138-e9b33f26da62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pydub'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-46fb429d57fc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpydub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msimpleaudio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydub'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub simpleaudio\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "import numpy as np\n",
        "\n",
        "def save_audio_to_folder(input_folder, output_folder, epsilon=1):\n",
        "    \"\"\"\n",
        "    Processes each audio file in the input folder by adding Laplacian noise\n",
        "    and saves the modified files to the output folder.\n",
        "\n",
        "    Parameters:\n",
        "    input_folder (str): Path to the input folder containing audio files.\n",
        "    output_folder (str): Path to the output folder where processed files will be saved.\n",
        "    epsilon (float): Epsilon value for the Laplacian noise scale.\n",
        "    \"\"\"\n",
        "    # Create the output folder if it doesn't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # Define the scale parameter for Laplacian noise\n",
        "    scale = 1 / epsilon\n",
        "\n",
        "    # Iterate through each file in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        # Check if the file is an audio file (mp3)\n",
        "        if filename.endswith(\".mp3\"):\n",
        "            # Load the audio file\n",
        "            input_file = os.path.join(input_folder, filename)\n",
        "            audio = AudioSegment.from_file(input_file)\n",
        "            samples = np.array(audio.get_array_of_samples())\n",
        "\n",
        "            # Generate and add Laplacian noise\n",
        "            laplacian_noise = np.random.laplace(0, scale, samples.shape)\n",
        "            if audio.sample_width == 1:  # 8-bit audio\n",
        "                noisy_samples = np.clip(samples + laplacian_noise, -128, 127).astype(np.int8)\n",
        "            elif audio.sample_width == 2:  # 16-bit audio\n",
        "                noisy_samples = np.clip(samples + laplacian_noise, -32768, 32767).astype(np.int16)\n",
        "            else:\n",
        "                raise ValueError(\"Unsupported audio sample width\")\n",
        "\n",
        "            # Create a new AudioSegment with noisy samples\n",
        "            noisy_audio = AudioSegment(\n",
        "                noisy_samples.tobytes(),\n",
        "                frame_rate=audio.frame_rate,\n",
        "                sample_width=audio.sample_width,\n",
        "                channels=audio.channels\n",
        "            )\n",
        "\n",
        "            # Construct the output file path and save the processed audio\n",
        "            output_file = os.path.join(output_folder, f\"noisy_{filename}\")\n",
        "            noisy_audio.export(output_file, format=\"wav\")\n",
        "            print(f\"Saved processed audio to: {output_file}\")\n",
        "\n",
        "# Usage\n",
        "input_folder = \"/content/sample_data/Audio_signal_input_1\"  # Path to the folder containing input audio files\n",
        "output_folder = \"/content/sample_data/Audio_signal_ouput_1\"  # Path to the folder for saving output audio files\n",
        "\n",
        "save_audio_to_folder(input_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjEuEc-4L0WZ",
        "outputId": "fd3114bc-e529-47bb-cb5a-81d7737becfa"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting simpleaudio\n",
            "  Downloading simpleaudio-1.0.4.tar.gz (2.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.0 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/2.0 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Building wheels for collected packages: simpleaudio\n",
            "  Building wheel for simpleaudio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for simpleaudio: filename=simpleaudio-1.0.4-cp310-cp310-linux_x86_64.whl size=2054402 sha256=bc7584474422f9498f620344e40d4254dca06d6f78c4245858b8cf1b837a2388\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/70/ed/8c41675109565c2c65c3ac40d20859fc9d3f93a8efbb11d1c7\n",
            "Successfully built simpleaudio\n",
            "Installing collected packages: simpleaudio, pydub\n",
            "Successfully installed pydub-0.25.1 simpleaudio-1.0.4\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_19.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_35.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_23.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_37.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_16.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_31.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_40.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_17.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_7.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_12.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_15.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_1.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_21.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_13.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_24.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_22.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_6.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_11.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_30.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_33.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_29.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_3.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_25.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_27.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_5.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_18.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_4.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_32.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_34.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_26.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_39.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_9.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_14.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_38.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_8.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_20.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_2.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_36.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_10.mp3\n",
            "Saved processed audio to: /content/sample_data/Audio_signal_ouput_1/noisy_28.mp3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def create_test_files(input_file, num_files, samples_per_file):\n",
        "    \"\"\"\n",
        "    Create test files from audio features data\n",
        "\n",
        "    Parameters:\n",
        "    input_file (str): Path to input CSV file\n",
        "    num_files (int): Number of test files to create\n",
        "    samples_per_file (int): Number of samples in each test file\n",
        "    \"\"\"\n",
        "    # Read the CSV file\n",
        "    try:\n",
        "        df = pd.read_csv(input_file)\n",
        "        print(f\"Successfully read {input_file}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File {input_file} not found\")\n",
        "        return\n",
        "\n",
        "    # Create output directory in Colab\n",
        "    output_dir = '/content/test_files'\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "        print(f\"Created directory: {output_dir}\")\n",
        "\n",
        "    # Get unique classes\n",
        "    classes = df['file_name'].unique()\n",
        "    samples_per_class = samples_per_file // len(classes)\n",
        "\n",
        "    print(f\"\\nCreating {num_files} test files with {samples_per_file} samples each\")\n",
        "    print(f\"Samples per class: {samples_per_class}\")\n",
        "\n",
        "    # Create test files\n",
        "    for i in range(num_files):\n",
        "        test_data = []\n",
        "\n",
        "        # Select samples from each class\n",
        "        for class_label in classes:\n",
        "            class_data = df[df['file_name'] == class_label]\n",
        "\n",
        "            # Make sure we don't try to select more samples than available\n",
        "            available_samples = len(class_data)\n",
        "            samples_to_select = min(samples_per_class, available_samples)\n",
        "\n",
        "            selected_samples = class_data.sample(\n",
        "                n=samples_to_select,\n",
        "                random_state=i*100 + class_label\n",
        "            )\n",
        "            test_data.append(selected_samples)\n",
        "\n",
        "        # Combine and shuffle the data\n",
        "        test_file = pd.concat(test_data, ignore_index=True)\n",
        "        test_file = test_file.sample(frac=1, random_state=i).reset_index(drop=True)\n",
        "\n",
        "        # Save to CSV\n",
        "        output_file = os.path.join(output_dir, f'test_set_{i+1}.csv')\n",
        "        test_file.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f'\\nCreated test file {i+1}:')\n",
        "        print(f'- Filename: test_set_{i+1}.csv')\n",
        "        print(f'- Total samples: {len(test_file)}')\n",
        "        print('- Class distribution:', test_file['file_name'].value_counts().to_dict())\n",
        "\n",
        "# Define the correct file path for Colab\n",
        "input_file = \"/content/sample_data/audio_features - Copy.csv\"  # Correct path with spaces\n",
        "num_files = 12\n",
        "samples_per_file = 4\n",
        "\n",
        "# Call the function with all required parameters\n",
        "create_test_files(\n",
        "    input_file=input_file,\n",
        "    num_files=num_files,\n",
        "    samples_per_file=samples_per_file\n",
        ")\n",
        "\n",
        "# Print summary of original data\n",
        "df = pd.read_csv(\"/content/sample_data/audio_features - Copy.csv\")  # Correct path\n",
        "print(\"\\nOriginal data summary:\")\n",
        "print(\"Total samples:\", len(df))\n",
        "print(\"Samples per class:\\n\", df['file_name'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DbM00xRoIMCY",
        "outputId": "e554d56e-fae0-45bd-a63d-9f1a5655654c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully read /content/sample_data/audio_features - Copy.csv\n",
            "Created directory: /content/test_files\n",
            "\n",
            "Creating 12 test files with 4 samples each\n",
            "Samples per class: 1\n",
            "\n",
            "Created test file 1:\n",
            "- Filename: test_set_1.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {2: 1, 3: 1, 1: 1, 0: 1}\n",
            "\n",
            "Created test file 2:\n",
            "- Filename: test_set_2.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {3: 1, 2: 1, 0: 1, 1: 1}\n",
            "\n",
            "Created test file 3:\n",
            "- Filename: test_set_3.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {2: 1, 3: 1, 1: 1, 0: 1}\n",
            "\n",
            "Created test file 4:\n",
            "- Filename: test_set_4.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {3: 1, 1: 1, 0: 1, 2: 1}\n",
            "\n",
            "Created test file 5:\n",
            "- Filename: test_set_5.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {0: 1, 1: 1, 3: 1, 2: 1}\n",
            "\n",
            "Created test file 6:\n",
            "- Filename: test_set_6.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {0: 1, 1: 1, 2: 1, 3: 1}\n",
            "\n",
            "Created test file 7:\n",
            "- Filename: test_set_7.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {0: 1, 3: 1, 1: 1, 2: 1}\n",
            "\n",
            "Created test file 8:\n",
            "- Filename: test_set_8.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {2: 1, 1: 1, 0: 1, 3: 1}\n",
            "\n",
            "Created test file 9:\n",
            "- Filename: test_set_9.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {2: 1, 1: 1, 0: 1, 3: 1}\n",
            "\n",
            "Created test file 10:\n",
            "- Filename: test_set_10.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {1: 1, 3: 1, 0: 1, 2: 1}\n",
            "\n",
            "Created test file 11:\n",
            "- Filename: test_set_11.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {2: 1, 0: 1, 3: 1, 1: 1}\n",
            "\n",
            "Created test file 12:\n",
            "- Filename: test_set_12.csv\n",
            "- Total samples: 4\n",
            "- Class distribution: {2: 1, 3: 1, 0: 1, 1: 1}\n",
            "\n",
            "Original data summary:\n",
            "Total samples: 42\n",
            "Samples per class:\n",
            " file_name\n",
            "2    11\n",
            "3    11\n",
            "0    10\n",
            "1    10\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def create_training_files(input_file, num_files, samples_per_file):\n",
        "    \"\"\"\n",
        "    Create training files from audio features data\n",
        "\n",
        "    Parameters:\n",
        "    input_file (str): Path to input CSV file\n",
        "    num_files (int): Number of training files to create\n",
        "    samples_per_file (int): Number of samples in each training file\n",
        "    \"\"\"\n",
        "    # Read the CSV file\n",
        "    try:\n",
        "        df = pd.read_csv(input_file)\n",
        "        print(f\"Successfully read {input_file}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"Error: File {input_file} not found\")\n",
        "        return\n",
        "\n",
        "    # Create output directory in Colab\n",
        "    output_dir = '/content/training_files'\n",
        "    if not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "        print(f\"Created directory: {output_dir}\")\n",
        "\n",
        "    # Get unique classes\n",
        "    classes = df['file_name'].unique()\n",
        "    samples_per_class = samples_per_file // len(classes)\n",
        "\n",
        "    print(f\"\\nCreating {num_files} training files with {samples_per_file} samples each\")\n",
        "    print(f\"Samples per class: {samples_per_class}\")\n",
        "\n",
        "    # Create training files\n",
        "    for i in range(num_files):\n",
        "        training_data = []\n",
        "\n",
        "        # Select samples from each class\n",
        "        for class_label in classes:\n",
        "            class_data = df[df['file_name'] == class_label]\n",
        "\n",
        "            # Make sure we don't try to select more samples than available\n",
        "            available_samples = len(class_data)\n",
        "            samples_to_select = min(samples_per_class, available_samples)\n",
        "\n",
        "            # Use different random_state for each file to ensure different samples\n",
        "            selected_samples = class_data.sample(\n",
        "                n=samples_to_select,\n",
        "                random_state=i*100 + hash(str(class_label)) % 10000  # More robust random state\n",
        "            )\n",
        "            training_data.append(selected_samples)\n",
        "\n",
        "        # Combine and shuffle the data\n",
        "        training_file = pd.concat(training_data, ignore_index=True)\n",
        "        training_file = training_file.sample(frac=1, random_state=i).reset_index(drop=True)\n",
        "\n",
        "        # Save to CSV\n",
        "        output_file = os.path.join(output_dir, f'training_set_{i+1}.csv')\n",
        "        training_file.to_csv(output_file, index=False)\n",
        "\n",
        "        print(f'\\nCreated training file {i+1}:')\n",
        "        print(f'- Filename: training_set_{i+1}.csv')\n",
        "        print(f'- Total samples: {len(training_file)}')\n",
        "        print('- Class distribution:', training_file['file_name'].value_counts().to_dict())\n",
        "\n",
        "# Define parameters\n",
        "input_file = \"/content/sample_data/audio_features - Copy.csv\"\n",
        "num_files = 28\n",
        "samples_per_file = 100  # Increased from 8 to 100 for better training data size\n",
        "\n",
        "# Call the function\n",
        "create_training_files(\n",
        "    input_file=input_file,\n",
        "    num_files=num_files,\n",
        "    samples_per_file=samples_per_file\n",
        ")\n",
        "\n",
        "# Print summary of original data\n",
        "df = pd.read_csv(input_file)\n",
        "print(\"\\nOriginal data summary:\")\n",
        "print(\"Total samples:\", len(df))\n",
        "print(\"Samples per class:\")\n",
        "class_distribution = df['file_name'].value_counts()\n",
        "print(class_distribution)\n",
        "\n",
        "# Print usage statistics\n",
        "print(\"\\nTraining data creation summary:\")\n",
        "print(f\"Total training files created: {num_files}\")\n",
        "print(f\"Samples per file: {samples_per_file}\")\n",
        "print(f\"Total training samples: {num_files * samples_per_file}\")\n",
        "print(f\"Samples per class per file: {samples_per_file // len(class_distribution)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUOjMVDYNj1o",
        "outputId": "83cebceb-7216-44c2-e2a4-e8f727cc4292"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully read /content/sample_data/audio_features - Copy.csv\n",
            "Created directory: /content/training_files\n",
            "\n",
            "Creating 28 training files with 100 samples each\n",
            "Samples per class: 25\n",
            "\n",
            "Created training file 1:\n",
            "- Filename: training_set_1.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 2:\n",
            "- Filename: training_set_2.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 3:\n",
            "- Filename: training_set_3.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 4:\n",
            "- Filename: training_set_4.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 5:\n",
            "- Filename: training_set_5.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {3: 11, 2: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 6:\n",
            "- Filename: training_set_6.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 7:\n",
            "- Filename: training_set_7.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 8:\n",
            "- Filename: training_set_8.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {3: 11, 2: 11, 1: 10, 0: 10}\n",
            "\n",
            "Created training file 9:\n",
            "- Filename: training_set_9.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {3: 11, 2: 11, 1: 10, 0: 10}\n",
            "\n",
            "Created training file 10:\n",
            "- Filename: training_set_10.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 11:\n",
            "- Filename: training_set_11.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 12:\n",
            "- Filename: training_set_12.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 13:\n",
            "- Filename: training_set_13.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 14:\n",
            "- Filename: training_set_14.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 1: 10, 0: 10}\n",
            "\n",
            "Created training file 15:\n",
            "- Filename: training_set_15.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {3: 11, 2: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 16:\n",
            "- Filename: training_set_16.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 17:\n",
            "- Filename: training_set_17.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 18:\n",
            "- Filename: training_set_18.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 1: 10, 0: 10}\n",
            "\n",
            "Created training file 19:\n",
            "- Filename: training_set_19.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {3: 11, 2: 11, 1: 10, 0: 10}\n",
            "\n",
            "Created training file 20:\n",
            "- Filename: training_set_20.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 1: 10, 0: 10}\n",
            "\n",
            "Created training file 21:\n",
            "- Filename: training_set_21.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 1: 10, 0: 10}\n",
            "\n",
            "Created training file 22:\n",
            "- Filename: training_set_22.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {3: 11, 2: 11, 1: 10, 0: 10}\n",
            "\n",
            "Created training file 23:\n",
            "- Filename: training_set_23.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {3: 11, 2: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 24:\n",
            "- Filename: training_set_24.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 1: 10, 0: 10}\n",
            "\n",
            "Created training file 25:\n",
            "- Filename: training_set_25.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {3: 11, 2: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 26:\n",
            "- Filename: training_set_26.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {3: 11, 2: 11, 1: 10, 0: 10}\n",
            "\n",
            "Created training file 27:\n",
            "- Filename: training_set_27.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Created training file 28:\n",
            "- Filename: training_set_28.csv\n",
            "- Total samples: 42\n",
            "- Class distribution: {2: 11, 3: 11, 0: 10, 1: 10}\n",
            "\n",
            "Original data summary:\n",
            "Total samples: 42\n",
            "Samples per class:\n",
            "file_name\n",
            "2    11\n",
            "3    11\n",
            "0    10\n",
            "1    10\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Training data creation summary:\n",
            "Total training files created: 28\n",
            "Samples per file: 100\n",
            "Total training samples: 2800\n",
            "Samples per class per file: 25\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load and prepare the data\n",
        "def prepare_data(file_path):\n",
        "    # Read the CSV file\n",
        "    df = pd.read_csv('/content/sample_data/train_copy.csv')\n",
        "\n",
        "    # Separate features and target\n",
        "    # Assuming all columns except 'file_name' are features\n",
        "    X = df.drop('file_name', axis=1)\n",
        "    y = df['file_name']\n",
        "\n",
        "    # Split the data\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
        "\n",
        "def train_and_evaluate_models(X_train, X_test, y_train, y_test):\n",
        "    # Initialize models\n",
        "    models = {\n",
        "        'SVM': SVC(kernel='rbf', random_state=42),\n",
        "        'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "        'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
        "        'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "        'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
        "        'Naive Bayes': GaussianNB()\n",
        "    }\n",
        "\n",
        "    # Dictionary to store results\n",
        "    results = {\n",
        "        'Model': [],\n",
        "        'Accuracy': [],\n",
        "        'Precision': [],\n",
        "        'Recall': [],\n",
        "        'F1-Score': []\n",
        "    }\n",
        "\n",
        "    # Train and evaluate each model\n",
        "    for name, model in models.items():\n",
        "        print(f\"\\nTraining {name}...\")\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = model.predict(X_test)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        recall = recall_score(y_test, y_pred, average='weighted')\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "        # Store results\n",
        "        results['Model'].append(name)\n",
        "        results['Accuracy'].append(accuracy)\n",
        "        results['Precision'].append(precision)\n",
        "        results['Recall'].append(recall)\n",
        "        results['F1-Score'].append(f1)\n",
        "\n",
        "        print(f\"{name} Results:\")\n",
        "        print(f\"Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Precision: {precision:.4f}\")\n",
        "        print(f\"Recall: {recall:.4f}\")\n",
        "        print(f\"F1-Score: {f1:.4f}\")\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "def plot_results(results_df):\n",
        "    # Set figure size\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    # Create grouped bar chart\n",
        "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "    x = np.arange(len(results_df['Model']))\n",
        "    width = 0.2\n",
        "\n",
        "    for i, metric in enumerate(metrics):\n",
        "        plt.bar(x + i*width, results_df[metric], width, label=metric)\n",
        "\n",
        "    plt.xlabel('Models')\n",
        "    plt.ylabel('Score')\n",
        "    plt.title('Model Performance Comparison')\n",
        "    plt.xticks(x + width*1.5, results_df['Model'], rotation=45)\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the plot\n",
        "    plt.savefig('model_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    # File path\n",
        "    file_path = \"/content/sample_data/audio_features - Copy.csv\"\n",
        "\n",
        "    print(\"Loading and preparing data...\")\n",
        "    X_train, X_test, y_train, y_test = prepare_data(file_path)\n",
        "\n",
        "    print(\"\\nTraining and evaluating models...\")\n",
        "    results_df = train_and_evaluate_models(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    print(\"\\nResults Summary:\")\n",
        "    print(results_df.to_string(index=False))\n",
        "\n",
        "    print(\"\\nCreating visualization...\")\n",
        "    plot_results(results_df)\n",
        "    print(\"Results have been plotted and saved as 'model_comparison.png'\")\n",
        "\n",
        "    # Save results to CSV\n",
        "    results_df.to_csv('model_results.csv', index=False)\n",
        "    print(\"Results have been saved to 'model_results.csv'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "WB0CdqCgQmDg",
        "outputId": "6c6c376c-36f6-4e0c-8963-e684379e5c78"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading and preparing data...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "EmptyDataError",
          "evalue": "No columns to parse from file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mEmptyDataError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-aa9235c02f3f>\u001b[0m in \u001b[0;36m<cell line: 131>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-aa9235c02f3f>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading and preparing data...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m     \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining and evaluating models...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-aa9235c02f3f>\u001b[0m in \u001b[0;36mprepare_data\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Read the CSV file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/sample_data/train_copy.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Separate features and target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1897\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1898\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1899\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;31m# Fail here loudly instead of in cython after reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mimport_optional_dependency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pyarrow\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mparsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mEmptyDataError\u001b[0m: No columns to parse from file"
          ]
        }
      ]
    }
  ]
}